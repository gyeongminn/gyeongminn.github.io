<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Python on Gyeongmin의 개발 블로그</title><link>https://gyeongmin.kr/tags/python/</link><description>Recent content in Python on Gyeongmin의 개발 블로그</description><generator>Hugo -- gohugo.io</generator><language>ko</language><copyright>Gyeongmin Lee</copyright><lastBuildDate>Thu, 11 Apr 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://gyeongmin.kr/tags/python/index.xml" rel="self" type="application/rss+xml"/><item><title>텍스트 임베딩</title><link>https://gyeongmin.kr/p/text-embedding/</link><pubDate>Thu, 11 Apr 2024 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/text-embedding/</guid><description>&lt;img src="https://gyeongmin.kr/images/pytorch-transformer-nlp-computer-vision.png" alt="Featured image of post 텍스트 임베딩" />&lt;h2 id="word2vec">Word2Vec&lt;/h2>
&lt;p>Word2Vec은 단어 간의 유사성을 측정하기 위해 분포 가설을 기반으로 개발된 임베딩 모델이다.&lt;/p>
&lt;p>분포 가설이란, 같은 문맥에서 함께 자주 나타나는 단어들은 서로 유사한 의미를 가질 가능성이 높다는 가정이다. 단어 간의 동시 발생 확률 분포를 이용해 단어 간의 유사성을 측정한다.&lt;/p>
&lt;p>&amp;ldquo;나는 자전거를 타고 간다&amp;rdquo; 와, &amp;ldquo;나는 자동차를 타고 간다&amp;rdquo; 라는 문장에서 &amp;lsquo;자전거&amp;rsquo;와 &amp;lsquo;자동차&amp;rsquo;는 이동수단이라는 맥락에서 서로 유사한 단어이다. 이런식으로 분포 가설에 의해 주변에 분포한 단어들이 동일하거나 유사하므로 비슷한 의미를 가질 것이라고 모델이 학습한다.&lt;/p>
&lt;p>이런 가정을 통해 단어의 분산 표현(Distributed Representation)을 학습할 수 있다. 분산 표현이란 단어를 고차원 벡터 공간에 매핑하여 단어의 의미를 담는 것을 의미한다. 유사한 문맥에서 등장하는 단어는 비슷한 벡터 공간상 위치를 갖게 된다.&lt;/p>
&lt;p>Word2Vec은 단어 임베딩 벡터 기법이다. 이는 밀집 표현이라고도 하는데, 벡터 표편이 sparse 하지 않아 단어를 고정된 크기의 실수 벡터로 표현하기 때문에 단어 사전의 크기가 커지더라도 벡터의 크기가 커지지 않는다.&lt;/p>
&lt;h2 id="cbow">CBoW&lt;/h2>
&lt;p>CBoW(Continuous Bag of Wbrds)란 주변에 있는 단어를 가지고 중간에 있는 단어를 예측하는 방법이다. 중심 단어(Center Word)는 예측해야 할 단어를 의미하며, 예측에 사용되는 단어들을 주변 단어(Context Word) 라고 한다.&lt;/p>
&lt;p>학습할 떈 슬라이딩 윈도우 기법을 적용하여 학습한다. 한 번 학습할 때 중심 단어를 기준으로, 좌우로 윈도우 사이즈 크기만큼의 주변 단어를 함께 학습한다.&lt;/p>
&lt;p>CBoW는 원-핫 벡터를 입력으로 받아, 입력 문장 내 모든 단어의 임베딩 벡터를 평균내어 중심 단어의 임베딩 벡터를 예측한다.&lt;/p>
&lt;p>입력 단어는 원-핫 벡터로 표현돼 투사층(Projection Layer)에 입력된다. 투사층이란 원-핫 벡터의 인덱스에 해당하는 임베딩 벡터를 반환하는 룩업 테이블(LUT)이 된다. 투사층을 통과하면 각 단어는 임베딩 벡터로 변환된다. 이 벡터에 소프트맥스 함수를 이용해 중심 단어를 예측한다.&lt;/p>
&lt;h2 id="skip-gram">Skip-gram&lt;/h2>
&lt;p>Skip-gram은 CBoW와 비슷하지만, 중심 단어를 입력으로 받아서 주변 단어를 예측하는 모델이다.&lt;/p>
&lt;p>CBoW는 하나의 윈도우에서 하나의 학습 데이터가 만들어졌지만, Skip-gram은 중심 단어와 주변 단어를 하나의 쌍으로 한 여러 데이터가 만들어진다. 따라서 더욱 많은 학습 데이터세트를 추출할 수 있어 더욱 높은 성능을 보인다. 또한 드물게 등장하는 단어도 더 잘 학습할 수 있고 벡터 공간에서 더 유의미한 거리 관계를 형성할 수 있다.&lt;/p>
&lt;h2 id="계층적-소프트맥스">계층적 소프트맥스&lt;/h2>
&lt;p>corpus의 크기가 커지만 단어 사전의 크기도 커져 학습 속도가 느려진다. 이를 해결하기 위해 계층적 소프트맥스를 사용한다.&lt;/p>
&lt;p>출력층을 이진 트리 구조로 표현하고 등장하는 단어일수록 트리의 상위 노드에 배치, 드물게 등장하는 단어는 하위 노드에 배치한다.&lt;/p>
&lt;p>단어 사전의 크기를 $V$라고 했을 때, $\bigo(V)$의 시간복잡도를 갖지만, 계층적 소프트맥스의 시간 복잡도는 $\bigo(\log_2V)$의 시간복잡도를 갖는다.&lt;/p></description></item><item><title>텍스트 벡터화</title><link>https://gyeongmin.kr/p/text-vectorization/</link><pubDate>Sat, 06 Apr 2024 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/text-vectorization/</guid><description>&lt;img src="https://gyeongmin.kr/images/pytorch-transformer-nlp-computer-vision.png" alt="Featured image of post 텍스트 벡터화" />&lt;p>컴퓨터는 텍스트를 이해할 수 없다. 따라서 텍스트를 숫자로 변환하는 텍스트 벡터화(Text Vectorization) 과정이 필요하다.&lt;/p>
&lt;h2 id="원-핫-인코딩">원-핫 인코딩&lt;/h2>
&lt;p>원-핫 인코딩 (One-Hot Encoding)은 문서에 등장하는 각 단어를 고유한 색인 값(index)으로 매핑한 후, 해당 색인 위치를 1로, 나머지는 0으로 표시하는 방식이다.&lt;/p>
&lt;p>&lt;code>I like apples&lt;/code>, &lt;code>I like bananas&lt;/code> 라는 두 문장을 토큰화하고 매핑 테이블을 구하면 아래와 같다.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Index&lt;/th>
&lt;th>0&lt;/th>
&lt;th>1&lt;/th>
&lt;th>2&lt;/th>
&lt;th>3&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Word&lt;/td>
&lt;td>I&lt;/td>
&lt;td>like&lt;/td>
&lt;td>apples&lt;/td>
&lt;td>bananas&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>이를 바탕으로 원-핫 인코딩을 진행하면 아래와 같다.&lt;/p>
&lt;ul>
&lt;li>&lt;code>I like apples&lt;/code> -&amp;gt; &lt;code>[1, 1, 1, 0]&lt;/code>&lt;/li>
&lt;li>&lt;code>I like bananas&lt;/code> -&amp;gt; &lt;code>[1, 1, 0, 1]&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>이러한 방법은 단어나 문장을 벡터 형태로 변환하기 쉽고 간단하다는 장점이 있지만, 벡터의 희소성 (Sparsity)이 크다는 단점이 있어 자칫 차원의 저주와 같은 문제에 빠질 수 있다.&lt;/p>
&lt;h2 id="빈도-벡터화">빈도 벡터화&lt;/h2>
&lt;p>빈도 벡터화 (Count Vectorization)는 BOW를 만드는 방법이다. 먼저 BOW를 알고 넘어가자.&lt;/p>
&lt;p>경제 뉴스에서는 경제 관련 단어가, 정치 뉴스에선 정치 관련 단어가 많이 나오듯, 문서의 내용과 연관성이 높은 단어가 자주 등장할 것이다. 이런 가설을 바탕으로 BOW, Bag of Words가 나왔다.&lt;/p>
&lt;p>BOW는 단어들의 출현 빈도(frequency)에만 집중하는 텍스트 데이터의 수치화 표현 방법이다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/text-vectorization/image.png"
width="661"
height="380"
srcset="https://gyeongmin.kr/p/text-vectorization/image_hu1844c23a2351ad80474ab4abca49cd8c_62162_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/text-vectorization/image_hu1844c23a2351ad80474ab4abca49cd8c_62162_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="BOW(Bag of Words)"
class="gallery-image"
data-flex-grow="173"
data-flex-basis="417px"
>&lt;/p>
&lt;p>단어 피처에 값을 부여할 때, 각 문서에서 해당 단어가 나타나는 횟수를 부여하는 경우를 카운트 벡터화 또는 빈도 벡터화라고 한다.&lt;/p>
&lt;p>&lt;code>I have an apple, do you have a banana?&lt;/code> 라는 문장을 빈도 벡터화 하면 다음과 같다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">sklearn.feature_extraction.text&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">CountVectorizer&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;I have an apple, do you have an banana?&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">vect&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">CountVectorizer&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">vect&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">fit_transform&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toarray&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">vect&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">vocabulary_&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">[[2 1 1 2 1 1]]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{&amp;#39;have&amp;#39;: 3, &amp;#39;an&amp;#39;: 0, &amp;#39;apple&amp;#39;: 1, &amp;#39;do&amp;#39;: 2, &amp;#39;you&amp;#39;: 5, &amp;#39;orange&amp;#39;: 4}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;code>an&lt;/code>는 2번, &lt;code>apple&lt;/code>는 1번, &lt;code>do&lt;/code>은 1번, &lt;code>have&lt;/code>은 2번, &lt;code>orange&lt;/code>는 1번, &lt;code>you&lt;/code>는 1번 나왔다. 2글자 미만인 &lt;code>I&lt;/code>는 제외되었다.&lt;/p>
&lt;p>이와 같이, 단어의 빈도만 고려하기 때문에 an과 같은 관사가 중요하게 고려되었다. 따라서, &lt;code>CountVectorizer(stop_words=[&amp;quot;the&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;an&amp;quot;, &amp;quot;is&amp;quot;, &amp;quot;not&amp;quot;])&lt;/code> 과 같이 불용어를 제거하고 사용하기도 한다.&lt;/p>
&lt;p>하지만, 여러 문장에서 자주 사용되는 단어들을 모두 불용어로 지정하는 것은 한계가 있을 것이다.&lt;/p>
&lt;h2 id="tf-idf">TF-IDF&lt;/h2>
&lt;p>TF-IDF(Term Frequency-Inverse Document Frequency) 란 텍스트 문서에서 특정 단어의 중요도를 계산하는 방법으로, 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적인 가중치를 의미한다.&lt;/p>
&lt;p>즉, BOW에 가중치를 부여하는 것이다. TF-IDF의 식은 아래와 같다.&lt;/p>
&lt;p>$$
\text{TF–IDF} = \text{TF}(t, d) \times \text{IDF}(t, d)
$$&lt;/p>
&lt;p>TF-IDF는 위와 같이 TF와 IDF의 곱이다. 먼저 TF에 대해 알아보자.&lt;/p>
&lt;p>TF는 Term Frequency, 단어 빈도이다. 3개의 문서에서 movie라는 단어가 4번 등장했다면, 값은 4이다.&lt;/p>
&lt;p>$$
\text{TF} = \text{count}(t, d)
$$&lt;/p>
&lt;p>IDF는 Inverse Document Frequency로, 전체 문서 수를 문서 빈도로 나눈 다음에 로그를 취한 값이다.&lt;/p>
&lt;p>문서 빈도가 높을수록 해당 단어가 일반적인 단어일 것이다. 따라서 IDF는 문서 내에서 특정 단어가 얼마나 중요한지를 나타낸다.&lt;/p>
&lt;div markdown="1">
$$
\begin{aligned}
\text{DF}(t, D) &amp;= \text{count}(t \in d : d \in D) \\
\text{IDF}(t, D) &amp;= \log \left( \frac{\text{count}(D)}{1 + \text{DF}(t, D)} \right)
\end{aligned}
$$
&lt;/div>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">sklearn.feature_extraction.text&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">TfidfVectorizer&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">corpus&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;That movie is famous movie&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;I like that actor&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;I don’t like that actor&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">tfidf_vectorizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">TfidfVectorizer&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">tfidf_vectorizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">fit&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">corpus&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">tfidf_matrix&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tfidf_vectorizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">transform&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">corpus&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tfidf_matrix&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">toarray&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tfidf_vectorizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">vocabulary_&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">[[0. 0. 0.39687454 0.39687454 0. 0.79374908
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0.2344005 ]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [0.61980538 0. 0. 0. 0.61980538 0.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0.48133417]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [0.4804584 0.63174505 0. 0. 0.4804584 0.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 0.37311881]]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{&amp;#39;that&amp;#39;: 6, &amp;#39;movie&amp;#39;: 5, &amp;#39;is&amp;#39;: 3, &amp;#39;famous&amp;#39;: 2, &amp;#39;like&amp;#39;: 4, &amp;#39;actor&amp;#39;: 0, &amp;#39;don&amp;#39;: 1}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>이를 통해 문서마다 중요한 단어만 추출할 수 있으며, 벡터값을 활용해 문서 내 핵심 단어를 추출할 수
있다.&lt;/p>
&lt;p>빈도 기반 벡터화는 문장의 순서나 문맥을 고려하지 않는다. 그러므로 문장 생성과 같이 순서가 중요한 작업에는 부적합하다. 또한, 벡터가 해당 문서 내의 중요도를 의미할 뿐, 벡터가 단어의 의미를 담고 있지는 않다.&lt;/p></description></item><item><title>토큰화</title><link>https://gyeongmin.kr/p/tokenization/</link><pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/tokenization/</guid><description>&lt;img src="https://gyeongmin.kr/images/pytorch-transformer-nlp-computer-vision.png" alt="Featured image of post 토큰화" />&lt;h2 id="자연어-처리">자연어 처리&lt;/h2>
&lt;p>자연어(Natural Language)는 사람들이 일상적으로 쓰는 언어를 말한다.
자연어 처리(Natural Language Processing)는 컴퓨터가 인간의 언어를 이해하고 해석 및 생성하기 위한 기술을 의미한다.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>모호성(Ambiguity): 인간 언어는 맥락에 따라 다양한 의미를 가질 수 있으며, 이를 명확히 구분&lt;/p>
&lt;/li>
&lt;li>
&lt;p>가변성(Variability): 인간 언어는 사투리, 억양, 신조어 등 다양한 스타일로 인해 가변적이며, 이를 이해하고 처리해야 언어를 올바르게 사용&lt;/p>
&lt;/li>
&lt;li>
&lt;p>구조성(Structure): 문장의 구조와 문법적 요소를 이해하고 이를 바탕으로 의미를 추론 및 분석&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="토큰화">토큰화&lt;/h2>
&lt;p>문제를 이해하고 구분할 수 있는 모델을 만들려면 우선 말뭉치(Corpus)를 일정한 단위인 토큰(Token)으로 나눠야 한다. 토큰화(Tokenization)을 진행해 컴퓨터가 자연어를 이해할 수 있도록 말뭉치를 나누는 것이다.&lt;/p>
&lt;h3 id="단어-토큰화">단어 토큰화&lt;/h3>
&lt;p>우리말 띄어쓰기 원칙 제 2항, &amp;ldquo;문장의 각 단어는 띄어 씀을 원칙으로 한다&amp;quot;에 의해, 공백을 기준으로 &lt;code>split()&lt;/code>하면 단어 토큰화를 할 수 있다.&lt;/p>
&lt;ul>
&lt;li>입력: &lt;code>'단어 토큰화 예시'&lt;/code>&lt;/li>
&lt;li>출력: &lt;code>['단어', '토큰화', '예시']&lt;/code>&lt;/li>
&lt;/ul>
&lt;h3 id="글자-토큰화">글자 토큰화&lt;/h3>
&lt;p>글자 토큰화는 글자 기준으로 문장을 나누는 방식이다. &lt;code>split('')&lt;/code>을 적용해 글자 토큰화를 할 수 있다.&lt;/p>
&lt;ul>
&lt;li>입력: &lt;code>'글자 토큰화이다.'&lt;/code>&lt;/li>
&lt;li>출력: &lt;code>['글', '자', ' ', '토', '큰', '화', '이', '다', '.']&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>영어는 한 칸에 한 글자가 들어가지만, 한글의 경우 초성, 중성, 종성의 조합으로 한 글자가 구성된다. 이를 모두 분해할 수 있는 자모(jamo) 라이브러리도 있다.&lt;/p>
&lt;ul>
&lt;li>입력: &lt;code>'자모 토큰화'&lt;/code>&lt;/li>
&lt;li>출력: &lt;code>['ㅈ', 'ㅏ', 'ㅁ', 'ㅗ', ' ', 'ㅌ', 'ㅗ', 'ㅋ', 'ㅡ', 'ㄴ', 'ㅎ', 'ㅘ']&lt;/code>&lt;/li>
&lt;/ul>
&lt;h3 id="형태소-토큰화">형태소 토큰화&lt;/h3>
&lt;p>형태소 토큰화(Morpheme Tokenization)란 텍스트를 형태소 단위로 나누는 토큰화 방법이다. 형태소는 의미를 가지는 최소 단위이다.&lt;/p>
&lt;p>형태소는 명사, 동사, 형용사와 같이 문장 내에서 홀로 쓰일 수 있으며 스스로 의미를 가지는 &lt;strong>자립 형태소&lt;/strong>와, 스스로 의미를 가지지 못하고 조사, 어미, 접두사, 접미사와 같이 다른 형태소와 조합되어 사용되는 &lt;strong>의존 형태소&lt;/strong>로 구분한다.&lt;/p>
&lt;p>문장 내 단어의 위치에 따라 품사가 결정되는 영어와는 달리, 한국어는 단어와 조사의 결합으로 품사가 결정된다. &amp;ldquo;나는 밥을 먹는다&amp;rdquo; 에서 &amp;ldquo;먹는다 나는 밥을&amp;rdquo; 로 바꾸어도 어색하지만 문장의 의미는 이해할 수 있는 것과 같다.&lt;/p>
&lt;p>우리말에서 동사를 보면 변화가 굉장히 많다. &amp;lsquo;먹다&amp;rsquo;, &amp;lsquo;먹는다&amp;rsquo;, &amp;lsquo;먹이다&amp;rsquo;, 먹었다&amp;rsquo;, &amp;lsquo;먹어&amp;rsquo; 등 유사한 단어가 무수히 많다. 이는 &amp;lsquo;먹-&amp;lsquo;이라는 어간에 어미 &amp;lsquo;-다&amp;rsquo;, 사동 접미사 &amp;lsquo;-이-&amp;rsquo;, 과거 시제 어미 &amp;lsquo;-었-&amp;rsquo; 등이 붙어 여러 단어의 조합이 된 것이다.&lt;/p>
&lt;p>이처럼 단어의 변화형을 고려하지 않고 유사한 단어를 모두 다른 단어로 간주한다면, 자칫 차원의 저주에 빠지게 되거나 모델 학습이 어려워질 수 있다. 따라서 의미를 가지는 최소 단위인 형태소로 글자를 분리(토큰화)하여 모델을 학습하는 것이 좋다.&lt;/p>
&lt;p>토큰화를 할 때는 그 언어의 문법적인 특성을 고려하여 적절한 토크나이저를 사용해야 한다.&lt;/p>
&lt;h4 id="형태소-분석기">형태소 분석기&lt;/h4>
&lt;p>Konlpy, NLTK, spaCy와 같은 라이브러리 등이 있다. 아래는 Konlpy 라이브러리에서 꼬꼬마 형태소 분석기를 사용하는 예시이다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">konlpy.tag&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">Kkma&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">kkma&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Kkma&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">sentence&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;무엇이든 상상할 수 있는 사람은 무엇이든 만들어 낼 수 있다.&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">nouns&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">kkma&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nouns&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sentence&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">sentences&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">kkma&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sentences&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sentence&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">morphs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">kkma&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">morphs&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sentence&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">pos&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">kkma&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pos&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sentence&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;명사 추출 :&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">nouns&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;문장 추출 :&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">sentences&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;형태소 추출 :&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">morphs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;품사 태깅 :&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">pos&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">명사 추출: [&amp;#39;무엇&amp;#39;, &amp;#39;상상&amp;#39;, &amp;#39;수&amp;#39;, &amp;#39;사람&amp;#39;, &amp;#39;무엇&amp;#39;]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">구문 추출 : [&amp;#39;무엇이든 상상할 수 있는 사람은 무엇이든 만들어 낼 수 있다.&amp;#39;]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">형태소 추출 : [&amp;#39;무엇&amp;#39;, &amp;#39;이&amp;#39;, &amp;#39;든&amp;#39;, &amp;#39;상상&amp;#39;, &amp;#39;하&amp;#39;, &amp;#39;ᄅ&amp;#39;, &amp;#39;수&amp;#39;, &amp;#39;있&amp;#39;, &amp;#39;는&amp;#39;, &amp;#39;사람&amp;#39;, &amp;#39;은&amp;#39;, &amp;#39;무엇&amp;#39;, &amp;#39;이&amp;#39;, &amp;#39;든&amp;#39;, &amp;#39;만들&amp;#39;, &amp;#39;어&amp;#39;, &amp;#39;내&amp;#39;, &amp;#39;ᄅ&amp;#39;, &amp;#39;수&amp;#39;, &amp;#39;있&amp;#39;, &amp;#39;다&amp;#39;, &amp;#39;.&amp;#39;]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">품사 태깅 : [(&amp;#39;무엇&amp;#39;, &amp;#39;NNG&amp;#39;), (&amp;#39;이&amp;#39;, &amp;#39;VCP&amp;#39;), (&amp;#39;든&amp;#39;, &amp;#39;ECE&amp;#39;), (&amp;#39;상상&amp;#39;, &amp;#39;NNG&amp;#39;), (&amp;#39;하&amp;#39;, &amp;#39;XSV&amp;#39;), (&amp;#39;ᄅ&amp;#39;, &amp;#39;ETD&amp;#39;), (&amp;#39;수&amp;#39;, &amp;#39;NNB&amp;#39;), (&amp;#39;있&amp;#39;, &amp;#39;VV&amp;#39;), (&amp;#39;는&amp;#39;, &amp;#39;ETD&amp;#39;), (&amp;#39;사람&amp;#39;, &amp;#39;NNG&amp;#39;), (&amp;#39;은&amp;#39;, &amp;#39;JX&amp;#39;), (&amp;#39;무엇&amp;#39;, &amp;#39;NP&amp;#39;), (&amp;#39;이&amp;#39;, &amp;#39;VCP&amp;#39;), (&amp;#39;든&amp;#39;, &amp;#39;ECE&amp;#39;), (&amp;#39;만들&amp;#39;, &amp;#39;VV&amp;#39;), (&amp;#39;어&amp;#39;, &amp;#39;ECD&amp;#39;), (&amp;#39;내&amp;#39;, &amp;#39;VX&amp;#39;), (&amp;#39;ᄅ&amp;#39;, &amp;#39;ETD&amp;#39;), (&amp;#39;수&amp;#39;, &amp;#39;NNB&amp;#39;), (&amp;#39;있&amp;#39;, &amp;#39;VV&amp;#39;), (&amp;#39;다&amp;#39;, &amp;#39;EFN&amp;#39;), (&amp;#39;.&amp;#39;, &amp;#39;SF&amp;#39;)]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h4 id="형태소-어휘-사전">형태소 어휘 사전&lt;/h4>
&lt;p>형태소 어휘 사전(Morpheme Vocabulary)는 자연어 처리에서 사용되는 단어 집합인 어휘 사전 중에서도 각 단어의 형태소 정보를 포함하는 사전을 말한다. &amp;ldquo;그녀&amp;rdquo;, &amp;ldquo;그녀는&amp;rdquo;, &amp;ldquo;그녀에게&amp;quot;를 모두 같은 의미 단위인 단어도 쉽게 학습할 수 있다.&lt;/p>
&lt;p>일반적으로 형태소 어휘 사전에는 각 형태소가 어떤 품사(Part Of Speech, POS)에 속하는지와 그 품사의 뜻에 대한 정보도 같이 제공된다. 품사를 태깅하는 작업은 품사 태깅(POS Tagging)이라고 한다. 이를 통해 문맥을 고려할 수 있어 더욱 정확한 분석이 가능하다.&lt;/p>
&lt;h3 id="하위-단어-토근화">하위 단어 토근화&lt;/h3>
&lt;p>언어는 시간이 지남에 따라 변화한다. 신조어나 축약어가 등장하거나 더 이상 쓰이지 않는 표현도 생긴다. 또한 디지털 시대에는 오탈자가 많아 기존 형태소 분석기로 토큰화하기 어려울 수 있다.&lt;/p>
&lt;p>형태소 분석기는 전문용어나 고유어에 취약하다. 즉, 형태소 분석기는 모르는 단어를 적절한 단어로 나누는 것에 취약하며, 이는 잠재적으로 어휘 사전의 크기를 크게 만들고 OOV(Out of Vocabulary)에 대응하기 어렵다.&lt;/p>
&lt;p>이를 해결하기 위한 방법 중 하나로 하위 단어 토큰화(Subword Tokenization)가 있다. 하위 단어 토큰화란 하나의 단어가 빈번하게 사용되는 하위 단어(Subword)의 조합으로 나누어 토큰화 하는 방법이다. 예를 들어 &amp;lsquo;Reinforcement&amp;rsquo;라는 단어는 길이가 비교적 길어 처리가 어려울 수 있다. 하위 단어 토큰화를 적용한다면 &amp;lsquo;Rein&amp;rsquo;, &amp;lsquo;force&amp;rsquo;, &amp;lsquo;ment&amp;rsquo; 등으로 나눠 처리할 수 있다.&lt;/p>
&lt;h4 id="바이트-페어-인코딩">바이트 페어 인코딩&lt;/h4>
&lt;p>바이트 페어 인코딩(Byte Pair Encoding, BPE)이란 다이그램 코딩(Digram Coding)이라고도 하며 하위 단어 토큰화의 한 종류다. 초기에는 데이터 압축을 위해 개발됐으나, 자연어 처리 분야에서 하위 단어 토큰화를 위한 방법으로 사용된다.&lt;/p>
&lt;p>빈도 사전 내 모든 단어를 글자 단위로 나누고, 가장 많이 등장한 글자 쌍을 병합하고 어휘 사전에 추가하는 과정 반복하여 사전을 구축한다.&lt;/p>
&lt;h4 id="센텐스피스">센텐스피스&lt;/h4>
&lt;p>구글에서 개발한 오픈소스 하위 단어 토크나이저 라이브러리로, 바이트 페어 인코딩과 유사한 알고리즘을 사용하였다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">sentencepiece&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">SentencePieceProcessor&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">tokenizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">SentencePieceProcessor&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">tokenizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;../models/petition_bpe.model&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">sentence&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;안녕하세요, 토크나이저가 잘 학습되었군요!&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">sentences&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;이렇게 입력값을 리스트로 받아서&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;쉽게 토크나이저를 사용할 수 있답니다&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">tokenized_sentence&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tokenizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">encode_as_pieces&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sentence&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">tokenized_sentences&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tokenizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">encode_as_pieces&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sentences&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;단일 문장 토큰화 :&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">tokenized_sentence&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;여러 문장 토큰화 :&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">tokenized_sentences&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">encoded_sentence&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tokenizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">encode_as_ids&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sentence&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">encoded_sentences&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tokenizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">encode_as_ids&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sentences&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;단일 문장 정수 인코딩 :&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">encoded_sentence&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;여러 문장 정수 인코딩 :&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">encoded_sentences&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">decode_ids&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tokenizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">decode_ids&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">encoded_sentences&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">decode_pieces&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tokenizer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">decode_pieces&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">encoded_sentences&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;정수 인코딩에서 문장 변환 :&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">decode_ids&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;하위 단어 토큰에서 문장 변환 :&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">decode_pieces&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">단일 문장 토큰화 : [&amp;#39;안녕하세요&amp;#39;, &amp;#39;,&amp;#39;, &amp;#39;토&amp;#39;, &amp;#39;크&amp;#39;, &amp;#39;나&amp;#39;, &amp;#39;이&amp;#39;, &amp;#39;저&amp;#39;, &amp;#39;가&amp;#39;, &amp;#39;잘&amp;#39;, &amp;#39;학&amp;#39;, &amp;#39;습&amp;#39;, &amp;#39;되었&amp;#39;, &amp;#39;군요&amp;#39;, &amp;#39;!&amp;#39;]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">여러 문장 토큰화 : [[&amp;#39;_이렇게&amp;#39;, &amp;#39;_입&amp;#39;, &amp;#39;력&amp;#39;, &amp;#39;값을&amp;#39;, &amp;#39;_리&amp;#39;, &amp;#39;_스트&amp;#39;, &amp;#39;로&amp;#39;, &amp;#39;_받아서&amp;#39;], [&amp;#39;_쉽게&amp;#39;, &amp;#39;_토&amp;#39;, &amp;#39;_크&amp;#39;, &amp;#39;_나&amp;#39;, &amp;#39;_이&amp;#39;, &amp;#39;_저&amp;#39;, &amp;#39;_를&amp;#39;, &amp;#39;_사용할&amp;#39;, &amp;#39;_수&amp;#39;, &amp;#39;_있&amp;#39;, &amp;#39;답니다&amp;#39;]]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">단일 문장 정수 인코딩 : [664, 6553, 991, 6880, 6544, 6513, 6590, 6523, 159, 110, 6554, 868, 782, 6648]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">여러 문장 정수 인코딩 : [[370, 180, 6677, 4427, 1768, 1610, 6527, 4157], [1677, 991, 6880, 6544, 6513, 6590, 6536, 5848, 18, 5, 2633]]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">정수 인코딩에서 문장 변환 : [&amp;#39;이렇게 입력값을 리스트로 받아서&amp;#39;, &amp;#39;쉽게 토크나이저를 사용할 수 있습니다&amp;#39;]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">하위 단어 토큰에서 문장 변환 : [&amp;#39;이렇게 입력값을 리스트로 받아서&amp;#39;, &amp;#39;쉽게 토크나이저를 사용할 수 있습니다&amp;#39;]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h4 id="워드피스">워드피스&lt;/h4>
&lt;p>워드피스(Wordpiece) 토크나이저는 확률 기반으로 글자 쌍을 병합한다. 새로운 하위 단어를 생성할 때 이전 하위 단어와 함께 나타날 확률을 계산해 가장 높은 확률을 가진 하위 단어를 선택한다. 각 글자 쌍에 대한 점수는 아래와 같이 계산된다. 여기서 $f$는 빈도(frequency)이다.&lt;/p>
&lt;p>$$
\text{score} = \frac{f(x,y)}{f(x), f(y)}
$$&lt;/p>
&lt;h4 id="토크나이저스">토크나이저스&lt;/h4>
&lt;p>토크나이저스 라이브러리는 정규화(Normalization)와 사전 토큰화(Pre-tokenization)를 제공한다.&lt;/p>
&lt;p>정규화는 일관된 형식으로 텍스트를 표준화하고 모호한 경우를 방지하기 위해 불필요한 공백 제거, 대소문자 변환, 유니코드 정규화, 구두점 처리, 특수 문자 처리 등을 제공한다.&lt;/p>
&lt;p>사전 토큰화는 입력 문장을 토큰화하기 전에 단어와 같은 작은 단위로 나누는 기능을 제공한다. 공백 혹은 구두점을 기준으로 입력 문장을 나눠 텍스트 데이터를 효율적으로 처리하고 모델의 성능을 향상시킬 수 있다.&lt;/p></description></item><item><title>Pre-trained 모델</title><link>https://gyeongmin.kr/p/pre-trained-model/</link><pubDate>Sun, 10 Mar 2024 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/pre-trained-model/</guid><description>&lt;img src="https://gyeongmin.kr/images/pytorch-transformer-nlp-computer-vision.png" alt="Featured image of post Pre-trained 모델" />&lt;h2 id="pre-trained-model">Pre-trained Model&lt;/h2>
&lt;p>사전 학습된 모델(Pre-trained Model)이란 대규모 데이터세트로 학습된 딥러닝 모델로, 이미 학습이 완료된 모델을 의미한다. 모델 자체를 현재 시스템에 적용하거나 사전 학습된 임베딩 벡터를 이용해 모델을 구성할 수 있다. Pre-trained 모델을 사용하면 처음부터 훈련시키는 게 아니므로 학습에 필요한 시간이 대폭 감소하며, 이미 다양한 작업에서 검증된 모델이기 때문에 안정적이고 우수한 성능을 기대할 수 있다.&lt;/p>
&lt;h3 id="backbone">Backbone&lt;/h3>
&lt;p>백본(Backbone)이란 입력 데이터에서 특징을 추출해 최종 분류기에 전달하는 딥러닝 모델이나 그 일부를 의미한다. 백본 네트워크는 입력 데이터에서 특징을 추출하므로 노이즈와 불필요한 특성을 제거하고 가장 중요한 특징을 추출할 수 있다. 이렇게 추출된 특징을 활용해 새로운 모델이나 기능의 입력으로 사용한다.&lt;/p>
&lt;p>포즈 추정 모델이나 이미지 분할 모델을 만들 땐, 객체를 검출하는 컨볼루젼 신경망의 특징값을 가져와 최종 레이어를 바꾸는 등의 방식으로 적용할 수 있다.&lt;/p>
&lt;p>백본을 쓴다고 성능이 급격하게 좋아지지는 않으며, 사전 학습된 백본은 쉽게 오버피팅될 수 있다. 미세 조정이나 전이 학습을 적용해 오버피팅을 피해야 한다.&lt;/p>
&lt;h3 id="transfer-learning">Transfer Learning&lt;/h3>
&lt;p>전이 학습(Transfer Learning)이란 어떤 작업을 수행하기 위해 이미 사전 학습된 모델을 재사용해 새로운 작업이나 관련 도메인의 성능을 향상시킬 수 있는 기술을 의미한다. 전이 학습은 대규모 데이터세트에서 사전 학습된 모델을 다른 작은 데이터세트로 미세 조정해 활용한다.&lt;/p>
&lt;p>소스 도메인에서 학습한 지식을 재사용함으로써 전이 학습된 모델이 더 적은 데이터와 학습 시간으로 더 높은 성능을 낼 수 있다. 또한 대규모 데이터세트에서 사전 학습된 모델을 활용하므로 과대적합 문제를 최소화할 수 있다.&lt;/p>
&lt;h4 id="upstream과-downstream">Upstream과 Downstream&lt;/h4>
&lt;p>전이 학습의 구조는 업스트림(Upstream) 모델과 다운스트림(Downstream) 모델로 나뉜다.&lt;/p>
&lt;ul>
&lt;li>업스트림 모델: 대규모 특정 도메인의 데이터세트에서 학습한 모델이다. 이 모델은 기본적인 특징을 학습하며, 새로운 작업에 필요한 지식을 제공한다.&lt;/li>
&lt;li>다운스트림 모델: 업스트림 모델에서 학습한 지식을 활용하여 새로운 작업이나 도메인의 데이터세트에서 학습하는 모델이다. 다운스트림 모델은 소규모 데이터세트에서 모델의 성능을 높이기 위해 미세 조정된다.&lt;/li>
&lt;/ul>
&lt;h4 id="inductive-transfer-learning">Inductive Transfer Learning&lt;/h4>
&lt;p>귀납적 전이 학습(Inductive Transfer Learning)은 기존의 모델이 학습한 지식을 새로운 작업에 적용하여 성능을 개선하는 방법이다.&lt;/p>
&lt;ul>
&lt;li>자기주도적 학습: 레이블이 없는 대규모 데이터에서 특징을 학습하고, 소량의 레이블 데이터를 이용해 미세 조정을 진행한다.&lt;/li>
&lt;li>다중 작업 학습: 소스 도메인과 타깃 도메인의 데이터를 기반으로 여러 작업을 동시에 학습하는 방법이다. 이 방식은 작업 간 상호작용을 통해 모델의 일반화를 돕는다.&lt;/li>
&lt;/ul>
&lt;h4 id="transductive-transfer-learning">Transductive Transfer Learning&lt;/h4>
&lt;p>변환적 전이 학습(Transductive Transfer Learning)은 소스 도메인과 타깃 도메인이 유사하지만 완전히 동일하지 않은 경우에 사용된다.&lt;/p>
&lt;ul>
&lt;li>도메인 적응: 두 도메인의 특징 분포 차이를 줄이는 방식으로 모델을 학습한다.&lt;/li>
&lt;li>표본 선택 편향/공변량 이동: 소스와 타깃 도메인의 데이터 분포 차이를 조정하여 전이를 진행한다.&lt;/li>
&lt;/ul>
&lt;h3 id="unsupervised-transfer-learning">Unsupervised Transfer Learning&lt;/h3>
&lt;p>비지도 전이 학습(Unsupervised Transfer Learning)은 소스와 타깃 도메인 모두에서 레이블이 없는 데이터를 사용하는 방법이다. GAN이나 군집화(Clustering) 기법을 통해 타깃 도메인에서의 성능을 개선한다.&lt;/p>
&lt;h4 id="zero-shot-transfer-learning">Zero-shot Transfer Learning&lt;/h4>
&lt;p>제로-샷 전이 학습은 사전 학습된 모델을 새로운 도메인에서도 바로 사용할 수 있도록 설계하는 방법이다. 학습하지 않은 데이터에도 일반화된 성능을 발휘하며, 데이터가 부족한 상황에서 유용하다.&lt;/p>
&lt;h4 id="one-shot-transfer-learning">One-shot Transfer Learning&lt;/h4>
&lt;p>원-샷 전이 학습은 클래스당 하나의 샘플만으로 모델을 학습하여 새로운 데이터를 분류하는 기법이다. 서포트 셋(Support Set)과 쿼리 셋(Query Set)을 활용해 분류를 진행하며, 적은 데이터로 높은 정확도를 달성할 수 있다.&lt;/p>
&lt;h3 id="feature-extraction">Feature Extraction&lt;/h3>
&lt;p>특징 추출(Feature Extraction)은 전이 학습에서 사전 학습된 모델의 계층을 활용하여 타깃 도메인의 데이터를 처리하는 방식이다. 이 방법은 소스 도메인과 타깃 도메인이 유사한 경우에 주로 사용된다.&lt;/p>
&lt;p>특징 추출 과정에서 사전 학습된 모델의 합성곱 계층(Convolutional Layers)과 같은 주요 계층은 동결(Freeze) 하여 학습하지 않는다. 대신, 이 계층에서 추출한 특징들을 기반으로 분류기(Classifier)만 재구성하고 학습한다.&lt;/p>
&lt;h3 id="fine-tuning">Fine-tuning&lt;/h3>
&lt;p>미세 조정은 사전 학습된 모델의 일부 계층 또는 전체 계층을 타깃 도메인의 데이터에 맞게 학습시키는 방식이다. 이 방법은 소스 도메인과 타깃 도메인이 유사하지 않거나, 타깃 도메인의 데이터세트가 충분히 크지 않은 경우에 사용된다.&lt;/p>
&lt;p>미세 조정에서는 특정 계층을 선택적으로 동결하거나, 동결을 해제하여 학습을 진행한다. 예를 들어, 하위 계층은 일반적으로 저수준 특징(예: 선, 모서리)을 학습하므로 그대로 사용하고, 상위 계층만 재학습하는 경우가 많다. 반면, 소스와 타깃 도메인의 차이가 크다면 전체 계층을 학습시키는 경우도 있다.&lt;/p></description></item><item><title>데이터 증강 및 변환</title><link>https://gyeongmin.kr/p/data-augmentation/</link><pubDate>Sat, 02 Mar 2024 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/data-augmentation/</guid><description>&lt;img src="https://gyeongmin.kr/images/pytorch-transformer-nlp-computer-vision.png" alt="Featured image of post 데이터 증강 및 변환" />&lt;h2 id="데이터-증강">데이터 증강&lt;/h2>
&lt;p>데이터 증강(Data Augmentation)이란 데이터가 가진 고유한 특징을 유지한 채 변형하거나 노이즈를 추가해 데이터세트의 크기를 늘리는 방법이다. 데이터 증강은 모델의 과대적합을 줄이고 일반화 능력을 향상시킬 수 있다.&lt;/p>
&lt;p>너무 많은 변형이나 노이즈를 추가한다면 기존 데이터가 가진 특징이 파괴될 수 있으므로 주의해야 한다.&lt;/p>
&lt;h2 id="텍스트-데이터">텍스트 데이터&lt;/h2>
&lt;h3 id="삽입-및-삭제">삽입 및 삭제&lt;/h3>
&lt;p>삽입은 의미 없는 문자나 단어, 또는 문장 의미에 영향을 끼치지 않는 수식어 등을 추가하는 방법이다. 임의의 단어나 문자를 기존 텍스트에 덧붙여 사용한다. 삭제는 삽입과 반대로 임의의 단어나 문자를 삭 제해 데이터의 특징을 유지하는 방법이다.&lt;/p>
&lt;p>&lt;code>ContextualWordEmbsAug&lt;/code> 클래스는 BERT 모델을 활용해 단어를 삽입하는 기능을 제공한다. &lt;code>action&lt;/code>으로는 &lt;code>insert&lt;/code>, &lt;code>substitute&lt;/code>, &lt;code>swap&lt;/code>, &lt;code>delete&lt;/code>가 가능하다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">nlpaug.augmenter.word&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">naw&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">texts&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;Those who can imagine anything, can create the impossible.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;We can only see a short distance ahead, but we can see plenty there that needs to be done.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;If a machine is expected to be infallible, it cannot also be intelligent.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">aug&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">naw&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ContextualWordEmbsAug&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model_path&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;bert-base-uncased&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">action&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;insert&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">augmented_texts&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">aug&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">augment&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">texts&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">augmented&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">zip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">texts&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">augmented_texts&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;src : &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;dst : &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">augmented&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;------------------&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">src: Those who can imagine anything, can create the impossible.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">dst: those scientists who can simply imagine seemingly anything, can create precisely the impossible.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">------------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">src : We can only see a short distance ahead, but we can see plenty there that needs to be done.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">dst : we probably can still only see a short distance ahead, but we can nonetheless see about plenty from there that just needs to be properly done.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">------------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">src : If a machine is expected to be infallible, it cannot also be intelligent.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">dst : if a logic machine is expected either to necessarily be infallible, subsequently it cannot also be highly intelligent.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="교체-및-대체">교체 및 대체&lt;/h3>
&lt;p>교체는 단어나 문자의 위치를 교환하는 방법이다. ‘문제점을 찾지 말고 해결책을 찾으라’라는 문장에서 교체를 적용한다면 &amp;lsquo;해결책을 찾으라 문제점을 찾지 말고&amp;rsquo;로 변경될 수 있다.
교체는 무의미하거나 의미상 잘못된 문장을 생성할 수 있으므로 데이터의 특성에 따라 주의해 사용해야 한다.&lt;/p>
&lt;p>대체는 단어나 문자를 임의의 단어나 문자로 바꾸거나 동의어로 변경하는 방법을 의미한다. ‘사과’라는 단어를 ‘바나나’와 같이 유사한 단어로 변경하거나 ‘해’를 ‘태양으로 바꿔 뜻이 같은 말로 바꾸는 작업이
다. 단어나 문장을 대체하면 다른 증강 방법보다 비교적 데이터의 정합성(Consistency)이 어긋나지 않아 효율적으로 데이터를 증강할 수 있다. 하지만 조사를 바꿔주진 않는다.&lt;/p>
&lt;p>&lt;code>RandomWordAug&lt;/code> 클래스를 통해 무작위로 단어를 교체할 수 있다. &lt;code>action&lt;/code>으로는 &lt;code>insert&lt;/code>, &lt;code>substitute&lt;/code>, &lt;code>swap&lt;/code>, &lt;code>delete&lt;/code>, &lt;code>crop&lt;/code>이 가능하다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">nlpaug.augmenter.word&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">naw&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">texts&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;Those who can imagine anything, can create the impossible.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;We can only see a short distance ahead, but we can see plenty there that needs to be done.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;If a machine is expected to be infallible, it cannot also be intelligent.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">aug&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">naw&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomWordAug&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">action&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;swap&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">augmented_texts&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">aug&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">augment&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">texts&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">augmented&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">zip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">texts&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">augmented_texts&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;src : &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;dst : &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">augmented&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;------------------&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">src : Those who can imagine anything, can create the impossible.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">dst : Those who can imagine can anything create, the. impossible
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">------------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">src : We can only see a short distance ahead, but we can see plenty there that needs to be done.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">dst : We see can only a short distance but ahead, can we see plenty that there needs to done be.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">------------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">src : If a machine is expected to be infallible, it cannot also be intelligent.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">dst : A if is machine to expected be infallible, cannot also it be intelligent.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">------------------
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>모델을 활용해 대체하는 경우 &lt;code>ContextualWordEmbsAug&lt;/code> 클래스를 사용하거나, &lt;code>SynonymAug&lt;/code> 클래스로 워드넷(WordNet) 데이터베이스나 의역 데이터베이스(The Paraphrase Database, PPDB)를 활용해 단어를 대체해 데이터를 증강할 수도 있다.&lt;/p>
&lt;p>단어 집합을 미리 선언하고 그 중 하나로 대체하고 싶은 경우, &lt;code>ReservedAug&lt;/code>를 사용할 수도 있다.&lt;/p>
&lt;h3 id="역번역">역번역&lt;/h3>
&lt;p>역번역(Back-translation)이란 입력 텍스트를 특정 언어로 번역한 다음 다시 본래의 언어로 번역하는 방법을 의미한다. 예를 들어 영어를 한국어로 번역한 다음 번역된 텍스트를 다시 영어로 번역하는 과정을 의미한다. 원래의 언어로 번역하는 과정에서 원래 텍스트와 유사한 텍스트가 생성되므로 패러프레이징(Paraphrasing)21 효과를 얻을 수 있다.&lt;/p>
&lt;p>역번역은 번역 모델의 성능에 크게 좌우되기에, 모델의 성능을 평가하는 데 사용되기도 한다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">nlpaug.augmenter.word&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">naw&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">texts&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;Those who can imagine anything, can create the impossible.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;We can only see a short distance ahead, but we can see plenty there that needs to be done.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;If a machine is expected to be infallible, it cannot also be intelligent.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">back_translation&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">naw&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BackTranslationAug&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">from_model_name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;facebook/wmt19-en-de&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">to_model_name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;facebook/wmt19-de-en&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">augmented_texts&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">back_translation&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">augment&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">texts&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">augmented&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">zip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">texts&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">augmented_texts&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;src : &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;dst : &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">augmented&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;------------------&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">src : Those who can imagine anything, can create the impossible.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">dst : Anyone who can imagine anything can achieve the impossible.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">------------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">src : We can only see a short distance ahead, but we can see plenty there that needs to be done.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">dst : We can only look a little ahead, but we can see a lot there that needs to be done.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">------------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">src : If a machine is expected to be infallible, it cannot also be intelligent.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">dst : If a machine is expected to be infallible, it cannot be intelligent.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">------------------
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="이미지-데이터">이미지 데이터&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="n">transform&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Compose&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Resize&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">512&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">512&lt;/span>&lt;span class="p">)),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ToTensor&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>이미지 데이터는 토치비전의 transforms 모듈을 이용하여 증강할 수 있다. 텐서화 클래스(transforms.ToTensor)는 &lt;code>PIL.Image&lt;/code> 형식을 Tensor 형식으로 변환한다. 텐서화 클래스는 [0~255] 범위의 픽셀값을 [0.0~1.0] 사이의 값으로 최대 최소 정규화를 수행한다. 또한 입력 데이터의 형태를 [채널, 높이, 너비] 형태로 변환한다.&lt;/p>
&lt;h3 id="회전-및-대칭">회전 및 대칭&lt;/h3>
&lt;p>학습 이미지를 회전하거나 대칭한다면 변형된 이미지가 들어오더라도 더 강건한 모델을 구축할 수 있으며 일반화된 성능을 끌어낼 수 있다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="n">transform&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Compose&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomRotation&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">degrees&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">expand&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">center&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">None&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomHorizontalFlip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.5&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomVerticalFlip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.5&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>위 코드는 이미지를 ±30° 사이로 회전시키면서, 수평 대칭과 수직 대칭을 50% 확률로 적용하는 예제이다. &lt;code>expand=True&lt;/code>이면 확장되어 여백이 생기지 않는다. 중심점을 입력하지 않으면 좌측 상단을 기준으로 회전한다.&lt;/p>
&lt;h3 id="자르기-및-패딩">자르기 및 패딩&lt;/h3>
&lt;p>OD(Object Detection)과 같은 모델을 구성할 때, 학습 데이터의 크기가 일정하지 않거나 주요한 객체가 일부 영역에만 작게 존재할 수 있다. 이러한 경우 불필요한 부분을 자르거나, 패딩을 주어 크기를 맞출 수 있다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="n">transform&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Compose&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomCrop&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">512&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">512&lt;/span>&lt;span class="p">)),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Pad&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">padding&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">50&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fill&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">127&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">127&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">255&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">padding_mode&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;constant&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;code>padding_mode&lt;/code>가 &lt;code>constant&lt;/code>면 &lt;code>fill=(127, 127, 255)&lt;/code>로 테두리가 생성된다. &lt;code>reflect&lt;/code>나 &lt;code>symmetric&lt;/code>이라면 입력한 RGB는 무시되며, 이미지의 픽셀값을 이용하여 생성한다. &lt;code>RandomCrop&lt;/code>에도 자를 때 발생하는 여백 공간에 대한 패딩을 줄 수 있다.&lt;/p>
&lt;h3 id="크기-조정">크기 조정&lt;/h3>
&lt;p>이미지 처리 모델 학습을 위해, 학습 데이터에 사용되는 이미지의 크기는 모두 일정해야 한다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="n">transform&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Compose&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Resize&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">512&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">512&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;code>size&lt;/code>를 정수로 입력하는 경우, 높이나 너비 중 더 작은 값에 비율을 맞추어 크기가 수정된다.&lt;/p>
&lt;h3 id="변형">변형&lt;/h3>
&lt;p>아핀 변환(Affine Transformation)이나 원근(Perspective Transformation) 변환과 같은 기하학적 변환을 사용한다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="n">transform&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Compose&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomAffine&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">degrees&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">translate&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mf">0.2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.2&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">scale&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mf">0.8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">1.2&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">shear&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">15&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>아핀 변환은 각도(degrees), 이동(translate), 척도(scale), 전단(shear)을 입력해 이미지를 변형한다.&lt;/p>
&lt;h3 id="색상-변환">색상 변환&lt;/h3>
&lt;p>이미지 데이터의 특징은 픽셀값의 분포나 패턴에 크게 좌우되는데, 앞선 변형들은 색상을 변경하진 않는다. 특정 색상에 편향되지 않도록 정규화하면 모델을 더 일반화시킬 수 있다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="n">transform&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Compose&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ColorJitter&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">brightness&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">contrast&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.3&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">saturation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">hue&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.3&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ToTensor&lt;/span>&lt;span class="p">(),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Normalize&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">mean&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">0.485&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.456&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.406&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">std&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mf">0.229&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.224&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.225&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ToPILImage&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="노이즈">노이즈&lt;/h3>
&lt;p>특정 픽셀값에 편향되지 않도록, 임의의 노이즈를 추가하는 것은 좋은 방법이다. 학습에 사용되지 않더라도, 테스트 데이터에 노이즈를 주어 Robustness를 평가하는 데 사용하기도 한다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">IaaTransforms&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">seq&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">iaa&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Sequential&lt;/span>&lt;span class="p">([&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">iaa&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SaltAndPepper&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mf">0.03&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.07&lt;/span>&lt;span class="p">)),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">iaa&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Rain&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">speed&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mf">0.3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.7&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__call__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">images&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">images&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">images&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">images&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">images&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dtype&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">augmented&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">seq&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">augment_image&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">images&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">Image&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">fromarray&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">augmented&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">transform&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Compose&lt;/span>&lt;span class="p">([&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">IaaTransforms&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="컷아웃-및-무작위-지우기">컷아웃 및 무작위 지우기&lt;/h3>
&lt;p>컷아웃은 임의의 ROI의 픽셀값을 0으로 채우는 것이고, 무작위 지우기는 랜덤 픽셀값으로 채우는 것이다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="n">transform&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Compose&lt;/span>&lt;span class="p">([&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ToTensor&lt;/span>&lt;span class="p">(),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomErasing&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">1.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">value&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomErasing&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">1.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">value&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;random&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">transforms&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ToPILImage&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>일부 영역이 누락되거나, 폐색 영역에 대해 모델을 더욱 견고하게 만들어준다.&lt;/p>
&lt;h3 id="컷믹스">컷믹스&lt;/h3>
&lt;p>컷믹스(CutMix)는 이미지 패치 영역에 다른 이미지를 덮어씌우는 방법이다. 패치 위에 새로운 패치를 덮어씌워 자연스러운 이미지를 구성한다. 패치 영역의 크기와 비율을 고려해 덮어쓴다.&lt;/p>
&lt;p>Label($y$)은 이미지가 얼마나 기여하였는지($\lambda$)를 이용하여 아래 공식과 같이 계산된다.&lt;/p>
&lt;p>$$
\tilde{y}=\lambda y_a + (1-\lambda)y_b
$$&lt;/p></description></item><item><title>정칙화</title><link>https://gyeongmin.kr/p/regularization/</link><pubDate>Mon, 26 Feb 2024 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/regularization/</guid><description>&lt;img src="https://gyeongmin.kr/images/pytorch-transformer-nlp-computer-vision.png" alt="Featured image of post 정칙화" />&lt;h2 id="정칙화regularization">정칙화(Regularization)&lt;/h2>
&lt;p>머신러닝과 딥러닝 모델을 학습시킬 때, 오버피팅은 모델이 훈련 데이터에 지나치게 적합되어 새로운 데이터에 대한 예측 성능이 저하되는 오버피팅(overfitting) 문제는 흔히 접해보았을 것이다. 이러한 문제를 해결하기 위해 사용되는 기술이 바로 정칙화(Regularization)이다.&lt;/p>
&lt;p>정칙화는 모델이 암기(Memorization)가 아니라 일반화(Generalization)할 수 있도록 손실 함수에 규제(Penalty)를 가하는 방식이다.&lt;/p>
&lt;p>정칙화를 적용하면 학습 데이터들이 갖고 있는 작은 차이점에 대해 덜 민감해져 모델의 분산 값이 낮아진다. 그러므로 정칙화는 모델이 데이터를 학습할 때 의존하는 특징의 수를 줄임으로써 모델의 추론 능
력을 개선한다.&lt;/p>
&lt;h2 id="오버피팅과-일반화">오버피팅과 일반화&lt;/h2>
&lt;p>&lt;img src="https://gyeongmin.kr/p/regularization/image.png"
width="1400"
height="609"
srcset="https://gyeongmin.kr/p/regularization/image_hu66396dc1fab62456da9622b86cbec07b_591451_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/regularization/image_hu66396dc1fab62456da9622b86cbec07b_591451_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Example of underfitting and overfitting"
class="gallery-image"
data-flex-grow="229"
data-flex-basis="551px"
>&lt;/p>
&lt;p>오버피팅은 모델이 훈련 데이터의 노이즈나 특정 패턴을 학습하여, 실제 데이터의 일반적인 패턴을 파악하지 못할 때 발생한다. 이로 인해 모델은 훈련 데이터에서는 높은 성능을 보이지만, 새로운 데이터에서는 성능이 급격히 떨어진다. 반면, 일반화는 모델이 새로운 데이터에서도 정확한 예측을 수행할 수 있는 능력을 의미한다.&lt;/p>
&lt;p>즉, 모델이 데이터의 일반적인 패턴을 학습하여 노이즈에 의존하지 않고, 다양한 데이터에 대해 일관된 성능을 유지하는 것이다.&lt;/p>
&lt;h2 id="정칙화의-종류">정칙화의 종류&lt;/h2>
&lt;h3 id="l1-정칙화">L1 정칙화&lt;/h3>
&lt;p>L1 정칙화는 라쏘 정칙화(Lasso Regularization)라고도 불리며, 가중치의 절댓값 합을 손실 함수에 추가하여 오버피팅을 방지한다.&lt;/p>
&lt;p>이 방식은 모델이 불필요한 피처의 가중치를 0으로 수렴시키는 특징이 있어, 자동으로 특징 선택(feature selection)의 효과를 제공한다. 그러나 L1 정칙화는 하이퍼파라미터인 규제 강도(lambda)를 적절히 조절해야 하며, 과도한 규제는 정보의 손실을 초래할 수 있다. 주로 선형 회귀 모델에서 활용되며, 계산 복잡도가 다소 높을 수 있다는 단점이 있다.&lt;/p>
&lt;p>$$
\text{Loss}&lt;em>\text{L1} = \text{Loss}&lt;/em>{\text{original}} + \lambda \sum_{i=1}^{n} |w_i|
$$&lt;/p>
&lt;ul>
&lt;li>$ \text{Loss}_{L1} $: L1 정칙화가 적용된 전체 손실 함수&lt;/li>
&lt;li>$ \text{Loss}_{\text{original}} $: 원래의 손실 함수 (ex. 평균 제곱 오차)&lt;/li>
&lt;li>$ \lambda $: 규제 강도 하이퍼파라미터&lt;/li>
&lt;li>$ w_i $: 각 가중치 파라미터&lt;/li>
&lt;li>$ n $: 가중치의 총 개수&lt;/li>
&lt;/ul>
&lt;h3 id="l2-정칙화">L2 정칙화&lt;/h3>
&lt;p>L2 정칙화는 릿지 정칙화(Ridge Regularization)라고도 하며, 가중치 제곱의 합을 손실 함수에 추가하여 오버피팅을 방지한다.&lt;/p>
&lt;p>L2 정칙화는 가중치를 0에 가깝게 유지하므로, 모델의 가중치가 균일하게 분포되도록 도와준다. 이는 모델의 복잡도를 조정하여 일반화 성능을 향상시키는 데 기여한다. L1 정칙화와 달리, L2 정칙화는 모든 가중치를 조금씩 줄이는 경향이 있어, 희소성을 제공하지 않는다. 주로 심층 신경망 모델에서 많이 사용되며, 하이퍼파라미터 조정이 필요하다.&lt;/p>
&lt;p>$$
\text{Loss}&lt;em>\text{L2} = \text{Loss}&lt;/em>{\text{original}} + \lambda \sum_{i=1}^{n} w_i^2
$$&lt;/p>
&lt;ul>
&lt;li>$ \text{Loss}_{L2} $: L2 정칙화가 적용된 전체 손실 함수&lt;/li>
&lt;/ul>
&lt;h3 id="가중치-감쇠">가중치 감쇠&lt;/h3>
&lt;p>가중치 감쇠는 L2 정칙화와 유사하게, 손실 함수에 규제 항을 추가하여 모델의 가중치를 작게 유지하는 기법이다.&lt;/p>
&lt;p>딥러닝 라이브러리에서는 종종 최적화 함수에 weight_decay 파라미터로 구현되며, L2 정칙화와 동일한 효과를 가진다. 가중치 감쇠는 모델의 일반화 성능을 향상시키기 위해 사용되며, 다른 정칙화 기법과 함께 적용할 때 더욱 효과적일 수 있다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SGD&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parametersO&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.01&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">weight_decay&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.01&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="엘라스틱-넷">엘라스틱 넷&lt;/h3>
&lt;p>엘라스틱 넷(Elastic-Net)은 L1 정칙화와 L2 정칙화를 결합한 방식으로, 두 정칙화의 장점을 동시에 활용한다.&lt;/p>
&lt;p>이는 모델이 희소성과 작은 가중치의 균형을 맞추도록 도와주며, 특히 피처의 수가 샘플의 수보다 많을 때 유의미한 성능 향상을 제공한다. 혼합 비율을 조절하여 두 정칙화의 영향을 조절할 수 있으나, 새로운 하이퍼파라미터가 추가되므로 튜닝이 필요하다.&lt;/p>
&lt;p>$$
\text{Loss}&lt;em>\text{ElasticNet} = \text{Loss}&lt;/em>{\text{original}} + \lambda_1 \sum_{i=1}^{n} |w_i| + \lambda_2 \sum_{i=1}^{n} w_i^2
$$&lt;/p>
&lt;ul>
&lt;li>$ \lambda_1 $: L1 정칙화의 규제 강도&lt;/li>
&lt;li>$ \lambda_2 $: L2 정칙화의 규제 강도&lt;/li>
&lt;/ul>
&lt;h3 id="드롭아웃">드롭아웃&lt;/h3>
&lt;p>&lt;img src="https://gyeongmin.kr/p/regularization/image-1.png"
width="848"
height="462"
srcset="https://gyeongmin.kr/p/regularization/image-1_hu1d510e10439ac30aa1a3a4f0b21d87ec_84154_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/regularization/image-1_hu1d510e10439ac30aa1a3a4f0b21d87ec_84154_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Dropout before/after"
class="gallery-image"
data-flex-grow="183"
data-flex-basis="440px"
>&lt;/p>
&lt;p>드롭아웃(Dropout)은 신경망의 훈련 과정에서 일부 노드를 임의로 제거하거나 0으로 설정하여 오버피팅을 방지하는 기법이다.&lt;/p>
&lt;p>이는 노드 간의 동조화(co-adaptation)를 억제하여 모델이 특정 노드에 지나치게 의존하지 않도록 한다. 드롭아웃은 모델의 일반화 성능을 향상시키는 동시에 모델 평균화 효과를 제공하지만, 충분한 데이터와 깊은 모델에 적용할 때 더욱 효과적이다. 배치 정규화와 함께 사용할 때는 신중하게 조합해야 한다.&lt;/p>
&lt;p>$$
y = \begin{cases}
0 &amp;amp; \text{with probability } p \
\frac{y}{1-p} &amp;amp; \text{with probability } 1-p
\end{cases}
$$&lt;/p>
&lt;ul>
&lt;li>$ y $: 뉴런의 출력값&lt;/li>
&lt;li>$ p $: 뉴런을 제거할 확률 (드롭아웃 비율)&lt;/li>
&lt;li>$ 1-p $: 뉴런을 유지할 확률&lt;/li>
&lt;li>출력값을 $ \frac{1}{1-p} $로 스케일링하여 훈련 시와 추론 시의 활성화 분포를 일치&lt;/li>
&lt;/ul>
&lt;h3 id="그레이디언트-클리핑">그레이디언트 클리핑&lt;/h3>
&lt;p>그레이디언트 클리핑(Gradient Clipping)은 모델 학습 시 기울기가 너무 커지는 현상을 방지하기 위해 사용되는 기법이다.&lt;/p>
&lt;p>이는 기울기의 크기를 특정 임곗값으로 제한하여, 학습 과정에서 발생할 수 있는 기울기 폭주 문제를 해결한다. 주로 순환 신경망(RNN)이나 LSTM 모델에서 활용되며, 학습률을 조절하는 효과와 유사한 역할을 한다. 그레이디언트 클리핑은 하이퍼파라미터인 최대 임곗값을 신중하게 설정해야 하며, 이를 통해 모델의 안정적인 학습을 도모할 수 있다.&lt;/p>
&lt;p>$$
\text{if } ||g||_2 &amp;gt; r, \quad g \leftarrow \frac{g}{||g||_2} \times r
$$&lt;/p>
&lt;ul>
&lt;li>$ g $: 기울기 벡터&lt;/li>
&lt;li>$ ||g||_2 $: 기울기 벡터의 L2 노름&lt;/li>
&lt;li>$ r $: 설정한 임계값 (threshold)&lt;/li>
&lt;li>기울기의 방향은 유지하면서 크기를 $ r $로 제한&lt;/li>
&lt;/ul></description></item><item><title>활성화 함수</title><link>https://gyeongmin.kr/p/activation-functions/</link><pubDate>Wed, 14 Feb 2024 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/activation-functions/</guid><description>&lt;img src="https://gyeongmin.kr/images/pytorch-transformer-nlp-computer-vision.png" alt="Featured image of post 활성화 함수" />&lt;h2 id="활성화-함수">활성화 함수&lt;/h2>
&lt;p>활성화 함수는 인공 신경망에서 뉴런의 출력을 비선형으로 변환하여 은닉층을 활성화하는 역할을 한다. 이를 통해 네트워크는 데이터의 복잡한 패턴을 학습하고 비선형 문제를 해결할 수 있다.&lt;/p>
&lt;p>각 노드의 전달 보강이 다르므로 입력값에 따라 일부 노드는 활성화(Activate)되고 다른 노드는 비활성화(Deactivate)된다.&lt;/p>
&lt;p>활성화 함수는 비선형 구조를 가지며 미분 가능해야 학습이 가능하고, 입력값을 정규화(Normalization)하는 효과도 수행한다.&lt;/p>
&lt;h2 id="계단-함수-step-function">계단 함수 (Step Function)&lt;/h2>
&lt;p>계단 함수는 입력값이 특정 임곗값(보통 0)을 넘으면 1을 출력하고, 그렇지 않으면 0을 출력하는 함수이다.&lt;/p>
&lt;p>이 함수는 출력이 이산적이므로 단순한 분류 작업에 사용될 수 있지만, 비연속적인 특성으로 인해 기울기(Gradient)가 존재하지 않아 역전파(Backpropagation)를 사용할 수 없다.&lt;/p>
&lt;p>$$
f(x) =
\begin{cases}
1 &amp;amp; \text{if } x \geq 0 \
0 &amp;amp; \text{if } x &amp;lt; 0
\end{cases}
$$&lt;/p>
&lt;pre class="mermaid">xychart-beta
title "Step Function"
y-axis 0 --> 1
x-axis [-4, -3, -2, -1, 0, 0, 1, 2, 3, 4]
line [ 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]
&lt;/pre>
&lt;h2 id="임곗값-함수-threshold-function">임곗값 함수 (Threshold Function)&lt;/h2>
&lt;p>임곗값 함수는 계단 함수의 변형으로 특정 임계값을 기준으로 값을 출력한다. 입력값이 임계값 이상이면 1을 출력하고, 그 미만이면 특정 값을 출력한다.&lt;/p>
&lt;p>이 함수는 이진 분류에 사용될 수 있으나, 계단 함수와 마찬가지로 기울기가 없어서 신경망 학습에는 적합하지 않다.&lt;/p>
&lt;p>$$
f(x) =
\begin{cases}
x &amp;amp; \text{if } x &amp;gt; threshold \
value &amp;amp; \text{else } \ \ \ otherwise
\end{cases}
$$&lt;/p>
&lt;pre class="mermaid">xychart-beta
title "Threshold Function (value = -5)"
y-axis -5 --> 4
x-axis [-4, -3, -2, -1, 0, 0, 1, 2, 3, 4]
line [-5, -5, -5, -5, -5, 0, 1, 2, 3, 4]
&lt;/pre>
&lt;h2 id="시그모이드-함수-sigmoid-function">시그모이드 함수 (Sigmoid Function)&lt;/h2>
&lt;p>시그모이드 함수는 입력값을 0과 1 사이의 연속적인 값으로 변환하는 함수로, 출력값을 확률로 해석할 수 있어 이진 분류 문제에서 사용된다.&lt;/p>
&lt;p>함수의 출력이 부드럽게 변하므로 미분이 가능하지만, 큰 입력값에서는 기울기가 0에 가까워지는 &lt;strong>Vanishing Gradient&lt;/strong> 문제가 발생할 수 있어 깊은 신경망에서는 성능이 저하될 수 있다.&lt;/p>
&lt;p>$$
f(x) = \frac{1}{1 + e^{-x}}
$$&lt;/p>
&lt;pre class="mermaid">xychart-beta
title "Sigmoid Function"
y-axis 0 --> 1
x-axis [-5, -4.5, -4, -3.5, -3, -2.5, -2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5]
line [0.0067, 0.011, 0.018, 0.029, 0.047, 0.076, 0.119, 0.182, 0.269, 0.378, 0.5, 0.622, 0.731, 0.818, 0.881, 0.924, 0.953, 0.971, 0.982, 0.989, 0.993]
&lt;/pre>
&lt;h2 id="하이퍼볼릭-탄젠트-함수-tanh-function">하이퍼볼릭 탄젠트 함수 (Tanh Function)&lt;/h2>
&lt;p>하이퍼볼릭탄젠트 함수는 시그모이드 함수의 확장판으로, 출력 범위가 -1에서 1 사이로 설정되어 있다.&lt;/p>
&lt;p>이 함수는 평균이 0에 가까워져 학습이 비교적 안정적이며, 시그모이드 함수보다 빠르게 수렴할 수 있다. 그러나 여전히 큰 입력값에서는 기울기가 0에 가까워지는 문제를 완전히 해결하지는 못한다.&lt;/p>
&lt;p>$$
f(x) = \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}
$$&lt;/p>
&lt;pre class="mermaid">xychart-beta
title "Tanh Function"
y-axis -1 --> 1
x-axis [-5, -4.5, -4, -3.5, -3, -2.5, -2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5]
line [-1, -0.999, -0.999, -0.998, -0.995, -0.986, -0.964, -0.905, -0.761, -0.462, 0, 0.462, 0.761, 0.905, 0.964, 0.986, 0.995, 0.998, 0.999, 0.999, 1]
&lt;/pre>
&lt;h2 id="relu-함수-rectified-linear-unit-function">ReLU 함수 (Rectified Linear Unit Function)&lt;/h2>
&lt;p>ReLU(Rectified Linear Unit) 함수는 입력값이 0 이하이면 0을 출력하고, 그 이상이면 입력값을 그대로 출력하는 함수이다.&lt;/p>
&lt;p>간단한 수식과 계산량 덕분에 학습 속도가 빠르고 효율적이지만, 0 이하의 값에서는 기울기가 0이 되어 뉴런이 더 이상 업데이트되지 않는 죽은 뉴런 문제가 발생할 수 있다.&lt;/p>
&lt;p>$$
f(x) = \max(0, x)
$$&lt;/p>
&lt;pre class="mermaid">xychart-beta
title "ReLU Function"
y-axis -0.5 --> 3
x-axis [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5]
line [0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5]
&lt;/pre>
&lt;h2 id="leaky-relu-함수">Leaky ReLU 함수&lt;/h2>
&lt;p>Leaky ReLU 함수는 ReLU 함수의 단점을 개선한 형태로, 입력값이 0 이하일 때도 작은 기울기
α를 곱한 값을 출력한다. 이로 인해 죽은 뉴런 문제를 완화하며 학습이 계속 이루어질 수 있도록 한다.&lt;/p>
&lt;p>기울기 α는 보통 0.01과 같은 작은 값으로 설정되며, ReLU의 비선형성과 계산 효율성을 유지한다.&lt;/p>
&lt;p>$$
f(x) =
\begin{cases}
x &amp;amp; \text{if } x &amp;gt; 0 \
\alpha x &amp;amp; \text{if } x \leq 0
\end{cases}
$$&lt;/p>
&lt;pre class="mermaid">xychart-beta
title "Leaky ReLU Function (α = 0.1)"
y-axis -1 --> 5
x-axis [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5]
line [-0.5, -0.4, -0.3, -0.2, -0.1, 0, 1, 2, 3, 4, 5]
&lt;/pre>
&lt;h2 id="prelu-함수-parametric-relu-function">PReLU 함수 (Parametric ReLU Function)&lt;/h2>
&lt;p>PReLU(Parametric ReLU) 함수는 Leaky ReLU의 확장판으로, 0 이하의 기울기 α를 고정된 값이 아닌 학습 가능한 파라미터로 설정한다.&lt;/p>
&lt;p>이로 인해 데이터에 따라 기울기를 최적화할 수 있으므로 네트워크의 성능을 더욱 개선할 수 있다. 다만 학습할 파라미터가 늘어나기 때문에 계산 비용이 조금 증가할 수 있다.&lt;/p>
&lt;h2 id="elu-함수-exponential-linear-unit-function">ELU 함수 (Exponential Linear Unit Function)&lt;/h2>
&lt;p>ELU(Exponential Linear Unit) 함수는 ReLU와 Leaky ReLU의 단점을 보완한 함수로, 입력값이 0 이하일 때 $ e^x - 1 $ 형태의 부드러운 곡선을 갖는다.&lt;/p>
&lt;p>ELU는 0 이하의 출력이 음수 값을 가지기 때문에 평균 출력이 0에 가깝게 유지되어 학습을 더 안정적으로 만들며, 죽은 뉴런 문제도 해결할 수 있다.&lt;/p>
&lt;p>$$
ELU(x) =
\begin{cases}
x &amp;amp; \text{if } x &amp;gt; 0 \
\alpha (e^x - 1) &amp;amp; \text{else } \text{otherwise}
\end{cases}
$$&lt;/p>
&lt;pre class="mermaid">xychart-beta
title "ELU Function (α = 1)"
y-axis -3 --> 5
x-axis [-4, -3.6, -3.2, -2.8, -2.4, -2, -1.6, -1.2, -0.8, -0.4, 0, 0.4, 0.8, 1.2, 1.6, 2, 2.4, 2.8, 3.2, 3.6, 4]
line [-0.9817, -0.9736, -0.9502, -0.9131, -0.8647, -0.7869, -0.6988, -0.6065, -0.4866, -0.3297, 0, 0.4, 0.8, 1.2, 1.6, 2, 2.4, 2.8, 3.2, 3.6, 4]
&lt;/pre>
&lt;h2 id="소프트맥스-함수-softmax-function">소프트맥스 함수 (Softmax Function)&lt;/h2>
&lt;p>소프트맥스 함수는 다중 클래스 분류에서 사용되는 함수로, 입력값을 확률 분포로 변환한다. 각 클래스의 출력값에 대해 지수 함수로 변환한 후, 전체 클래스의 지수값 합으로 나눈다.&lt;/p>
&lt;p>이로 인해 출력값의 합이 항상 1이 되며, 이를 통해 각 클래스에 대한 확률로 해석할 수 있다. 소프트맥스 함수는 주로 신경망의 출력층에서 사용된다.&lt;/p>
&lt;p>$$
p_k = \frac{e^{z_k}}{\sum_{i=1}^n e^{z_i}}
$$&lt;/p></description></item><item><title>최적화 함수의 종류와 발전 과정</title><link>https://gyeongmin.kr/p/optimization-functions/</link><pubDate>Fri, 09 Feb 2024 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/optimization-functions/</guid><description>&lt;img src="https://gyeongmin.kr/images/pytorch-transformer-nlp-computer-vision.png" alt="Featured image of post 최적화 함수의 종류와 발전 과정" />&lt;h2 id="최적화-함수란">최적화 함수란?&lt;/h2>
&lt;p>신경망(neural network)의 학습 목적은 손실 함수(loss function)의 값을 최대한 낮추는 매개변수(parameter)를 찾는 것이다. 이는 곧 매개변수의 최적값을 찾는 문제이며, 이를 최적화 문제(optimization)라고 한다. 최적화 문제를 해결하기 위해 사용하는 도구가 바로 최적화 함수(optimizer)이다.&lt;/p>
&lt;p>최적화 함수는 손실 함수의 값을 최소화하는 방향으로 모델의 매개변수를 조정한다. 손실 함수는 예측값(predicted value)과 실제값(true value) 간의 차이를 나타내며, 최적화 함수는 손실을 점진적으로 줄여 모델의 예측 성능을 향상시킨다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/optimization-functions/image.png"
width="3193"
height="1536"
srcset="https://gyeongmin.kr/p/optimization-functions/image_hu0eebc20c8c24827b2e90536cf3d5f782_408890_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/optimization-functions/image_hu0eebc20c8c24827b2e90536cf3d5f782_408890_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="saddle point and local minima"
class="gallery-image"
data-flex-grow="207"
data-flex-basis="498px"
>&lt;/p>
&lt;p>최적화 함수는 기울기(gradient)를 활용하여 손실 함수의 값을 낮추는 방향으로 매개변수를 조정한다. 기울기는 각 지점에서 함수의 값을 줄이는 방향을 나타내는 지표로, 손실 값을 줄이기 위한 업데이트의 핵심 정보를 제공한다. 그러나 딥러닝에서 사용하는 손실 함수는 고차원적이고 복잡한 지형을 가지기 때문에, 기울기가 항상 최적의 방향을 가리킨다고 보장할 수는 없다. 이는 다음과 같은 문제로 이어질 수 있다.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>안장점(Saddle Point)&lt;br>
안장점은 특정 방향에서는 극대값처럼 보이고, 다른 방향에서는 극솟값처럼 보이는 지점이다. 이 지점에서는 기울기가 0에 가까워져 학습이 정체될 수 있다.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>지역 최적해(Local Minimum)&lt;br>
지역 최적해는 특정 구역에서 손실 값이 가장 작은 지점이다. 그러나 이는 전역 최솟값(global minimum)과는 거리가 있을 수 있으며, 최적화 과정이 이 지점에 갇히면 더 나은 해를 찾지 못할 위험이 있다.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>평탄한 구간(Flat Regions)&lt;br>
손실 함수가 일정하거나 기울기가 매우 작은 평탄한 구간에서는 학습이 느려지거나 멈출 수 있다.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>이러한 문제를 극복하고 손실 값을 줄이기 위해, 최적화 함수는 기울기의 정보를 활용해 적절한 방향으로 이동한다. 이러한 접근 방식의 시초가 되는 알고리즘이 바로 경사하강법(Gradient Descent)이다.&lt;/p>
&lt;h2 id="gradient-descent-gd">Gradient Descent (GD)&lt;/h2>
&lt;p>경사하강법은 손실 함수의 기울기를 계산하여 손실 값을 줄이는 방향으로 매개변수를 업데이트하는 알고리즘이다.&lt;/p>
&lt;p>경사하강법의 기본 수식은 다음과 같다.&lt;/p>
&lt;p>$$
\theta_{t+1} = \theta_t - \eta \nabla_{\theta} L(\theta_t)
$$&lt;/p>
&lt;ul>
&lt;li>$ \theta_t $ : 현재 파라미터,&lt;/li>
&lt;li>$ \eta $ : 학습률(learning rate),&lt;/li>
&lt;li>$ \nabla_{\theta} L(\theta_t) $ : 손실 함수의 기울기.&lt;/li>
&lt;/ul>
&lt;p>이 수식에서 기울기는 손실 값을 줄이는 방향을 가리킨다. 이를 반복적으로 수행하면 모델의 매개변수가 점진적으로 최적값에 근접한다.&lt;/p>
&lt;h2 id="1950s-stochastic-gradient-descent-sgd">1950s, Stochastic Gradient Descent (SGD)&lt;/h2>
&lt;p>SGD는 초기의 Batch Gradient Descent의 비효율성을 해결하기 위해 개발되었다. Batch Gradient Descent는 전체 데이터셋을 사용하여 손실 함수의 기울기를 계산하고 파라미터를 업데이트하기 때문에 데이터셋이 클수록 계산 비용이 급격히 증가한다. 이러한 문제를 해결하기 위해 SGD는 데이터의 일부인 샘플이나 미니배치를 사용하여 손실 함수의 기울기를 계산하고 파라미터를 업데이트한다.&lt;/p>
&lt;p>SGD의 업데이트 방식은 GD와 거의 같으나, 전체 데이터가 아닌 샘플들을 가지고 gradient 를 구하며 parameter 를 업데이트 해가는 방식이다.&lt;/p>
&lt;p>SGD는 전체 데이터셋을 처리하지 않고도 학습을 진행할 수 있어 대규모 데이터 학습에서 계산 비용을 대폭 줄일 수 있다. 또한, 실시간 학습이나 스트리밍 데이터 처리와 같은 환경에서도 효과적으로 사용할 수 있다. 그러나 기울기의 노이즈로 인해 최적점 근처에서 진동(oscillation) 현상이 발생하며, 손실 함수의 평탄한 구간(flat regions)에서는 느리게 수렴한다는 한계가 있다.&lt;/p>
&lt;p>PyTorch에서 SGD는 아래와 같이 구현할 수 있다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch.optim&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">optim&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SGD&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.01&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="1964-momentum">1964, Momentum&lt;/h2>
&lt;p>Momentum은 SGD의 진동 문제를 해결하기 위해 제안되었다. SGD는 현재 기울기만을 기반으로 업데이트를 수행하기 때문에 손실 함수의 지형이 비대칭인 경우 진동이 발생하여 최적점에 도달하는 데 오랜 시간이 걸릴 수 있다. Momentum은 과거 기울기의 이동 평균을 반영하여 더욱 안정적이고 효율적인 학습 경로를 제공한다.&lt;/p>
&lt;p>Momentum의 업데이트 방식은 아래와 같다.
$$
v_{t+1} = \beta v_t + (1-\beta) \nabla_{\theta_t} L(\theta_t)
$$&lt;/p>
&lt;p>$$
\theta_{t+1} = \theta_t - \eta_t v_{t+1}
$$&lt;/p>
&lt;ul>
&lt;li>$ v_t $ : 이동 평균(모멘텀 변수),&lt;/li>
&lt;li>$ \beta $ : 모멘텀 계수로, 일반적으로 0.9로 설정된다.&lt;/li>
&lt;/ul>
&lt;p>Momentum은 기울기의 이동 평균을 계산하여 진동을 줄이고, 손실 함수가 좁고 깊은 구간에서도 빠르게 수렴할 수 있도록 한다. 그러나 추가적인 하이퍼파라미터 $ \beta $를 적절히 설정해야 한다는 점에서 복잡성이 증가한다.&lt;/p>
&lt;p>PyTorch에서 Momentum은 아래와 같이 구현할 수 있다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SGD&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.01&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">momentum&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.9&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="1983-nesterov-accelerated-gradient-nag">1983, Nesterov Accelerated Gradient (NAG)&lt;/h2>
&lt;p>NAG는 Momentum의 단점을 보완하기 위해 개발되었다. Momentum 방식은 현재 위치에서 기울기를 계산하므로, 최적점 근처에서 오버슈팅(overshooting)이 발생할 가능성이 있다. NAG는 모멘텀에 의해 예측된 미래의 위치에서 기울기를 계산함으로써 이러한 문제를 해결한다.&lt;/p>
&lt;p>NAG의 업데이트 방식은 아래와 같다.
$$
v_{t+1} = \beta v_t + \nabla_{\theta} L(\theta_t - \eta \beta v_t)
$$&lt;/p>
&lt;p>$$
\theta_{t+1} = \theta_t - \eta v_{t+1}
$$&lt;/p>
&lt;p>NAG는 Momentum이 제공하는 이동 방향에 대해 한 단계 더 정교하게 접근하여, 최적점 근처에서의 오버슈팅 문제를 완화한다. 또한, 수렴 속도를 개선하며 최적점 근처에서도 안정적으로 작동한다. 그러나 기울기 계산이 더 복잡해지고 계산 비용이 증가한다는 한계가 있다.&lt;/p>
&lt;p>NAG는 PyTorch에서 아래와 같이 구현할 수 있다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SGD&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.01&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">momentum&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">nesterov&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="2011-adagrad">2011, Adagrad&lt;/h2>
&lt;p>Adagrad는 SGD와 Momentum이 모든 파라미터에 동일한 학습률을 적용한다는 문제를 해결하기 위해 도입되었다. 데이터셋에 드문 특징(sparse feature)이 포함되어 있는 경우, 이러한 방식은 드문 특징을 학습하는 데 비효율적이다. Adagrad는 각 파라미터의 과거 기울기의 제곱합을 기반으로 학습률을 조정하여 이를 해결한다.&lt;/p>
&lt;p>Adagrad의 업데이트 방식은 아래와 같다.
$$
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{G_t + \epsilon}} \nabla_{\theta} L(\theta_t)
$$&lt;/p>
&lt;ul>
&lt;li>$ G_t $ : 과거 기울기의 제곱합,&lt;/li>
&lt;li>$ \epsilon $ : 0으로 나누는 것을 방지하기 위한 작은 값.&lt;/li>
&lt;/ul>
&lt;p>Adagrad는 희소 데이터에 대한 학습에서 특히 효과적이며, 각 파라미터에 적응적인 학습률을 적용한다는 점에서 큰 장점이 있다. 그러나 기울기의 제곱합이 점진적으로 증가하면서 학습률이 감소하여 장기 학습에는 적합하지 않다는 한계가 있다.&lt;/p>
&lt;p>Adagrad는 PyTorch에서 아래와 같이 구현할 수 있다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Adagrad&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.01&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="2012-rmsprop">2012, RMSprop&lt;/h2>
&lt;p>RMSprop은 Adagrad의 단점을 해결하기 위해 제안되었다. Adagrad는 기울기의 제곱합이 점진적으로 증가하여 학습률이 감소하고, 장기 학습에서는 효과가 떨어진다. RMSprop은 기울기의 제곱 이동 평균(Exponentially Weighted Moving Average)을 사용하여 학습률을 조정함으로써 이러한 문제를 해결한다.&lt;/p>
&lt;p>RMSprop의 업데이트 방식은 아래와 같다.&lt;/p>
&lt;p>$$
E[g^2]_t = \rho E[g^2] _{t-1} + (1-\rho)g_t^2
$$&lt;/p>
&lt;p>$$
\theta_{t+1} = \theta _t - \frac{\eta}{\sqrt{E[g^2] _t + \epsilon}} \nabla _{\theta} L(\theta _t)
$$&lt;/p>
&lt;ul>
&lt;li>$ E[g^2]_t $ : 기울기의 제곱 이동 평균,&lt;/li>
&lt;li>$ \rho $ : 지수 이동 평균의 가중치 계수로, 일반적으로 0.9로 설정된다,&lt;/li>
&lt;li>$ \epsilon $ : 0으로 나누는 것을 방지하기 위한 작은 값.&lt;/li>
&lt;/ul>
&lt;p>RMSprop은 Adagrad와 달리 이동 평균을 사용하여 학습률 감소 문제를 해결하고, 일정한 학습률을 유지하며 안정적으로 작동한다. 특히 RNN(Recurrent Neural Network)과 같은 모델에서 효과적으로 사용된다.&lt;/p>
&lt;p>RMSprop은 PyTorch에서 아래와 같이 구현할 수 있다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RMSprop&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.01&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="2014-adam">2014, Adam&lt;/h2>
&lt;p>Adam은 Momentum과 RMSprop의 장점을 결합하여 더욱 효율적이고 안정적인 학습을 제공하기 위해 제안되었다. Adam은 1차 모멘텀(기울기의 이동 평균)과 2차 모멘텀(기울기의 제곱 이동 평균)을 모두 사용하여 학습률을 조정한다.&lt;/p>
&lt;p>Adam의 업데이트 방식은 아래와 같다.&lt;/p>
&lt;p>$$
m_t = \beta_1 m_{t-1} + (1 - \beta_1)g_t
$$&lt;/p>
&lt;p>$$
v_t = \beta_2 v_{t-1} + (1 - \beta_2)g_t^2
$$&lt;/p>
&lt;p>$$
\hat{m}_t = \frac{m_t}{1-\beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1-\beta_2^t}
$$&lt;/p>
&lt;p>$$
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t
$$&lt;/p>
&lt;ul>
&lt;li>$ m_t $ : 기울기의 1차 모멘텀(평균),&lt;/li>
&lt;li>$ v_t $ : 기울기의 2차 모멘텀(분산),&lt;/li>
&lt;li>$ \hat{m}_t $, $ \hat{v}_t $ : 편향 보정된 모멘텀.&lt;/li>
&lt;/ul>
&lt;p>Adam은 빠르고 안정적인 수렴을 제공하며, 대부분의 딥러닝 모델에서 기본 최적화 알고리즘으로 사용된다. 학습률의 조정이 자동으로 이루어져 하이퍼파라미터 설정의 복잡성이 감소하는 장점이 있다. 그러나 과적합 가능성이 높아질 수 있으며, 일반화 성능이 저하될 위험이 있다.&lt;/p>
&lt;p>Adam은 PyTorch에서 아래와 같이 구현할 수 있다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Adam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.001&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="2017-adamw">2017, AdamW&lt;/h2>
&lt;p>AdamW는 Adam의 일반화 성능 문제를 해결하기 위해 제안되었다. Adam은 L2 정규화를 사용하는 방식이 가중치 감쇠(weight decay)와 동일하지 않다는 문제가 있었고, 이는 과적합 위험을 증가시켰다. AdamW는 가중치 감쇠를 명시적으로 적용하여 이러한 문제를 해결하였다.&lt;/p>
&lt;p>AdamW의 업데이트 방식은 아래와 같다.
$$
\theta_{t+1} = \theta_t - \eta (\hat{m}_t / \sqrt{\hat{v}_t} + \epsilon + \lambda \theta_t)
$$&lt;/p>
&lt;ul>
&lt;li>$ \lambda $ : 가중치 감쇠(weight decay) 계수.&lt;/li>
&lt;/ul>
&lt;p>AdamW는 과적합을 줄이고 일반화 성능을 향상시키는 데 효과적이다. 특히 딥러닝 연구와 최신 모델 개발에서 기본 최적화 알고리즘으로 널리 사용되고 있다.&lt;/p>
&lt;p>AdamW는 PyTorch에서 아래와 같이 구현할 수 있다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">optim&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AdamW&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">parameters&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.001&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">weight_decay&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.01&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Word2Vec의 최적화</title><link>https://gyeongmin.kr/p/word2vec-2/</link><pubDate>Wed, 03 Jan 2024 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/word2vec-2/</guid><description>&lt;img src="https://gyeongmin.kr/images/deep-learning-from-scratch.jpeg" alt="Featured image of post Word2Vec의 최적화" />&lt;h1 id="word2vec의-최적화">Word2Vec의 최적화&lt;/h1>
&lt;p>&lt;img src="https://gyeongmin.kr/p/word2vec-2/image-3.png"
width="1569"
height="1191"
srcset="https://gyeongmin.kr/p/word2vec-2/image-3_hu8834c8184300983a591c4f0045bd8abe_487521_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/word2vec-2/image-3_hu8834c8184300983a591c4f0045bd8abe_487521_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Word2Vec의 구조"
class="gallery-image"
data-flex-grow="131"
data-flex-basis="316px"
>&lt;/p>
&lt;p>Word2Vec은 자연어 처리 분야에서 매우 중요한 도구로 자리 잡고 있다. 그러나 Word2Vec은 어휘의 양이 방대해질수록 계산량과 메모리 사용량이 커지는 문제를 가지고 있다. 이러한 문제를 해결하기 위하여 &amp;lsquo;임베딩(Embedding)&amp;rsquo; 계층을 도입하고 &amp;lsquo;네거티브 샘플링(Negative Sampling)&amp;rsquo; 기법을 적용하는 두 가지 주요 개선 방법을 살펴보자.&lt;/p>
&lt;h2 id="embedding-계층">Embedding 계층&lt;/h2>
&lt;p>&lt;img src="https://gyeongmin.kr/p/word2vec-2/image-4.png"
width="1347"
height="661"
srcset="https://gyeongmin.kr/p/word2vec-2/image-4_hu38ab5d6d8c1cfa13035a3656906f9354_254061_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/word2vec-2/image-4_hu38ab5d6d8c1cfa13035a3656906f9354_254061_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Embedding Layer"
class="gallery-image"
data-flex-grow="203"
data-flex-basis="489px"
>&lt;/p>
&lt;h3 id="배경">배경&lt;/h3>
&lt;p>전통적으로 단어를 표현하는 방법 중 하나는 원-핫 인코딩이다. 이 방법은 각 단어를 하나의 긴 벡터로 표현하며, 벡터의 크기는 어휘의 크기와 같다. 벡터에서 단어에 해당하는 위치는 1이고 나머지는 모두 0이다. 이 방식은 직관적이지만, 벡터가 대부분 0으로 채워지는 희소성 문제와 차원이 커질수록 계산 비효율성이 증가하는 문제를 가지고 있다.&lt;/p>
&lt;p>예를 들어, 어휘 사전에 10,000개의 단어가 있다면, 각 단어는 10,000차원의 벡터로 표현된다. 이렇게 고차원 벡터와 가중치 행렬의 곱셈 계산은 많은 계산 자원을 소모한다.&lt;/p>
&lt;p>임베딩 레이어는 각 단어를 고정된 크기의 밀집 벡터로 변환한다. 이 밀집 벡터는 단어의 의미를 수치적으로 포착할 수 있으며, 벡터의 각 요소는 연속된 값으로 이루어져 있다. 이로 인해 희소성 문제를 해결하고, 효율적인 계산이 가능해진다.&lt;/p>
&lt;h3 id="작동-원리">작동 원리&lt;/h3>
&lt;p>임베딩 레이어는 각 단어를 고유한 인덱스에 매핑하고, 이 인덱스를 사용하여 단어의 밀집 벡터를 찾는다. 이 밀집 벡터는 학습 가능한 파라미터로, 모델 학습 과정에서 최적화된다.&lt;/p>
&lt;p>전통적인 원-핫 인코딩 방식은 단어의 인덱스에 해당하는 위치에만 1을 두고 나머지는 0으로 채워 계산을 수행한다. 이에 반해, 임베딩 레이어는 각 단어에 대한 밀집 벡터를 직접 참조하여 계산을 수행하기 때문에, 불필요한 계산을 크게 줄여준다.&lt;/p>
&lt;h3 id="구현-예시">구현 예시&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">Embedding&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">W&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">W&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zeros_like&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">idx&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">None&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">idx&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">W&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">idx&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">idx&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">out&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">W&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">idx&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">out&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dout&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dW&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dW&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="o">...&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_id&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">idx&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dW&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">word_id&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">dout&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="kc">None&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="네거티브-샘플링-기법">네거티브 샘플링 기법&lt;/h2>
&lt;p>&lt;img src="https://gyeongmin.kr/p/word2vec-2/image-5.png"
width="1559"
height="772"
srcset="https://gyeongmin.kr/p/word2vec-2/image-5_huf6cb38d7ca8e765b1958c39d9d025593_249082_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/word2vec-2/image-5_huf6cb38d7ca8e765b1958c39d9d025593_249082_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Negative Sampling"
class="gallery-image"
data-flex-grow="201"
data-flex-basis="484px"
>&lt;/p>
&lt;p>&lt;strong>네거티브 샘플링&lt;/strong>은 다중 분류 문제를 이진 분류로 근사하여 계산량을 대폭 줄이는 기법이다. 이 기법은 특히 대규모 어휘를 다루는 자연어 처리에서 중요한 역할을 한다.&lt;/p>
&lt;h3 id="배경-1">배경&lt;/h3>
&lt;p>Word2Vec과 같은 언어 모델은 단어의 의미를 벡터로 변환하여 수치화하는 과정을 수행한다. 이 과정에서 전체 어휘에 대한 예측을 수행하게 되면, 어휘의 크기가 커질수록 계산량이 매우 늘어나는 문제가 있다. 특히, Softmax 계층에서의 계산은 모든 어휘에 대해 수행되어야 하므로, 어휘 수에 비례하여 계산량이 급격히 증가한다. 네거티브 샘플링은 이러한 문제를 효과적으로 해결하는 방법으로 제안되었다.&lt;/p>
&lt;h3 id="다중-분류-문제의-이진-분류-근사">다중 분류 문제의 이진 분류 근사&lt;/h3>
&lt;p>네거티브 샘플링의 핵심 아이디어는 다중 분류 문제를 이진 분류 문제로 근사하는 것이다. 전체 어휘에 대한 예측 대신, 모델이 특정 단어를 정답으로 예측하는지 여부만을 판단하게 한다. 즉, &amp;lsquo;이 단어가 맞는가? 아닌가?&amp;lsquo;라는 간단한 질문에 답하는 형식으로 문제를 단순화한다.&lt;/p>
&lt;h3 id="긍정적-예와-부정적-예의-선택">긍정적 예와 부정적 예의 선택&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>긍정적 예(Positive Samples): 모델이 맞추어야 하는 실제 단어. 예를 들어 문맥이 &amp;ldquo;The cat sits on the&amp;rdquo; 일 때, 실제 다음 단어인 &amp;ldquo;mat&amp;rdquo; 이 긍정적 예가 된다.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>부정적 예(Negative Samples): 무작위로 선택된 단어들로, 모델이 이 단어들을 정답으로 선택하지 않도록 학습한다. 이들은 긍정적 예와 구분되어야 할 대상들이다.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="계산-효율성의-증가">계산 효율성의 증가&lt;/h3>
&lt;p>네거티브 샘플링을 사용하면 모델이 전체 어휘에 대한 Softmax 계산을 수행할 필요가 없어진다. 대신, 긍정적 예에 대해서는 확률을 높이고, 선택된 부정적 예에 대해서는 확률을 낮추는 방식으로 학습이 이루어진다. 이 과정은 계산량을 현저히 줄여주며, 특히 어휘의 크기가 큰 경우에 매우 효과적이다.&lt;/p>
&lt;h3 id="구현-예시-1">구현 예시&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">NegativeSamplingLoss&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">W&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">corpus&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">power&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.75&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">sample_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sample_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sample_size&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sampler&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">UnigramSampler&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">corpus&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">power&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">sample_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loss_layers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">SigmoidWithLoss&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sample_size&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">embed_dot_layers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">EmbeddingDot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sample_size&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span> &lt;span class="o">=&lt;/span>&lt;span class="p">[],&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">layer&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">embed_dot_layers&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">h&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">batch_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">target&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">negative_sample&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sampler&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get&lt;/span> &lt;span class="n">_negative_sample&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">target&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 긍정적 예 순전파&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">score&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">embed_dot_layers&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">h&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">correct_label&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ones&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">batch_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">int32&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loss_layers&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">score&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">correct_label&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 부정적 예 순전파&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">negative_label&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zeros&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">batch_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">int32&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sample&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">size&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">negative_target&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">negative_sample&lt;/span>&lt;span class="p">[:,&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">score&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">embed_dot_layers&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">h&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">negative_target&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loss_layers&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">score&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">negative_label&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">loss&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dout&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dh&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">l0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">l1&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">zip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loss_layers&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">embed_dot_layers&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dscore&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">10.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dout&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dh&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">l1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dscore&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">dh&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="cbow-모델-구현">CBOW 모델 구현&lt;/h2>
&lt;p>이전 포스팅에서 구현했던 CBOW 모델에 Embedding과 Negative Sampling Loss 계층을 적용해 개선해 보자.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">CBOW&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">vocab_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">hidden_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">window_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">corpus&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">V&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">H&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">vocab_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">hidden_size&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">W_in&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.01&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">V&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">H&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">astype&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;f&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">W_out&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.01&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">V&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">H&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">astype&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;f&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">in_layers&lt;/span> &lt;span class="o">=&lt;/span>&lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">window_size&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">layer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Embedding&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W_in&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">in_layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layer&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ns_loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">NegativeSamplingLoss&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W_out&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">corpus&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">power&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.75&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">sample_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">layers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">in_layers&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ns_loss&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[],&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">layer&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">layers&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">word_vecs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">W_in&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">contexts&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">h&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">layer&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">in_layers&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">h&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">contexts&lt;/span>&lt;span class="p">[:,&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">h&lt;/span> &lt;span class="o">*=&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">in_layers&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ns_loss&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">h&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">loss&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dout&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="err">：&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dout&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ns_loss&lt;/span>&lt;span class="o">.&lt;/span> &lt;span class="n">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dout&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dout&lt;/span> &lt;span class="o">*=&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">in_layers&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">layer&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">in_layers&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dout&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="kc">None&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://gyeongmin.kr/p/word2vec-2/image.png"
width="771"
height="224"
srcset="https://gyeongmin.kr/p/word2vec-2/image_hu97ada50fdfa2d7dea73986e8a482bada_60348_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/word2vec-2/image_hu97ada50fdfa2d7dea73986e8a482bada_60348_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="맥락과 타깃을 단어 ID로 나타낸 예시"
class="gallery-image"
data-flex-grow="344"
data-flex-basis="826px"
>&lt;/p>
&lt;p>단어 ID의 배열이 contexts와 target의 예이다. 맥락은 2차원 배열이고 타겟은 1차원 배열이고, 이러한 데이터가 순전파에에 입력되는 것이다.&lt;/p>
&lt;h2 id="결론">결론&lt;/h2>
&lt;p>임베딩 계층과 네거티브 샘플링 기법은 Word2Vec 모델의 계산량과 메모리 사용량을 현저하게 줄여주는 효과적인 방법이다. 특히, 대규모 어휘를 가진 말뭉치를 다루는 데 있어서 이러한 개선 방법은 필수적이다. 이를 통해 보다 빠르고 효율적으로 자연어 처리 모델을 학습이 가능하다.&lt;/p>
&lt;p>Word2Vec은 자연어 처리에 중요한 역할을 하고 있다. 이것으로 단어들이 고정 길이의 벡터로 변환되며, 이렇게 변환된 단어 벡터는 비슷한 의미를 가진 단어들을 찾는 데 유용하게 사용된다. 또한, 단어의 분산 표현은 전이 학습에도 적용할 수 있는데, 이는 한 분야에서 획득한 지식을 다른 분야에 적용하는 것을 의미한다. 이를 통해 다양한 자연어 처리 문제에 효과적으로 접근할 수 있다.&lt;/p>
&lt;p>자연어 처리 작업에서는 Word2Vec 모델이 주로 큰 말뭉치로 사전 학습된 상태에서 사용된다. 예를 들어, 텍스트 분류, 문서 클러스터링, 감정 분석 등의 작업에서 사전에 학습된 단어 벡터를 활용함으로써 작업의 성능을 향상시킬 수 있다. 이러한 방식은 자연어를 벡터로 변환함으로써 일반적인 머신러닝 기법(신경망, SVM 등등)을 자연어 처리 문제에 적용할 수 있게 해준다. 따라서 Word2Vec의 단어 분산 표현은 자연어 처리 분야에서 높은 정확도와 효율성을 제공하는 핵심적인 요소가 되고 있다.&lt;/p></description></item><item><title>word2vec을 이용한 단어 임베딩</title><link>https://gyeongmin.kr/p/word2vec/</link><pubDate>Tue, 19 Dec 2023 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/word2vec/</guid><description>&lt;img src="https://gyeongmin.kr/images/deep-learning-from-scratch.jpeg" alt="Featured image of post word2vec을 이용한 단어 임베딩" />&lt;blockquote>
&lt;p>본 포스팅은 &amp;lsquo;밑바닥부터 시작하는 딥러닝 2&amp;rsquo; 교재를 참고했습니다.&lt;/p>
&lt;/blockquote>
&lt;h2 id="추론-기반-기법과-신경망">추론 기반 기법과 신경망&lt;/h2>
&lt;p>단어를 벡터로 표현하는 방법은 통계 기반 기법과 추론 기반 기법이 있다. 둘 모두 &lt;a class="link" href="https://gyeongminn.github.io/p/word-distributed-representation/#%eb%b6%84%ed%8f%ac-%ea%b0%80%ec%84%a4%ea%b3%bc-%eb%b6%84%ec%82%b0-%ed%91%9c%ed%98%84" target="_blank" rel="noopener"
>분포 가설&lt;/a>을 기반으로 한다.&lt;/p>
&lt;h3 id="통계-기반-기법의-문제점">통계 기반 기법의 문제점&lt;/h3>
&lt;p>통계 기반 기법은 주변 단어의 빈도를 기초로 단어를 표현한다. 단어 수가 $N$개일 때, $N \times N$이라는 거대한 행렬을 만들게 된다. 영어 어휘만 해도 100만 개에 가까운데, 그렇다면 1조개의 원소를 가진 행렬이 필요하다는 것이다.&lt;/p>
&lt;p>이렇게 통계 기반 기법처럼 학습 데이터를 한번에 처리하지 말고, &lt;strong>데이터를 작게 나눠 순차적으로 학습&lt;/strong>시키는 (미니배치 학습) 방법이 필요하다.&lt;/p>
&lt;h3 id="추론-기반-기법의-개요">추론 기반 기법의 개요&lt;/h3>
&lt;p>추론이란 &lt;strong>주변 단어&lt;/strong> (맥락)가 주어졌을 때, 무슨 단어가 들어갈 지 단어를 &lt;strong>유추&lt;/strong>하는 것이다.&lt;/p>
&lt;p>맥락 정보를 입력받아 출현할 수 있는 단어들의 확률분포를 나타내는 모델을 만들고, 학습의 결과로 분산 표현을 얻는 것이 추론 기반 기법이다.&lt;/p>
&lt;h3 id="신경망에서의-단어-처리">신경망에서의 단어 처리&lt;/h3>
&lt;p>신경망은 단어를 그대로 처리할 수 없기 때문에, 단어를 고정된 길이의 벡터로 변환해야 한다. 이를 위해 가장 대표적으로 사용되는 방법이 &lt;strong>원핫 인코딩&lt;/strong>(one-hot encoding)이다.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">단어(텍스트)&lt;/th>
&lt;th style="text-align:center">단어 ID&lt;/th>
&lt;th style="text-align:center">원핫 표현&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">you&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">(1, 0, 0, 0, 0, 0, 0, 0)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">goodbye&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">(0, 0, 1, 0, 0, 0, 0, 0)&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>위와 같이 단어는 텍스트, 단어 ID, 원핫 표현으로 나타낼 수 있다. 단어를 고정 크기의 원핫 표현으로 나타내게 되면 뉴런의 수를 고정할 수 있다.&lt;/p>
&lt;p>신경망을 구성하는 계층들이 벡터를 처리할 수 있으므로, 이제 단어를 신경망으로 처리할 수 있을 것이다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/word2vec/image.png"
width="562"
height="459"
srcset="https://gyeongmin.kr/p/word2vec/image_hu3f7b4f5201a3d844f9498b9d3ce51d55_90389_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/word2vec/image_hu3f7b4f5201a3d844f9498b9d3ce51d55_90389_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="완전연결계층에 의한 변환을 단순화한 그림"
class="gallery-image"
data-flex-grow="122"
data-flex-basis="293px"
>&lt;/p>
&lt;p>완전연결계층의 계산은 행렬 곱으로 수행할 수 있고. 행렬 곱은 넘파이의 &lt;code>np.matmul()&lt;/code>로 할 수 있다.&lt;/p>
&lt;h2 id="cbow">CBOW&lt;/h2>
&lt;h3 id="cbow-모델의-추론-처리">CBOW 모델의 추론 처리&lt;/h3>
&lt;p>CBOW 모델은 맥락으로부터 타깃을 추측하는 용도의 신경망이다. (타깃은 중앙 단어, 맥락은 주변 단어를 의미한다)&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/word2vec/image-1.png"
width="853"
height="829"
srcset="https://gyeongmin.kr/p/word2vec/image-1_hub4bfc2fe41a6c706de102652017462d2_200069_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/word2vec/image-1_hub4bfc2fe41a6c706de102652017462d2_200069_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="CBOW 모델의 신경망 구조"
class="gallery-image"
data-flex-grow="102"
data-flex-basis="246px"
>&lt;/p>
&lt;p>입력층이 2개 있고, 은닉층을 거쳐 출력층에 도달한다.&lt;/p>
&lt;p>두 입력층에서 은닉층으로의 변환은 완전연결계층이 수행한다. 그리고 은닉층에서 출력층 뉴런으로의 변환은 다른 완전연결계층이 처리한다. 입력층이 여러 개이면 전체를 &lt;strong>평균&lt;/strong>하면 된다.&lt;/p>
&lt;p>출력층의 뉴런은 총 7개인데, 이 뉴런 하나하나가 각각의 단어에 대응한다. 출력층 뉴런은 각 단어의 &lt;strong>점수&lt;/strong>를 뜻하며, 값이 높을수록 대응 단어의 출현 확률도 높아진다. 이 점수에 소프트맥스 함수를 적용해서, &lt;strong>확률&lt;/strong>을 얻을 수 있다.&lt;/p>
&lt;p>학습을 진행할수록 맥락에서 출현하는 단어를 잘 추측하는 방향으로 이 분산 표현들이 갱신된다. 이렇게 얻은 벡터에는 &lt;strong>단어의 의미도 포함되어 있다&lt;/strong>.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/word2vec/image-2.png"
width="1009"
height="771"
srcset="https://gyeongmin.kr/p/word2vec/image-2_hu83e02f47960715b8f885eb14234d3d19_138189_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/word2vec/image-2_hu83e02f47960715b8f885eb14234d3d19_138189_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="계층 관점에서 본 CBOW 모델의 신경망 구성"
class="gallery-image"
data-flex-grow="130"
data-flex-basis="314px"
>&lt;/p>
&lt;p>이제 CBOW 모델의 추론 처리를 파이썬으로 구현해 보자.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">MatMul&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">W&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">W&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zeros_like&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">None&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">W&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">out&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">W&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">out&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dout&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">W&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dx&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dout&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">W&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">T&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dW&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">T&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dout&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="o">...&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dW&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">dx&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>MatMul 계층은 내부에서 행렬 곱을 계산한다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 샘플 맥락 데이터&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">c0&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">c1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 가중치 초기화&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">W_in&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">W_out&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 계층 생성&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">in_layer0&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">MatMul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W_in&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">in_layer1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">MatMul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W_in&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">out_layer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">MatMul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W_out&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 순전파&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">h0&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">in_layer0&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">c0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">h1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">in_layer1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">c1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">h&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.5&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">h0&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">h1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">s&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">out_layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">h&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">s&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>CBOW 모델은 활성화 함수를 사용하지 않는 간단한 구성의 신경망이다.&lt;/p>
&lt;h3 id="cbow-모델의-학습">CBOW 모델의 학습&lt;/h3>
&lt;blockquote>
&lt;p>모델이 올바른 예측을 할 수 있도록 가중치를 조정해야 한다.&lt;/p>
&lt;/blockquote>
&lt;p>소프트맥스 함수를 이용 해 점수를 확률로 변환하고, 그 확률과 정답 레이블로부터 교차 엔트로피 오차를 구한 후, 그 값을 손실로 사용해 학습을 진행한다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/word2vec/image-3.png"
width="995"
height="596"
srcset="https://gyeongmin.kr/p/word2vec/image-3_hu42c86eda2c2eb22ccbe976f58bc00797_127466_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/word2vec/image-3_hu42c86eda2c2eb22ccbe976f58bc00797_127466_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="CBOW 모델의 학습 시 신경망 구성"
class="gallery-image"
data-flex-grow="166"
data-flex-basis="400px"
>&lt;/p>
&lt;p>앞서 구현한 추론 처리를 수행하는 CBOW 모델에 &lt;code>Softmax&lt;/code> 계층과 &lt;code>Cross Entropy Error&lt;/code> 계층을 추가하기만 하면 된다.&lt;/p>
&lt;h3 id="word2vec의-가중치와-분산-표현">word2vec의 가중치와 분산 표현&lt;/h3>
&lt;p>word2vec에서 사용되는 신경망에는 두 가지 가중치가 존재한다.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>입력 측 가중치 $ W_\text{in} $: 입력 측 완전연결계층의 가중치로, 각 행은 해당 단어의 분산 표현을 나타낸다.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>출력 측 가중치 $ W_\text{out} $: 출력 측 완전연결계층의 가중치로, 단어의 의미가 인코딩된 벡터가 각 열에 저장된다.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>일반적으로 word2vec에서는 입력 측 가중치 $ W_\text{in} $만을 최종 단어의 분산 표현으로 사용한다. 출력 측 가중치는 대부분의 연구에서 버려진다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/word2vec/image-4.png"
width="904"
height="497"
srcset="https://gyeongmin.kr/p/word2vec/image-4_hu1af831d405d8a936ea25b48a045ffece_189259_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/word2vec/image-4_hu1af831d405d8a936ea25b48a045ffece_189259_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="각 단어의 분산 표현"
class="gallery-image"
data-flex-grow="181"
data-flex-basis="436px"
>&lt;/p>
&lt;p>두 가중치는 하나만 이용할 수도 있고, 둘을 합쳐서 사용할 수도 있다.&lt;/p>
&lt;p>word2vec의 skip-gram 등 &lt;strong>많은 연구에서는 입력 측의 가중치만 사용&lt;/strong>하고, GloVe에서는 두 가중치를 더하여 사용한다.&lt;/p>
&lt;h2 id="학습-데이터-준비">학습 데이터 준비&lt;/h2>
&lt;p>&amp;ldquo;You say goodbye and I say hello&amp;rdquo; 문장을 이용해 학습을 진행해 보자.&lt;/p>
&lt;p>문장을 전처리하는 &lt;code>preprocess&lt;/code> 함수는 &lt;a class="link" href="https://gyeongminn.github.io/p/word-distributed-representation/#%eb%a7%90%eb%ad%89%ec%b9%98-%ec%a0%84%ec%b2%98%eb%a6%ac" target="_blank" rel="noopener"
>여기&lt;/a>를 참고하자.&lt;/p>
&lt;h3 id="맥락과-타깃">맥락과 타깃&lt;/h3>
&lt;p>word2vec에서 이용하는 신경망의 입력은 &lt;strong>맥락&lt;/strong>이다. 그 정답 레이블은 중앙 단어인 &lt;strong>타깃&lt;/strong> 이다. 우리는 맥락을 입력했을 때, 타깃을 출력할 확률이 높아지도록 학습시키면 된다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/word2vec/image-5.png"
width="789"
height="312"
srcset="https://gyeongmin.kr/p/word2vec/image-5_hu9e7d1c407f3b0c8c4571a4e51b18e111_176184_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/word2vec/image-5_hu9e7d1c407f3b0c8c4571a4e51b18e111_176184_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="맥락과 타깃의 예시"
class="gallery-image"
data-flex-grow="252"
data-flex-basis="606px"
>&lt;/p>
&lt;p>맥락과 타깃을 만드는 함수를 구현해 보자.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">create_contexts_target&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">corpus&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">window_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">target&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">corpus&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">window_size&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">window_size&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">contexts&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">idx&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">window_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">corpus&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">window_size&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">t&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">window_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">window_size&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">t&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">continue&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">cs&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">corpus&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">idx&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">t&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">contexts&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">cs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">contexts&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">target&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="원핫-벡터로-변환">원핫 벡터로 변환&lt;/h3>
&lt;p>맥락과 타깃을 단어 ID에서 원핫 표현으로 변환하기 위해, 원핫 벡터로 변환하는 함수를 구현해 보자.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">convert_one_hot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">corpus&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">vocab_size&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">N&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">corpus&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">corpus&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ndim&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">one_hot&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zeros&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="n">N&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">vocab_size&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">int32&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">idx&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_id&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">corpus&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">one_hot&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">idx&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_id&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">elif&lt;/span> &lt;span class="n">corpus&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ndim&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">C&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">corpus&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">one_hot&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zeros&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="n">N&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">C&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">vocab_size&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">int32&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">idx_0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_ids&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">corpus&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">idx_1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_id&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">word_ids&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">one_hot&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">idx_0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">idx_1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_id&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">one_hot&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="cbow-모델-구현">CBOW 모델 구현&lt;/h2>
&lt;p>그럼 이제 모델을 구현해 보자.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/word2vec/image-6.png"
width="978"
height="664"
srcset="https://gyeongmin.kr/p/word2vec/image-6_hud00d83d8669da602ae7fdcc74b583914_117555_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/word2vec/image-6_hud00d83d8669da602ae7fdcc74b583914_117555_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="CBOW 모델의신경망 구성"
class="gallery-image"
data-flex-grow="147"
data-flex-basis="353px"
>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">SimpleCBOW&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">vocab_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">hidden_size&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">V&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">H&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">vocab_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">hidden_size&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 가중치 초기화&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">W_in&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.01&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">V&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">H&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">astype&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;f&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">W_out&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.01&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">H&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">V&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">astype&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;f&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 계층 생성&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">in_layer0&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">MatMul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W_in&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">in_layer1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">MatMul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W_in&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">out_layer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">MatMul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W_out&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loss_layer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">SoftmaxWithLoss&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 모든 가중치와 기울기를 리스트에 모은다.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">layers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">in_layer0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">in_layer1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">out_layer&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[],&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">layer&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">layers&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 인스턴스 변수에 단어의 분산 표현을 저장한다.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">word_vecs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">W_in&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">contexts&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">h0&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">in_layer0&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">contexts&lt;/span>&lt;span class="p">[:,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">h1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">in_layer1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">contexts&lt;/span>&lt;span class="p">[:,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">h&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">h0&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">h1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mf">0.5&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">score&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">out_layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">h&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loss_layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">score&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">loss&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dout&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">ds&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loss_layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dout&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">da&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">out_layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">da&lt;/span> &lt;span class="o">*=&lt;/span> &lt;span class="mf">0.5&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">in_layer1&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">da&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">in_layer0&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">da&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="kc">None&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="학습코드구현">학습코드구현&lt;/h3>
&lt;p>학습 데이터를 준비해 신경망에 입력한 다음, 기울기를 구하고 가중치 매개변수를 순서대로 갱신해보자.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="n">window_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">hidden_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">5&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">batch_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">3&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">max_epoch&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1000&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;You say goodbye and I say hello.&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">corpus&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_to_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">id_to_word&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">preprocess&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">vocab_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">word_to_id&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">contexts&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">create_contexts_target&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">corpus&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">window_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">target&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">convert_one_hot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">target&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">vocab_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">contexts&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">convert_one_hot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">contexts&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">vocab_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">SimpleCBOW&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">vocab_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">hidden_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">optimizer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Adam&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">trainer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Trainer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">optimizer&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">trainer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">fit&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">contexts&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">target&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">max_epoch&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">batch_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">trainer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">plot&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">word_vecs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">word_vecs&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">word_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">id_to_word&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">items&lt;/span>&lt;span class="p">():&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_vecs&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">word_id&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Optimizer는 Adam을 사용해서 학습시켰다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/word2vec/image-7.png"
width="640"
height="480"
srcset="https://gyeongmin.kr/p/word2vec/image-7_hu7d4630c01d55ea2ccca985100a1b63c6_27676_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/word2vec/image-7_hu7d4630c01d55ea2ccca985100a1b63c6_27676_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="학습 경과 그래프"
class="gallery-image"
data-flex-grow="133"
data-flex-basis="320px"
>&lt;/p>
&lt;p>학습을 거듭할수록 손실이 줄어들고 있다. 그럼 이제 학습이 끝난 후의 가중치 매개변수를 확인해 보자.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">you [ 1.001226 1.0100921 -1.0480953 -1.1371888 1.4559563]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">say [-1.1566567 -1.176362 1.1436371 1.10196 0.29608265]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">goodbye [ 0.93248147 0.8733082 -0.8807387 -0.79100204 0.47581592]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">and [-0.77025014 -0.7765116 0.7260802 0.86010003 1.9209603 ]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">i [ 0.9177614 0.86838746 -0.8880995 -0.7853987 0.48234403]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">hello [ 0.97636664 1.0043367 -1.0315654 -1.1388433 1.4567573 ]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">. [-1.2583737 -1.2487313 1.2197953 1.20546 -1.6672388]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>이제 드디어 단어를 밀집벡터로 나타낼 수 있게 되었다. 이 밀집 벡터가 바로 단어의 분산 표현이다.&lt;/p>
&lt;p>학습이 잘 이루어졌으니, 이 분산 표현은 단어의 실제 의미를 담고 있을 것이다.&lt;/p>
&lt;p>여태 구현한 CBOW 모델은 처리 효율 면에서 문제가 있다. 이제 그걸 개선해 보자.&lt;/p>
&lt;h2 id="word2vec-보충">word2vec 보충&lt;/h2>
&lt;h3 id="cbow-모델과-확률">CBOW 모델과 확률&lt;/h3>
&lt;p>사건 A가 일어날 확률은 $P(A)$와 같이 표기하고, A와 B가 동시에 일어날 확률은 $P(A, B)$와 같이 표기한다. 사건 B가 일어났을 때 사건 A가 일어날 확률은 $P(A|B)$와 같이 표기한다.&lt;/p>
&lt;p>맥락으로 $w_{t-1}$과 $w_{t+1}$ 이 주어졌을 때 $w_t$가 일어날 확률은&lt;/p>
&lt;p>$$
P(w_t | w_{t-1}, w_{t+1})
\tag 1
$$&lt;/p>
&lt;p>식 1과 같이 쓸 수 있다. 이는 CBOW를 모델링 하는 식이다.&lt;/p>
&lt;p>교차 엔트로피 오차 식은 $L = - \sum_k t_k \log y_k$이다. $y_k$는 $k$번째에 해당하는 사건이 일어날 확률을 의미하고, $t_k$는 정답 레이블로 원핫 벡터로 표현된다. 여기서 문제의 정답은 $w_i$가 발생하는 것이므로 $w_i$에 해당하는 원소만 1이고 나머지는 0이 된다. 이 점을 활용하여, 다음 식을 유도할 수 있다.&lt;/p>
&lt;p>$$
L = - \log P(w_t \ | \ w_{t-1}, \ w_{t+1})
\tag 2
$$&lt;/p>
&lt;p>식 2는 &lt;strong>음의 로그 가능도&lt;/strong>라고 부른다. 이처럼 CBOW 모델의 손실 함수는 식 1의 확률에 $\log$를 취한 다음 마이너스를 붙인 것이다. 이는 샘플 데이터 하나에 대한 손실 함수이고, 이를 corpus 전체로 확장시키면 아래 식 3과 같다.&lt;/p>
&lt;p>$$
L = - \frac{1}{T} \sum_{t=1}^T \log P(w_t \ | \ w_{t-1}, \ w_{t+1})
\tag 3
$$&lt;/p>
&lt;p>CBOW 모델의 학습이 수행하는 일은 이 손실 함수의 값을 가능한 한 작게 만드는 것이다.&lt;/p>
&lt;h3 id="skip-gram-모델">skip-gram 모델&lt;/h3>
&lt;p>skip-gram은 CBOW에서 다루는 맥락과 타깃을 역전시킨 모델이다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/word2vec/image-8.png"
width="833"
height="147"
srcset="https://gyeongmin.kr/p/word2vec/image-8_hu2916d9d77f1323c25fd727aaf35c33dd_75662_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/word2vec/image-8_hu2916d9d77f1323c25fd727aaf35c33dd_75662_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="CBOW 모델과 skip-gram 모델이 다루는 문제"
class="gallery-image"
data-flex-grow="566"
data-flex-basis="1360px"
>&lt;/p>
&lt;p>CBOW 모델은 맥락이 여러 개 있고, 그 여러 맥락으로부터 타깃을 추측한다. 반면에 skip-gmm 모델은 중앙의 타깃으로부터 주변의 맥락을 추측한다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/word2vec/image-9.png"
width="811"
height="660"
srcset="https://gyeongmin.kr/p/word2vec/image-9_huab099de2643e368e2fc9c09000b2c279_217229_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/word2vec/image-9_huab099de2643e368e2fc9c09000b2c279_217229_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="skip-gram 모델의 신경망 구성 예"
class="gallery-image"
data-flex-grow="122"
data-flex-basis="294px"
>&lt;/p>
&lt;p>skip-gram 모델을 확률 표기로 나타내면 아래 식 4와 같다.&lt;/p>
&lt;p>$$
P(w_{t-1}, \ w_{t+1} \ | \ w_t)
\tag 4
$$&lt;/p>
&lt;p>조건부 독립이라고 가정하고 (맥락의 단어 사이에 관련성이 없다고 가정하고) 식 4를 아래 식 5와 같이 분해한다.&lt;/p>
&lt;p>$$
P(w_{t-1}, \ w_{t+1} \ | \ w_t) = P(w_{t-1} \ | \ w_{t}) \ P(w_{t+1} \ | \ w_{t})
\tag 5
$$&lt;/p>
&lt;p>위 식을 교차 엔트로피 오차에 적용하고, corpus 전체로 확장시키면 아래 식 6이 된다.&lt;/p>
&lt;p>$$
L = - \frac{1}{T} \sum_{t=1}^T ( \log P(w_{t-1} \ | \ w_{t})+ P(w_{t+1} \ | \ w_{t}))
\tag 6
$$&lt;/p>
&lt;p>skip-gram 모델은 맥락의 수만큼 추측하기 때문에 그 손실 함수는 각 맥락에서 구한 손실의 총합이어야 하는 반면, CBOW 모델은 타깃 하나의 손실을 구한다.&lt;/p>
&lt;p>단어 분산 표현의 정밀도 면에서 skip-gram 모델의 결과가 더 좋은 경우가 많고, corpus가 클 수록 성능 면에서 skip-gram이 뛰어난 경향이 있다.&lt;/p>
&lt;h3 id="통계-기반-vs-추론-기반">통계 기반 vs 추론 기반&lt;/h3>
&lt;p>통계 기반 기법과 추론 기반 기법인 word2vec은 학습과 갱신 방식에서 차이를 보인다.&lt;/p>
&lt;p>통계 기반은 새 단어 추가 시 처음부터 다시 계산해야 하지만, word2vec은 기존 가중치를 활용해 효율적으로 갱신할 수 있다. 단어의 유사성과 복잡한 패턴 인코딩에서도 word2vec이 더 복잡한 관계를 파악할 수 있으며, &amp;lsquo;king - man + woman = queen&amp;rsquo; 같은 유추 문제를 풀 수 있다.&lt;/p>
&lt;p>그러나 실제 유사성 평가에서는 두 기법 간 우열을 가리기 어렵다. 추론 기반과 통계 기반은 서로 관련되어 있으며, 이를 바탕으로 추론 기반과 통계 기반을 융합한 GloVe 기법이 등장하여 두 방법의 장점을 결합했다.&lt;/p></description></item><item><title>단어의 분산 표현</title><link>https://gyeongmin.kr/p/word-distributed-representation/</link><pubDate>Mon, 27 Nov 2023 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/word-distributed-representation/</guid><description>&lt;img src="https://gyeongmin.kr/images/deep-learning-from-scratch.jpeg" alt="Featured image of post 단어의 분산 표현" />&lt;blockquote>
&lt;p>본 포스팅은 &amp;lsquo;밑바닥부터 시작하는 딥러닝 2&amp;rsquo; 교재를 참고했습니다.&lt;/p>
&lt;/blockquote>
&lt;h2 id="자연어-처리와-단어의-의미">자연어 처리와 단어의 의미&lt;/h2>
&lt;p>&lt;strong>자연어&lt;/strong>(Natural Language)란 우리가 평소에 사용하는 언어, 예를 들어 한국어나 영어를 말한다. &lt;strong>자연어 처리&lt;/strong>(NLP, Natural Language Processing)는 이러한 자연어를 컴퓨터가 이해하도록 만드는 기술 분야이다.&lt;/p>
&lt;p>우리의 말은 문자로 이루어져 있고, 말의 의미는 &lt;strong>단어&lt;/strong>로 구성된다. 따라서 컴퓨터가 자연어를 이해하도록 하려면 우선 단어의 의미부터 이해시켜야 한다.&lt;/p>
&lt;h2 id="시소러스">시소러스&lt;/h2>
&lt;blockquote>
&lt;p>단어의 의미를 나타내는 가장 Naive한 방법&lt;/p>
&lt;/blockquote>
&lt;p>사람이 직접 단어의 의미를 정의하는 방식으로, 쉽게 말해 &amp;lsquo;유의어 사전&amp;rsquo;이다.&lt;/p>
&lt;p>car, auto, automobile은 모두 자동차를 나타낸다. 시소러스에서는 이러한 유의어/동의어를 한 그룹으로 분류한다.&lt;/p>
&lt;pre class="mermaid">graph LR
car~~~auto~~~automobile
&lt;/pre>
&lt;p>또한 단어 간의 상위/하위, 전체/부분 등 세세한 관계까지 정의하기도 한다.&lt;/p>
&lt;pre class="mermaid">flowchart TD
a[object] --> b[mortor vehicle]
b --> d[go-cart]
b --> c[car]
b --> e[truck]
c --> f[suv]
c --> g[compact]
c --> h[hatch-back]
&lt;/pre>
&lt;h3 id="wordnet">WordNet&lt;/h3>
&lt;p>1985년 구축된 WordNet은 자연어 처리 분야에서 가장 유명한 시소러스이다.&lt;/p>
&lt;p>WordNet을 사용하면 유의어를 얻거나, 단어 네트워크를 사용해 단어 간의 유사도를 구할 수 있다.&lt;/p>
&lt;h3 id="문제점">문제점&lt;/h3>
&lt;p>사람이 수작업으로 라벨링 해야하기에 여러 단점이 존재한다.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>시대 변화에 대응하기 어렵다.&lt;/p>
&lt;ul>
&lt;li>단어의 의미는 시간이 지남에 따라 변하기도 하고, 새로운 단어가 생기기도 한다.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>비용이 많이 든다.&lt;/p>
&lt;ul>
&lt;li>영어 단어만 해도 1000만개가 넘으며, 이는 높은 인적 비용을 요구한다.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>단어 간의 미묘한 차이를 표현할 수 없다.&lt;/p>
&lt;ul>
&lt;li>예를 들어 빈티지와 레트로의 경우 의미는 같지만, 용법은 다르다. 시소러스는 이러한 차이를 표현할 수 없다.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="통계-기반-기법">통계 기반 기법&lt;/h2>
&lt;p>통계 기반 기법을 사용하기 위해 우리는 말뭉치(corpus)를 이용할 것이다.&lt;/p>
&lt;p>말뭉치란 자연어처리 연구나 어플리케이션을 위해 수집된 대량의 텍스트 데이터로, 대표적인 말뭉치는 위키백과, 구글뉴스, 셰익스피어의 소설 등이 있다.&lt;/p>
&lt;h3 id="말뭉치-전처리">말뭉치 전처리&lt;/h3>
&lt;p>작은 말뭉치를 전처리하는 과정을 살펴보자.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;You say goodbye and I say hello.&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">lower&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="c1"># 모두 소문자로 변환&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">replace&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;.&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39; .&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># &amp;#39;.&amp;#39;을 &amp;#39; .&amp;#39;으로 변환&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">text&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s1">&amp;#39;you say goodbye and i say hello .&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>모든 단어를 소문자로 변환하고, 단어의 마지막 점을 띄워줬다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">words&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="c1"># 공백을 기준으로 나눔&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">words&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;you&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;say&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;goodbye&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;and&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;i&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;say&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;hello&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;.&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>공백을 기준으로 나눠, 리스트에 담았다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">word_to_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">id_to_word&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">word&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">words&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">...&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="n">word&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">word_to_id&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">...&lt;/span> &lt;span class="n">new_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">word_to_id&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">...&lt;/span> &lt;span class="n">word_to_id&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">new_id&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">...&lt;/span> &lt;span class="n">id_to_word&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">new_id&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">word&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;code>word_to_id&lt;/code> 의 경우 key가 단어, value는 id이다. &lt;code>id_to_word&lt;/code>는 그 반대이다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">id_to_word&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;you&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;say&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;goodbye&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;and&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;i&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;hello&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s1">&amp;#39;.&amp;#39;&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">word_to_id&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>&lt;span class="s1">&amp;#39;you&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;say&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;goodbye&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;and&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;i&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;hello&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;.&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>마지막으로 단어 목록을 단어 ID 목록으로 변환하면 된다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">corpus&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">word_to_id&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">w&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">w&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">words&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">corpus&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">array&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>이렇게 범주형 변수를 숫자로 바꾸는 것을 &lt;strong>원 핫 인코딩(one-hot encodeing)&lt;/strong> 이라고 한다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">preprocess&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">lower&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">replace&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;.&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39; .&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">words&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">text&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39; &amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">word_to_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">id_to_word&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">word&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">words&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">word&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">word_to_id&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">new_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">word_to_id&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">word_to_id&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">new_id&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">id_to_word&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">new_id&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">word&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">corpus&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">word_to_id&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">w&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">w&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">words&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">corpus&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_to_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">id_to_word&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>위 과정을 합쳐 단어를 전처리하는 preprocess 함수를 구현했다.&lt;/p>
&lt;h3 id="분포-가설과-분산-표현">분포 가설과 분산 표현&lt;/h3>
&lt;blockquote>
&lt;p>비슷한 위치에서 등장한 단어는 비슷한 의미를 가지지 않을까?&lt;/p>
&lt;/blockquote>
&lt;p>&amp;ldquo;단어의 의미는 주변 단어에 의해 형성된다.&amp;rdquo; 라는 것을 &lt;strong>분포 가설&lt;/strong>이라고 한다.&lt;/p>
&lt;p>단어 자체에는 의미가 없고, 그 단어가 사용 된 맥락이 의미를 형성한다는 것이다. 여기서 맥락이란 특정 단어를 중심에 둔 그 주변 단어를 말한다.&lt;/p>
&lt;p>좌우 모든 단어를 고려하며 계산하면 컴퓨팅 비용이 너무 많이 들기에, 우리는 특정 크기만큼만 고려할 것이다. 즉, 슬라이딩 윈도우를 적용할 것이다. &amp;lsquo;맥락의 크기&amp;rsquo;는 슬라이딩 윈도우의 사이즈와 같다.&lt;/p>
&lt;p>&lt;strong>분산 표현&lt;/strong> 이란 &lt;strong>분포 가설에 기반해 주변 단어의 분포를 기준으로 단어의 벡터 표현을 결정하는 것&lt;/strong> 이다.&lt;/p>
&lt;h3 id="동시-행렬-발생">동시 행렬 발생&lt;/h3>
&lt;p>분포 가설에 기초해 단어를 벡터로 나타내 보자.&lt;/p>
&lt;p>가장 간단한 방법은 한 단어에 주목하여, 주변에 어떤 단어가 몇 번 등장했는지 계산하는 것이다. 이는 통계 기반 기법(statistical based)이라고 한다.&lt;/p>
&lt;blockquote>
&lt;p>{&amp;lsquo;you&amp;rsquo;: 0, &amp;lsquo;say&amp;rsquo;: 1, &amp;lsquo;goodbye&amp;rsquo;: 2, &amp;lsquo;and&amp;rsquo;: 3, &amp;lsquo;i&amp;rsquo;: 4, &amp;lsquo;hello&amp;rsquo;: 5, &amp;lsquo;.&amp;rsquo;: 6}&lt;/p>
&lt;/blockquote>
&lt;p>예를 들어, &amp;lsquo;&lt;U>you&lt;/U> &lt;strong>say&lt;/strong> &lt;U>goodbye&lt;/U> and &lt;U>i&lt;/U> &lt;strong>say&lt;/strong> &lt;U>hello&lt;/U> .&amp;rsquo; 에서 &amp;lsquo;say&amp;rsquo;를 기준으로 살펴보자.&lt;/p>
&lt;p>&amp;lsquo;say&amp;rsquo; 좌우로 &amp;lsquo;you&amp;rsquo;, &amp;lsquo;goodbye&amp;rsquo;, &amp;lsquo;i&amp;rsquo;, &amp;lsquo;hello&amp;rsquo; 가 있다.&lt;/p>
&lt;p>이는 벡터 &amp;lsquo;[1, 0, 1, 0, 1, 1, 0]&amp;rsquo; 으로 표현 할 수 있을 것이다.&lt;/p>
&lt;p>이것을 모든 단어에 대해 적용시킨다면 아래와 같은 테이블을 얻을 수 있을 것이다.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">&lt;/th>
&lt;th style="text-align:center">you&lt;/th>
&lt;th style="text-align:center">say&lt;/th>
&lt;th style="text-align:center">goodbye&lt;/th>
&lt;th style="text-align:center">and&lt;/th>
&lt;th style="text-align:center">i&lt;/th>
&lt;th style="text-align:center">hello&lt;/th>
&lt;th style="text-align:center">.&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">you&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">say&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">goodbye&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">and&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">i&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">hello&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">.&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>이것을 &lt;strong>동시 발생 행렬&lt;/strong> 이라고 한다.&lt;/p>
&lt;p>동시 발생 행렬을 만드는 코드는 아래와 같다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">create_co_matrix&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">corpus&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">vocab_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">window_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">corpus_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">corpus&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">co_matrix&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zeros&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="n">vocab_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">vocab_size&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">int32&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">idx&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_id&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">corpus&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">window_size&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">left_idx&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">idx&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">i&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">right_idx&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">idx&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">i&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">left_idx&lt;/span> &lt;span class="o">&amp;gt;=&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">left_word_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">corpus&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">left_idx&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">co_matrix&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">word_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">left_word_id&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">right_idx&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">corpus_size&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">right_word_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">corpus&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">right_idx&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">co_matrix&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">word_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">right_word_id&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">co_matrix&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="벡터간-유사도">벡터간 유사도&lt;/h3>
&lt;p>앞서 구한 행렬을 통해 벡터 간의 유사도를 구한다면 단어 간의 유사도를 구할 수 있을 것이다.&lt;/p>
&lt;p>벡터의 유사도를 측정하는 대표적인 방법으로는 벡터의 내적이나 유클리드 거리, 코사인 유사도가 있다. 이 중, 우리는 코사인 유사도를 사용할 것이다.&lt;/p>
&lt;p>$$
\tag{1}
\text{similarity}(A, B)=\frac{A⋅B}{||A||\ ||B||}=\frac{\sum_{i=1}^{n}{A_{i}B_{i}}}{\sqrt{\sum_{i=1}^{n}(A_{i})^2}\sqrt{\sum_{i=1}^{n}(B_{i})^2}}
$$&lt;/p>
&lt;p>[식 1]의 분자에는 벡터의 내적이, 분모에는 각 벡터의 노름(norm)이 등장한다. 노름은 벡터의 크기를 나타낸 것으로, 여기선 L2 노름을 계산한다.&lt;/p>
&lt;blockquote>
&lt;p>코사인 유사도는 두 벡터가 가르키는 방향이 얼마나 유사한지를 나타낸다. 방향이 같으면 1, 반대면 -1이다.&lt;/p>
&lt;/blockquote>
&lt;p>파이썬 코드로는 아래와 같이 나타낼 수 있다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">cos_similarity&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">eps&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">1e-8&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">nx&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sqrt&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">**&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">eps&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># x의 정규화&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">ny&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">y&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sqrt&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">y&lt;/span> &lt;span class="o">**&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">eps&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># y의 정규화&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">nx&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ny&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>0으로 나누어 오류가 나는 일이 없도록 $10^{-8}$ 이라는 작은 값을 더해주는 것을 볼 수 있다.&lt;/p>
&lt;h3 id="유사-단어의-랭킹">유사 단어의 랭킹&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">most_similar&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">query&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_to_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">id_to_word&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_matrix&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">top&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">query&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">word_to_id&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="si">%s&lt;/span>&lt;span class="s1"> is not found&amp;#39;&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="n">query&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s1">[query] &amp;#39;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">query&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">query_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">word_to_id&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">query&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">query_vec&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">word_matrix&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">query_id&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">vocab_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">id_to_word&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">similarity&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zeros&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">vocab_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">vocab_size&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">similarity&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">cos_similarity&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">word_matrix&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">query_vec&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">count&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">similarity&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">argsort&lt;/span>&lt;span class="p">():&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">id_to_word&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">query&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">continue&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39; &lt;/span>&lt;span class="si">%s&lt;/span>&lt;span class="s1">: &lt;/span>&lt;span class="si">%s&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">id_to_word&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">similarity&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">count&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">count&lt;/span> &lt;span class="o">&amp;gt;=&lt;/span> &lt;span class="n">top&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>위 코드로 &amp;lsquo;you&amp;rsquo; 와 유사한 단어를 찾아보자.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">&lt;/th>
&lt;th>Value&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">goodbye&lt;/td>
&lt;td>0.7071067691154799&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">i&lt;/td>
&lt;td>0.7071067691154799&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">hello&lt;/td>
&lt;td>0.7071067691154799&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">say&lt;/td>
&lt;td>0.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">and&lt;/td>
&lt;td>0.0&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&amp;lsquo;goodbye&amp;rsquo;, &amp;lsquo;i&amp;rsquo;, &amp;lsquo;hello&amp;rsquo;의 경우 &amp;lsquo;say&amp;rsquo;나 &amp;lsquo;and&amp;rsquo;에 비해 유사하다고 볼 수 있다.&lt;/p>
&lt;h2 id="통계-기반-기법의-개선">통계 기반 기법의 개선&lt;/h2>
&lt;h3 id="상호정보량">상호정보량&lt;/h3>
&lt;blockquote>
&lt;p>발생 횟수는 좋은 특징이 아니다&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>동시 발생 행렬&lt;/strong>은 두 단어가 동시에 발생한 빈도를 측정한다. 하지만 이것만으로는 부족하다. &amp;rsquo;the&amp;rsquo;, &amp;rsquo;this&amp;rsquo;처럼 &lt;strong>고빈도 단어&lt;/strong> 의 경우를 생각해 보자.&lt;/p>
&lt;p>&amp;lsquo;drive&amp;rsquo;, &amp;rsquo;the&amp;rsquo; 중에 &amp;lsquo;car&amp;rsquo;와 더 유사한 단어는 무엇인가? 모두 &amp;lsquo;drive&amp;rsquo;와 유사한 단어로 &amp;lsquo;car&amp;rsquo;를 고를 것이다.&lt;/p>
&lt;p>하지만 동시 발생 빈도는 &amp;rsquo;the&amp;rsquo;가 압도적으로 높을 것이다. 동시 발생 행렬에서는 &amp;rsquo;the&amp;rsquo; 자체가 문서에서 &lt;strong>더 많이 등장&lt;/strong>하기에, 더 높은 유사성을 갖는다고 잘못 평가할 수 있다.&lt;/p>
&lt;p>이 문제를 해결하기 위해 &lt;strong>점별 상호정보량&lt;/strong>(PMI, Pointwise Mutual Information) 이라는 척도를 사용할 것이다.&lt;/p>
&lt;p>&lt;strong>PMI&lt;/strong>는 확률 변수 $x$와 $y$에 대해 다음과 같은 식으로 정의된다.&lt;/p>
&lt;p>$$
\tag{2}
\text{PMI}(x,y)=\log_2\frac{P(x,y)}{P(x)P(y)}
$$&lt;/p>
&lt;p>[식 2]에서 $P(x)$는 $x$가 일어날 확률, $P(y)$는 $y$가 일어날 확률, $P(x,y)$는 $x, y$가 동시에 일어날 확률이다. PMI가 높을 수록 관련성이 높다는 의미이다.&lt;/p>
&lt;p>자연어 처리에서 $P(x)$는 말뭉치에서 $x$라는 단어가 등장할 확률이다. 예를 들어, 단어 100,000개의 말뭉치에서 &amp;rsquo;the&amp;rsquo;라는 단어가 100번 등장했다면, $P(`\text{the}&amp;rsquo;) = 0.0001$이다.&lt;/p>
&lt;p>하지만 PMI도 문제가 있다. 동시 발생 횟수가 0이라면 PMI 값은 $-\infty$가 된다.&lt;/p>
&lt;p>따라서 &lt;strong>PPMI&lt;/strong>(Positive PMI) 라는 척도를 쓴다. 이는 다음과 같다.&lt;/p>
&lt;p>$$
\tag{3}
\text{PPMI}(x, y) = \max(0, \text{PMI}(x,y))
$$&lt;/p>
&lt;p>[식 3]을 보면, PPMI는 PMI값이 음수면 0으로 취급한다는 것을 확인할 수 있다.&lt;/p>
&lt;p>이제 PPMI를 파이썬으로 구현해 보자.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">ppmi&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">C&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">eps&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">1e-8&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">M&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zeros_like&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">C&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">float32&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">N&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">C&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">S&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">C&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">axis&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">C&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">j&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">C&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">pmi&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">log2&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">C&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">j&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">N&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">S&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">j&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">S&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">eps&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">M&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">j&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">max&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">pmi&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">M&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>이제 동시 발생 행렬을 PPMI로 변환해 보자.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;You say goodbye and I say hello.&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">corpus&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_to_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">id_to_word&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">preprocess&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">vocab_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">word_to_id&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">C&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">create_co_matrix&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">corpus&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">vocab_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">W&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ppmi&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">C&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_printoptions&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">precision&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 유효 자릿수를 세 자리로 표시&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;동시발생 행렬&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">C&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;-&amp;#39;&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="mi">50&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;PPMI&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>위 코드를 실행시킨 결과는 아래와 같다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-txt" data-lang="txt">&lt;span class="line">&lt;span class="cl">동시발생 행렬
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[[0 1 0 0 0 0 0]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [1 0 1 0 1 1 0]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [0 1 0 1 0 0 0]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [0 0 1 0 1 0 0]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [0 1 0 1 0 0 0]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [0 1 0 0 0 0 1]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [0 0 0 0 0 1 0]]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">--------------------------------------------------
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">PPMI
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[[0. 1.807 0. 0. 0. 0. 0. ]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [1.807 0. 0.807 0. 0.807 0.807 0. ]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [0. 0.807 0. 1.807 0. 0. 0. ]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [0. 0. 1.807 0. 1.807 0. 0. ]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [0. 0.807 0. 1.807 0. 0. 0. ]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [0. 0.807 0. 0. 0. 0. 2.807]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [0. 0. 0. 0. 0. 2.807 0. ]]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>이제 더 좋은 단어 벡터를 얻었다.&lt;/p>
&lt;p>하지만 아직 문제점이 있다. 벡터의 크기가 너무 크다는 것이다. 단어의 개수가 10만개라면, 벡터의 차운 수도 10만이 된다.&lt;/p>
&lt;p>또한, 대부분 0으로 구성된 희소행렬(Sparse Matrix)이다.&lt;/p>
&lt;p>이는 매우 비효율적이고, 노이즈에 취약하다.&lt;/p>
&lt;h3 id="차원-축소">차원 축소&lt;/h3>
&lt;p>차원 축소는 중요한 정보는 최대한 유지하되, 벡터의 차원을 줄이는 것이다. 그 중 특잇값 분해를 적용해보자.&lt;/p>
&lt;p>특잇값 분해에 대한 자세한 설명은 &lt;a class="link" href="https://pasus.tistory.com/15" target="_blank" rel="noopener"
>여기&lt;/a> 블로그를 참고하자.&lt;/p>
&lt;p>특잇값 분해를 사용한 파이썬 코드는 아래와 같다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="n">text&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;You say goodbye and I say hello.&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">corpus&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_to_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">id_to_word&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">preprocess&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">text&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">vocab_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">id_to_word&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">C&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">create_co_matrix&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">corpus&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">vocab_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">window_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">W&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ppmi&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">C&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">U&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">S&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">V&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">linalg&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">svd&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_printoptions&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">precision&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">C&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">U&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">word&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_id&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">word_to_id&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">items&lt;/span>&lt;span class="p">():&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">annotate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">word&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">U&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">word_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">U&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">word_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">]))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">scatter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">U&lt;/span>&lt;span class="p">[:,&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">U&lt;/span>&lt;span class="p">[:,&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">alpha&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.5&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">show&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://gyeongmin.kr/p/word-distributed-representation/myplot.png"
width="640"
height="480"
srcset="https://gyeongmin.kr/p/word-distributed-representation/myplot_huf803c14a96123a2f3e5d87800bfe075b_11535_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/word-distributed-representation/myplot_huf803c14a96123a2f3e5d87800bfe075b_11535_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="133"
data-flex-basis="320px"
>&lt;/p>
&lt;p>위 코드는 동시발생 행렬에 SVD를 적용한 후 각 단어를 2차원 벡터로 변환한 것을 시각화 한 것이다.&lt;/p>
&lt;h3 id="ptb-데이터셋-평가">PTB 데이터셋 평가&lt;/h3>
&lt;p>이번에는 많은 양의 데이터를 처리해야 하므로, sklearn의 고속 SVD를 사용하자.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">dataset&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">ptb&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">sklearn.utils.extmath&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">randomized_svd&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">window_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">wordvec_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">100&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">corpus&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_to_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">id_to_word&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ptb&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">load_data&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;train&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">vocab_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">word_to_id&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">C&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">create_co_matrix&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">corpus&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">vocab_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">window_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">W&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ppmi&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">C&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">verbose&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">U&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">S&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">V&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">randomized_svd&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">n_components&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">wordvec_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">n_iter&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">word_vecs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">U&lt;/span>&lt;span class="p">[:,&lt;/span> &lt;span class="p">:&lt;/span>&lt;span class="n">wordvec_size&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">querys&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;you&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;year&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;car&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;toyota&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">query&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">querys&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">most_similar&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">query&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_to_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">id_to_word&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">word_vecs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">top&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>이제 드디어 단어의 의미를 벡터로 잘 인코딩했다.&lt;/p>
&lt;p>말뭉치를 사용해 맥락에 속한 단어의 등장 횟수를 센 후 PPMI 행렬로 변환하고, 다시 SVD를 이용해 차원을 감소시킴으로써 더 좋은 단어 벡터를 얻어냈다.&lt;/p>
&lt;p>이것이 단어의 분산 표현이고, 각 단어는 고정 길이의 밀집벡터로 표현되었다.&lt;/p>
&lt;blockquote>
&lt;p>단어의 벡터 공간에서는 의미가 가까운 단어는 그 거리도 가깝다.&lt;/p>
&lt;/blockquote></description></item><item><title>신경망의 학습</title><link>https://gyeongmin.kr/p/neural-network-trainning/</link><pubDate>Tue, 21 Nov 2023 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/neural-network-trainning/</guid><description>&lt;img src="https://gyeongmin.kr/images/deep-learning-from-scratch.jpeg" alt="Featured image of post 신경망의 학습" />&lt;blockquote>
&lt;p>본 포스팅은 &amp;lsquo;밑바닥부터 시작하는 딥러닝 2&amp;rsquo; 교재를 참고했습니다.&lt;/p>
&lt;/blockquote>
&lt;h1 id="신경망의-학습">신경망의 학습&lt;/h1>
&lt;blockquote>
&lt;p>학습되지 않은 신경망은 좋은 추론을 할 수 없다. 따라서 학습을 먼저 수행하고, 학습된 매개변수를 이용해 추론을 수행해야 한다.&lt;/p>
&lt;/blockquote>
&lt;h2 id="손실-함수">손실 함수&lt;/h2>
&lt;blockquote>
&lt;p>신경망 학습에는 학습이 얼마나 잘 되고 있는지를 알기 위한 척도가 필요하다.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;strong>손실&lt;/strong>이란 신경망이 예측한 결과를 비교하여 예측이 얼마나 나쁜가를 산출한 &lt;strong>스칼라 값&lt;/strong>으로, 성능을 나타내는 척도이다.&lt;/p>
&lt;p>이것을 구하는 것이 바로 &lt;strong>손실 함수&lt;/strong>이다.&lt;/p>
&lt;p>우리는 소프트맥스와 교차 엔트로피 오차를 통해 손실 함수를 구현할 것이다.&lt;/p>
&lt;h2 id="소프트맥스">소프트맥스&lt;/h2>
&lt;p>$$
p_k = \frac{\exp{(s_k)}}{\sum_{k=1}^{n}{\exp{(s_k)}}} \quad for \ k=1,2,\dots,k
\tag{1}
$$&lt;/p>
&lt;p>[식 1]에서 소프트맥스 함수의 출력의 각 원소 $p_k$는 $0 \leq p_k \leq 1,\space p_k \in \mathbb{R}$ 이다.&lt;/p>
&lt;p>따라서 소프트맥스의 출력은 &lt;strong>확률&lt;/strong>로 해석할 수 있다. 우리는 이것을 교차 엔트로피 오차에 입력할 것이다.&lt;/p>
&lt;h2 id="교차-엔트로피-오차">교차 엔트로피 오차&lt;/h2>
&lt;p>$$
Loss = - \sum_{k}t_k \log{p_k}
\tag{2}
$$&lt;/p>
&lt;p>[식 2]에서 $t_k$는 $k$번째 클래스의 정답 레이블이다. $t = \begin{bmatrix} 0, 1, 1 \end{bmatrix}$ 과 같이 one-hot vector로 표기한다.&lt;/p>
&lt;blockquote>
&lt;p>one-hot vector는 단 하나의 원소만 1 이고 그 외에는 0인 벡터이다.&lt;/p>
&lt;/blockquote>
&lt;p>미니 배치를 고려하면 교차 엔트로피 오차의 식은 아래와 같이 바뀌게 된다.&lt;/p>
&lt;p>$$
Loss = - \frac{1}{N} \sum_{n} \sum_{k}t_{nk} \log{p_{nk}}
\tag{3}
$$&lt;/p>
&lt;p>[식 3]에서 $N$은 미니 배치의 개수, $t_{nk}$는 $n$번째 데이터의 $k$차원째의 값,
$p_{nk}$는 신경망의 출력, $t_{nk}$는 정답 레이블이다.&lt;/p>
&lt;p>이는 N으로 나눠서 1 개당의 &lt;strong>평균 손실 함수&lt;/strong>를 구하는 것이다. 미니배치의 크기에 관계없이 항상 일관된 척도를 얻을 수 있다.&lt;/p>
&lt;h2 id="행렬의-미분">행렬의 미분&lt;/h2>
&lt;blockquote>
&lt;p>신경망 학습의 목표는 손실을 최소화하는 매개변수를 찾는 것이다. 이때 중요한 것이 바로 미분과 기울기이다.&lt;/p>
&lt;/blockquote>
&lt;p>행렬을 입력이나 출력으로 가지는 함수를 미분하는 것을 &lt;strong>행렬 미분&lt;/strong>이라고 한다. (정확하게는 편미분이다.)&lt;/p>
&lt;p>또한 행렬미분에는 분자중심 표현법과 분모중심 표현법 두 가지가 있는데, 본 포스팅에서는 분모중심 표현법으로 서술하겠다.&lt;/p>
&lt;blockquote>
&lt;p>행렬 미분에 대한 상세한 정의는 &lt;a class="link" href="https://geniewishescometrue.tistory.com/entry/%EC%84%A0%ED%98%95%EB%8C%80%EC%88%98%ED%95%99-%ED%96%89%EB%A0%AC%EB%AF%B8%EB%B6%84-Matrix-Calculus" target="_blank" rel="noopener"
>여기&lt;/a>를 참고하기 바란다.&lt;/p>
&lt;/blockquote>
&lt;p>$$
\frac{\partial L}{\partial \mathbf{x}}=
\begin{pmatrix} \frac{\partial L}{\partial x_1} &amp;amp; \frac{\partial L}{\partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial L}{\partial x_n}
\end{pmatrix}
\tag{4}
$$&lt;/p>
&lt;p>$L$은 스칼라, $x$는 벡터인 함수 $L=f(x)$가 있을 때, $x_i$에 대한 $L$의 미분은 $\frac{\partial y}{\partial x_i}$로 쓸 수 있으며, 이를 정리하면 [식 4]와 같다.&lt;/p>
&lt;p>$$
\frac{\partial L}{\partial \mathbf{W}}=
\begin{pmatrix}
\frac{\partial L}{\partial W_{11}} &amp;amp; \cdots &amp;amp; \frac{\partial L}{\partial W_{1n}}
\\ \vdots &amp;amp; \ddots
\\ \frac{\partial L}{\partial W_{m1}} &amp;amp; &amp;amp; \frac{\partial L}{\partial W_{mn}}
\end{pmatrix}
\tag{5}
$$&lt;/p>
&lt;p>$\mathbf{W}$가 $m \times n$ 행렬이라면, $L = g(\mathbf{W})$ 함수의 기울기는 [식 5] 같이 쓸 수 있다.&lt;/p>
&lt;p>여기서 중요한 점은 $\mathbf{W}$와 $\frac{\partial L}{\partial \mathbf{x}}$의 형상이 같다는 것이다. 이 성질을 이용하면 매개변수 갱신과 연쇄 법칙을 쉽게
구현할 수 있다.&lt;/p>
&lt;h2 id="연쇄-법칙">연쇄 법칙&lt;/h2>
&lt;blockquote>
&lt;p>우리는 신경망의 학습을 위해 각 매개변수에 대한 손실의 기울기를 구해 매개변수를 갱신할 것이다. 신경망의 기울기는 오차역전파법 (back-propagation)을 통해 구할 수 있으며, 이 때 필요한 것이 연쇄 법칙이다.&lt;/p>
&lt;/blockquote>
&lt;p>$y=f(x)$와 $z=g(y)$라는 두 함수가 있을 때, $z=g(f(x))$이다.&lt;/p>
&lt;p>$$
\frac{\partial z}{\partial x} = \frac{\partial z}{\partial y} \frac{\partial y}{\partial x}
\tag{6}
$$&lt;/p>
&lt;p>$x$에 대한 $z$의 미분은 [식 6]과 같이 $y=f(x)$의 미분과 $z=g(y)$의 미분을 곱해 구할 수 있다. 이것이 바로 연쇄 법칙이다.&lt;/p>
&lt;p>즉, 함수가 아무리 복잡하더라도 개별 함수들의 미분을 통해 효율적인 계산을 할 수 있다는 것이다.&lt;/p>
&lt;h2 id="가중치-갱신">가중치 갱신&lt;/h2>
&lt;p>신경망의 학습은 다음 순서로 수행된다.&lt;/p>
&lt;pre class="mermaid">graph LR
a((미니배치))-->b((기울기 계산))-->c((매개변수 갱신))-->a
&lt;/pre>
&lt;p>우선 미니배치에서 데이터를 선택하고, 이어서 오차역전파법으로 가중치의 기울기를 얻는다. 이 기울기는 현재의 가중치 매개변수에서 손실을 가장 크게 하는 방향을 가리킨다. 따라서 매개변수를 그 기울기와 반대 방향으로 갱신하면 손실을 줄일 수 있다. 이것이 바로 &lt;strong>경사하강법&lt;/strong>이다.&lt;/p>
&lt;h2 id="확률적경사하강법">확률적경사하강법&lt;/h2>
&lt;p>확률적 경사하강법 (Stochastic Gradient Descent)은 무작위로 선택된 데이터(미니배치)에 대한 기울기를 이용하여, 현재의 가중치를 기울기 방향으로 일정한 거리만큼 갱신한다.&lt;/p>
&lt;p>$$
W \gets {W} - \eta {\frac{\partial {L}}{\partial {W}}}
\tag{7}
$$&lt;/p>
&lt;p>[식 7]에서 갱신하는 가중치 매개변수는 $\mathbf{W}$
이고, $\mathbf{W}$에 대한 손실 함수의 기울기는 $\frac{\partial {L}}{\partial {W}}$이다. $\eta$는 학습률 (learning rate)을 나타내고, 0.01이나 0.001 같은 값을 미리 정해서 사용한다.&lt;/p>
&lt;p>이것을 파이썬으로 구현하면 아래와 같다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">SGD&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">lr&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.01&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">lr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">lr&lt;/span> &lt;span class="c1"># 학습률&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">update&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">params&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">grads&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">params&lt;/span>&lt;span class="p">)):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">params&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">-=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">lr&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">grads&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="신경망-예제">신경망 예제&lt;/h2>
&lt;p>이전 포스팅에서 설계한 신경망에 Softmax 레이어와 Cross Entropy Error 레이어를 새로 추가해 보자.&lt;/p>
&lt;pre class="mermaid">graph LR
x(x)==> A(Affine)
A==> B(Sigmoid)
B==> C(Affine)
C==>D(Softmax)
t(t)==>E
D==>E(Cross Entropy Error)
E==>F(L)
&lt;/pre>
&lt;p>$\textbf{x}$는 입력 데이터, $\textbf{t}$는 정답 레이블. $L$은 손실을 나타낸다.&lt;/p>
&lt;h2 id="sigmoid의-역전파-구현">Sigmoid의 역전파 구현&lt;/h2>
&lt;p>Sigmoid의 수식은 $y=\frac{1}{1+\exp{(-x)}}$이다. 그 미분은 아래 [식 7]과 같다.&lt;/p>
&lt;p>$$
\frac{\partial y}{\partial x} = y(1-y)
\tag{8}
$$&lt;/p>
&lt;p>이를 파이썬으로 구현하면 아래와 같다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">Sigmoid&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">exp&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dout&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">dout&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mf">1.0&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">out&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">out&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="affine의-역전파-구현">Affine의 역전파 구현&lt;/h2>
&lt;p>Affine의 역전파는 MatMul 노드와 Repeat 노드의 역전파를 수행하면 구할 수 있다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">Affine&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">W&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">W&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zeros_like&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zeros_like&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">b&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">None&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">W&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">out&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">matmul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">xz&lt;/span> &lt;span class="n">W&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">b&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">out&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dout&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">W&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dx&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">matmul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">doutz&lt;/span> &lt;span class="n">W&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">T&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dW&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">matmul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">T&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dout&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">db&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dout&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">axis&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="o">...&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dW&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="o">...&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">db&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">dx&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="twolayernet-구현">TwoLayerNet 구현&lt;/h2>
&lt;p>Sigmoid와 Affine 레이어의 back-propagation을 구현했으니, 이제 &lt;code>TwoLayerNet&lt;/code> 클래스를 완성해 보자.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">SoftmaxWithLoss&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[],&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">y&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">None&lt;/span> &lt;span class="c1"># softmax의 출력&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">t&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">None&lt;/span> &lt;span class="c1"># 정답 레이블&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">t&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">t&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">t&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">y&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">softmax&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 정답 레이블이 원핫 벡터일 경우 정답의 인덱스로 변환&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">t&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">size&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">y&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">size&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">t&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">t&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">argmax&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">axis&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">cross_entropy_error&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">y&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">t&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">loss&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">TwoLayerNet&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">input_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">hidden_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">output_size&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">I&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">H&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">O&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">input_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">hidden_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">output_size&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">W1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.01&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">I&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">H&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">b1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zeros&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">H&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">W2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.01&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">H&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">O&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">b2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zeros&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">O&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">layers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Affine&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Sigmoid&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Affine&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b2&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loss_layer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">SoftmaxWithLoss&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[],&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">layer&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">grads&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">predict&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">layer&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">x&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">t&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">score&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">predict&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loss_layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">score&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">t&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">loss&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dout&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dout&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">loss_layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dout&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">layer&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">reversed&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dout&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">backward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dout&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">dout&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>신경망의 추론</title><link>https://gyeongmin.kr/p/neural-network-inference/</link><pubDate>Mon, 20 Nov 2023 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/neural-network-inference/</guid><description>&lt;img src="https://gyeongmin.kr/images/deep-learning-from-scratch.jpeg" alt="Featured image of post 신경망의 추론" />&lt;blockquote>
&lt;p>본 포스팅은 &amp;lsquo;밑바닥부터 시작하는 딥러닝 2&amp;rsquo; 교재를 참고했습니다.&lt;/p>
&lt;/blockquote>
&lt;h1 id="신경망의-추론">신경망의 추론&lt;/h1>
&lt;blockquote>
&lt;p>추론이란 다중 클래스 분류 등의 문제에 답을 구하는 작업이다.&lt;/p>
&lt;/blockquote>
&lt;h2 id="신경망-예시">신경망 예시&lt;/h2>
&lt;blockquote>
&lt;p>신경망은 두뇌의 신경세포, 즉 뉴런이 연결된 형태를 모방한 모델이다.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://gyeongmin.kr/p/neural-network-inference/image.png"
width="527"
height="320"
srcset="https://gyeongmin.kr/p/neural-network-inference/image_hu6da0e4cb5786d7f007b46bb018fc88f8_111431_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/neural-network-inference/image_hu6da0e4cb5786d7f007b46bb018fc88f8_111431_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="신경망의 예시 (출처 : https://blog.skby.net)"
class="gallery-image"
data-flex-grow="164"
data-flex-basis="395px"
>&lt;/p>
&lt;p>위 신경망의 경우 입력층 4개, 중간층(은닉층) 2개, 출력층 3개로 구성되어 있다.&lt;/p>
&lt;p>입력층과 중간층 사이를 보면 인접한 층의 모든 뉴런들이 서로 연결되어 있는데, 이것을 &lt;strong>fully connected layer (완전연결계층)&lt;/strong> 이라고 한다.&lt;/p>
&lt;h2 id="가중치와-편향">가중치와 편향&lt;/h2>
&lt;p>각 노드 사이에는 &lt;strong>가중치&lt;/strong>가 존재한다. 가중치 값과 뉴런의 값을 곱해 그 합이 다음 뉴런의 입력으로 쓰인다.&lt;/p>
&lt;p>또한, 이 때 이전 뉴런의 값에 영향을 받지 않는 정수도 더해지는데, 이 정수를 &lt;strong>bias (편향)&lt;/strong> 이라고 한다.&lt;/p>
&lt;p>입력층의 데이터를 $\textbf{x}$, 가중치는 $\textbf{W}$, 편향은 $\textbf{b}$로 나타내면 은닉층의 뉴런 $\textbf{h}$는 다음과 같이 나타낼 수 있다.&lt;/p>
&lt;p>$$
\textbf{h} = \textbf{x} \textbf{W} + \textbf{b}
\tag{1}
$$&lt;/p>
&lt;h2 id="sigmoid-활성화-함수">Sigmoid 활성화 함수&lt;/h2>
&lt;blockquote>
&lt;p>완전연결계층에 의한 변환은 선형 변환이다. 여기에 비선형 효과를 부여하는 것이 바로 &lt;strong>활성화 함수&lt;/strong>이다. 이를 통해 신경망의 표현력을 높일 수 있다.&lt;/p>
&lt;/blockquote>
&lt;p>가장 대표적인 활성화 함수인 Sigmoid를 알아보자.&lt;/p>
&lt;pre class="mermaid">xychart-beta
title "Sigmoid"
y-axis 0 --> 1
x-axis [-5, "-4.5", -4, "-3.5", -3, "-2.5", -2, "-1.5", -1, "-0.5", 0, "0.5", 1, "1.5", 2, "2.5", 3, "3.5", 4, "4.5", 5]
line [0.0066928509242848554, 0.01098694263059318, 0.01798620996209156, 0.02931223075135632, 0.04742587317756678, 0.07585818002124355, 0.11920292202211755, 0.18242552380635635, 0.2689414213699951, 0.3775406687981454, 0.5, 0.6224593312018546, 0.7310585786300049, 0.8175744761936437, 0.8807970779778823, 0.9241418199787566, 0.9525741268224334, 0.9706877692486436, 0.9820137900379085, 0.9890130573694068, 0.9933071490757153]
&lt;/pre>
&lt;p>시그모이드 함수는 S자와 유사한 완만한 곡선을 가진다.
식은 아래와 같다.&lt;/p>
&lt;p>$$
\sigma(x)=\frac{1}{1+\exp(-x)}
\tag{2}
$$&lt;/p>
&lt;p>이를 파이썬으로 구현하면 다음과 같다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">sigmoid&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="err">：&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">exp&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="신경망과-순전파의-구현">신경망과 순전파의 구현&lt;/h2>
&lt;p>신경망 추론 과정에서 하는 처리는 순전파(forward propagation)에 해당한다.
말 그대로 입력층에서 출력층으로 향하는 전파이다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 시그모이드 함수에 의한 변환&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">Sigmoid&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="err">：&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="err">：&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">exp&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 완전연결계층에 의한 변환&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">Affine&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="err">（&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">W&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span>&lt;span class="err">）：&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">W&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="err">：&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">W&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">matmul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">W&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">b&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>완전연결계층에 의한 변환은 기하학에서의 Affine 변환에 해당한다.&lt;/p>
&lt;/blockquote>
&lt;p>입력 $\textbf{x}$가 Affine 계층 Sigmoid 계층 Affine 계층을 차례로 거쳐 점수인 $\textbf{s}$를 출력하는 신경망을 만들어 보자.&lt;/p>
&lt;pre class="mermaid">graph LR
X==> A[Affine]
A==> B[Sigmoid]
B==> C[Affine]
C==> S[S]
&lt;/pre>
&lt;p>이 신경망을 파이썬으로 구현하면 아래와 같다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="k">class&lt;/span> &lt;span class="nc">TwoLayerNet&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="fm">__init__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">input_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">hidden_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">output_size&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="err">：&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">I&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">H&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">O&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">input_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">hidden_size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">output_size&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 가중치와 편향 초기화&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">W1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">I&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">H&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">b1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">H&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">W2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">H&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">O&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">b2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">O&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 계층 생성&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">layers&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Affine&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b1&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Sigmoid&lt;/span>&lt;span class="p">(),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Affine&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">W2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b2&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 모든 가중치를 리스트에 모은다.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">layer&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="n">layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">params&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">def&lt;/span> &lt;span class="nf">predict&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="err">：&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">layer&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="bp">self&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">forward&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">x&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>위에서 구현한 &lt;code>TwoLayerNet&lt;/code> 클래스를 이용해 신경망의 추론을 수행해 보자.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">randn&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">TwoLayerNet&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">s&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">predict&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>이처럼 계층을 클래스로 만들어두면 신경망을 쉽게 사용할 수 있다.&lt;/p></description></item><item><title>기초 선형대수 - 스칼라, 벡터, 행렬</title><link>https://gyeongmin.kr/p/basic-linear-algebra/</link><pubDate>Wed, 15 Nov 2023 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/basic-linear-algebra/</guid><description>&lt;img src="https://gyeongmin.kr/images/deep-learning-from-scratch.jpeg" alt="Featured image of post 기초 선형대수 - 스칼라, 벡터, 행렬" />&lt;blockquote>
&lt;p>본 포스팅은 &amp;lsquo;밑바닥부터 시작하는 딥러닝 2&amp;rsquo; 교재를 참고했습니다.&lt;/p>
&lt;/blockquote>
&lt;h1 id="기초-선형대수">기초 선형대수&lt;/h1>
&lt;h2 id="스칼라와-벡터">스칼라와 벡터&lt;/h2>
&lt;blockquote>
&lt;p>스칼라와 벡터는 선형 대수에서 가장 기본적인 개념이다.
스칼라는 크기, 벡터는 크기와 방향을 가지고 있다.&lt;/p>
&lt;/blockquote>
&lt;h3 id="스칼라">스칼라&lt;/h3>
&lt;p>&lt;strong>크기&lt;/strong>만으로 나타낼 수 있는 물리량이다.&lt;/p>
&lt;p>길이, 부피, 거리 등과 같이 숫자 하나로 표현되는 값이다.&lt;/p>
&lt;p>변수에 저장 할때는 일반적으로 소문자를 이용하여 표기한다.&lt;/p>
&lt;h3 id="벡터">벡터&lt;/h3>
&lt;blockquote>
&lt;p>벡터는 스칼라의 집합이며, 행렬을 구성하는 기본 단위이다.&lt;/p>
&lt;/blockquote>
&lt;p>크기와 방향을 모두 나타내는 개념이다.&lt;/p>
&lt;p>일반적으로 영어 볼드체로 표기하고, 파이썬에선 1차원 리스트로 취급할 수 있다.&lt;/p>
&lt;h4 id="행벡터와-열벡터">행벡터와 열벡터&lt;/h4>
&lt;p>열벡터(열 행렬) $m × 1$ 행렬은 $m$ 원소들의 단일 열벡터이다.&lt;/p>
&lt;p>$$
\mathbf{x}=\begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_m \end{bmatrix}
\tag{1}
$$&lt;/p>
&lt;p>행벡터(행 행렬) 1 × m 행렬은 그 원소들 m의 단일 행벡터이다.&lt;/p>
&lt;h2 id="행렬">행렬&lt;/h2>
&lt;blockquote>
&lt;p>행렬은 숫자가 2차원 형태로 숫자를 나열하는 것이다.&lt;/p>
&lt;/blockquote>
&lt;p>행렬은 행과 열로 구성되어 있다. 행은 가로 방향을 나타내고, 열을 세로 방향을 나타낸다.&lt;/p>
&lt;p>아래와 같이 소괄호를 사용하기도 하고, 대괄호를 사용하기도 한다.&lt;/p>
&lt;p>$$
\mathbf{A} =
\begin{pmatrix}
2 &amp;amp; 4 \\ 7 &amp;amp; 3
\end{pmatrix} =
\begin{bmatrix}
2 &amp;amp; 4 \\ 7 &amp;amp; 3
\end{bmatrix}
\tag{2}
$$&lt;/p>
&lt;h3 id="전치-행렬">전치 행렬&lt;/h3>
&lt;p>$$
\mathbf{x} = \begin{bmatrix}
x_1 &amp;amp; x_2 &amp;amp; \dots &amp;amp; x_m
\end{bmatrix}
\tag{3}
$$&lt;/p>
&lt;p>행벡터의 전치행렬(윗첨자 T로 표기)은 열벡터이고, 마찬가지로 열벡터의 전치 행렬은 행 벡터이다.&lt;/p>
&lt;p>$$
\begin{bmatrix} x_1 &amp;amp; x_2 &amp;amp; \dots &amp;amp; x_m \end{bmatrix}^\intercal = \begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_m \end{bmatrix}
\tag{4}
$$&lt;/p>
&lt;h3 id="행렬의-덧셈과-뺄셈">행렬의 덧셈과 뺄셈&lt;/h3>
&lt;p>각 위치에 대응하는 원소끼리 더하거나 빼는 것이다.&lt;/p>
&lt;p>$$
\mathbf{A} =
\begin{pmatrix}
1 &amp;amp; 2 \\ 3 &amp;amp; 4
\end{pmatrix}
, \space
\mathbf{B} =
\begin{pmatrix}
5 &amp;amp; 6 \\ 7 &amp;amp; 8
\end{pmatrix}
, \space
\mathbf{A + B} =
\begin{pmatrix}
6 &amp;amp; 8 \\ 10 &amp;amp; 12
\end{pmatrix}
\tag{5}
$$&lt;/p>
&lt;h3 id="행렬의-내적">행렬의 내적&lt;/h3>
&lt;p>벡터의 내적은 두 벡터에서 대응하는 원소들의 곱을 모두 더한 것이다.&lt;/p>
&lt;p>$$
\mathbf{x} \cdot \mathbf{y} = x_1y_1 + x_2y_2 + \dots + x_ny_n
\tag{6}
$$&lt;/p>
&lt;h3 id="행렬의-곱셈">행렬의 곱셈&lt;/h3>
&lt;blockquote>
&lt;p>행렬의 곱셈은 일반적인 곱셈과 다르다. 일종의 함수로 이해하는 것이 좋다.&lt;/p>
&lt;/blockquote>
&lt;p>행렬곱은 앞 행렬의 열의 수와 뒷 행렬의 행의 수가 같을 때만 정의된다.&lt;/p>
&lt;p>두 행렬 $A, B$가 각각 $m\times n, n\times r$ 행렬일 때,&lt;/p>
&lt;p>$$
A=\begin{pmatrix}a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \\ {\color{blue}a_{21}} &amp;amp; {\color{blue}a_{22}} &amp;amp; {\color{blue}\cdots} &amp;amp; {\color{blue}a_{2n}} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn}\end{pmatrix}, B=\begin{pmatrix}{\color{red}b_{11}} &amp;amp; b_{12} &amp;amp; \cdots &amp;amp; b_{1r} \\ {\color{red}b_{21}} &amp;amp; b_{22} &amp;amp; \cdots &amp;amp; b_{2r} \\ {\color{red}\vdots} &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ {\color{red}b_{n1}} &amp;amp; b_{n2} &amp;amp; \cdots &amp;amp; b_{nr}\end{pmatrix}
\tag{7}
$$&lt;/p>
&lt;p>이라고 하면 행렬의 곱 $AB$는 $m\times r$ 행렬이며,&lt;/p>
&lt;p>$$
AB=\begin{pmatrix}\sum_k a_{1k}b_{k1} &amp;amp; \sum_k a_{1k}b_{k2} &amp;amp; \cdots &amp;amp; \sum_k a_{1k}b_{kr} \\ {\color{#C0C}\sum_k a_{2k}b_{k1}} &amp;amp; \sum_k a_{2k}b_{k2} &amp;amp; \cdots &amp;amp; \sum_k a_{2k}b_{kr} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ \sum_k a_{mk}b_{k1} &amp;amp; \sum_k a_{mk}b_{k2} &amp;amp; \cdots &amp;amp; \sum_k a_{mk}b_{kr}\end{pmatrix}
\tag{8}
$$&lt;/p>
&lt;p>이다. (단, $k=1,2,&amp;hellip;,n$)&lt;/p>
&lt;blockquote>
&lt;p>항상 행렬을 다룰땐 &lt;strong>형상&lt;/strong>에 주의해야 한다.&lt;/p>
&lt;/blockquote>
&lt;h2 id="파이썬에서의-벡터와-행렬">파이썬에서의 벡터와 행렬&lt;/h2>
&lt;p>파이썬에서는 &lt;code>numpy&lt;/code> 라이브러리를 통해 쉽게 벡터와 행렬을 표현할 수 있다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">(&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ndim&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">W&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">W&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">W&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ndim&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="mi">2&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="행렬의-원소별-연산">행렬의 원소별 연산&lt;/h3>
&lt;p>서로 대응하는 원소들끼리 독립적인 연산이 이루어진다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">W&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">array&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">W&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">array&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="브로드캐스트">브로드캐스트&lt;/h3>
&lt;p>넘파이의 다차원 배열은 형상이 다른 배열끼리 연산을 하는 브로드캐스트가 가능하다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">A&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">A&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mi">10&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">array&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">A&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">b&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">array&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">80&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>AtCoder ABC 300: A, C, D</title><link>https://gyeongmin.kr/p/abc-300/</link><pubDate>Sun, 30 Apr 2023 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/abc-300/</guid><description>&lt;img src="https://gyeongmin.kr/images/atcoder.png" alt="Featured image of post AtCoder ABC 300: A, C, D" />&lt;h2 id="a---n-choice-question">A - N-choice question&lt;/h2>
&lt;p>&lt;a class="link" href="https://atcoder.jp/contests/abc300/tasks/abc300_a" target="_blank" rel="noopener"
>https://atcoder.jp/contests/abc300/tasks/abc300_a&lt;/a>&lt;/p>
&lt;h3 id="문제">문제&lt;/h3>
&lt;p>첫째 줄에 배열의 길이 $N$과 두 수 $A$와 $B$가 주어진다.
둘째 줄에 배열이 주어진다.&lt;/p>
&lt;h3 id="설명">설명&lt;/h3>
&lt;p>배열 중에서 $A+B$와 일치하는 것의 인덱스를 출력한다.&lt;/p>
&lt;h3 id="소스-코드">소스 코드&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">sys&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">input&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sys&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">stdin&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">readline&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">n&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">a&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">()]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">index&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">a&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="n">b&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;hr>
&lt;h2 id="c---cross">C - Cross&lt;/h2>
&lt;p>&lt;a class="link" href="https://atcoder.jp/contests/abc300/tasks/abc300_c" target="_blank" rel="noopener"
>https://atcoder.jp/contests/abc300/tasks/abc300_c&lt;/a>&lt;/p>
&lt;h3 id="문제-1">문제&lt;/h3>
&lt;p>첫째 줄에 배열의 높이 $H$와 너비 $W$가 주어진다.
둘째 줄부터 $1+H$ 번째 줄까지 배열이 주어진다.&lt;/p>
&lt;p>&amp;lsquo;#&amp;lsquo;이 크로스하는 경우를 세 주면 되는데, 사이즈별로 개수를 세 주어야 한다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">#...#
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.#.#.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">..#..
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.#.#.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#...#
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>위 경우는 사이즈가 2인 것이다.&lt;/p>
&lt;p>사이즈가 $1$인 개수부터 사이즈가 $N$인 개수까지 출력하면 된다.
여기서 $N$은 $min(H,W)$이다.&lt;/p>
&lt;h3 id="해설">해설&lt;/h3>
&lt;p>중심점을 먼저 찾으면 되는데, 모든 중심점은 두 가지 조건을 만족한다.&lt;/p>
&lt;ol>
&lt;li>모든 크로스의 중심점은 아래 에시의 형태이다.&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">#.#
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.#.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#.#
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol start="2">
&lt;li>모든 중심점의 좌표값은 다음 범위 내에 있다.
$1 \leq R \leq H-2$
$1 \leq C \leq W-2$&lt;/li>
&lt;/ol>
&lt;p>이걸로 중심점을 한 개씩 잡고, 1씩 크기를 늘려가면서 체크해주면 된다.&lt;/p>
&lt;h3 id="소스-코드-1">소스 코드&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">sys&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">input&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sys&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">stdin&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">readline&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">check&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">i&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">while&lt;/span> &lt;span class="kc">True&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">dx&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dy&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">zip&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">nx&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ny&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">dx&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">dy&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="n">nx&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">w&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="ow">or&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="n">ny&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">h&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">arr&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">ny&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">nx&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">!=&lt;/span> &lt;span class="s1">&amp;#39;#&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">i&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">h&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">w&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="nb">input&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">rstrip&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">h&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">h&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">w&lt;/span>&lt;span class="p">))]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">y&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">h&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">w&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">arr&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">y&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">arr&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">y&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">arr&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">y&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">arr&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">y&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">arr&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">y&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s1">&amp;#39;#&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">result&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">check&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">)]&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">result&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;hr>
&lt;h2 id="d---aabcc">D - AABCC&lt;/h2>
&lt;p>&lt;a class="link" href="https://atcoder.jp/contests/abc300/tasks/abc300_d" target="_blank" rel="noopener"
>https://atcoder.jp/contests/abc300/tasks/abc300_d&lt;/a>&lt;/p>
&lt;h3 id="문제-2">문제&lt;/h3>
&lt;p>첫째 줄에 $N$이 주어진다. $(3 \leq N \leq 10^{12})$&lt;/p>
&lt;p>$N$보다 크지 않은 양의 정수 중에서, $a^2\times b\times c^2$ 로 표현될 수 있는 수의 개수를 출력한다.
$(a&amp;lt;b&amp;lt;c)$ 이며, $a, b,c$는 소수이다.&lt;/p>
&lt;h3 id="해설-1">해설&lt;/h3>
&lt;p>재미있는 문제였다.&lt;/p>
&lt;p>$\sqrt{N}$까지 소수를 구하고, $a&amp;lt;b&amp;lt;c$가 되도록 세 가지 소수를 선택해 조건을 만족하는지 개수를 세 주면 된다.&lt;/p>
&lt;p>커팅 없이 돌리면 시간 초과가 나고, 두 가지 커팅을 해 주어야 한다.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>$b &amp;lt; c$ 이므로 $a^2 \times b^3$이 $N$ 보다 크다면 $a^2\times b\times c^2 \leq N$을 만족할 수 없으므로, 그 뒤는 확인하지 않아도 된다.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$a^2\times b\times c^2$ 가 $N$보다 크다면, 마찬가지로 그 뒤는 확인하지 않아도 된다.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="소스-코드-2">소스 코드&lt;/h3>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">sys&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">math&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="o">*&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">input&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sys&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">stdin&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">readline&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">eratosthenes&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">primes&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">n&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">p&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">while&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">primes&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">p&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">n&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">primes&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">False&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">p&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">primes_list&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">primes&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">p&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">primes_list&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">primes_list&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">n&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">input&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">primes&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">eratosthenes&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">floor&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sqrt&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">l&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">primes&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">count&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">l&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">j&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">l&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">a&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">primes&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">primes&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">j&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">a&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">a&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">b&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">b&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">b&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">break&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">k&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">j&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">l&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">a&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">c&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">primes&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">primes&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">j&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">primes&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">k&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">a&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">a&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">b&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">c&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">count&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">break&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">count&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>BOJ 23807: 두 단계 최단 경로 3 (Python)</title><link>https://gyeongmin.kr/p/boj-23807/</link><pubDate>Fri, 21 Apr 2023 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/boj-23807/</guid><description>&lt;img src="https://gyeongmin.kr/images/boj.png" alt="Featured image of post BOJ 23807: 두 단계 최단 경로 3 (Python)" />&lt;blockquote>
&lt;p>문제 링크 : &lt;a class="link" href="https://www.acmicpc.net/problem/23807" target="_blank" rel="noopener"
>https://www.acmicpc.net/problem/23807&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="문제">문제&lt;/h2>
&lt;p>서준이는 아빠로부터 생일선물로 세계 지도를 받아서 매우 기뻤다. 세계 지도에서 최단 경로를 찾는 프로그램을 개발해서 아빠께 감사의 마음을 전달하려고 한다. 세계 지도는 도시를 정점으로 갖고 도시 간의 도로를 간선으로 갖는 무방향성 그래프이며(undirected graph), 도로의 길이가 간선의 가중치이다. 출발 정점 $X$에서 출발해서 $P$개의 중간 정점 중 적어도 세 개의 정점을 반드시 거친 후 도착 정점 $Z$에 도달하는 최단 거리를 구해서 우리 서준이를 도와주자.&lt;/p>
&lt;h2 id="입력">입력&lt;/h2>
&lt;p>첫째 줄에 정점의 수 $N(10 \leq N \leq 100,000)$, 간선의 수 $M(10 \leq M \leq 300,000)$이 주어진다.&lt;/p>
&lt;p>다음 $M$개 줄에 간선 정보 $u, v, w$가 주어지며 도시 $u$와 도시 $v$ 사이의 가중치가 정수 $w$인 양방향 도로를 나타낸다. $(1 \leq u, v \leq N, u ≠ v, 1 \leq w \leq 1,000,000)$&lt;/p>
&lt;p>다음 줄에 $X Z$가 주어진다. $(1 \leq X, Z \leq N, X \neq Z)$&lt;/p>
&lt;p>다음 줄에 $P$가 주어진다. $(3 \leq P \leq \min(100, N - 3))$&lt;/p>
&lt;p>다음 줄에 $P$개의 서로 다른 중간 정점 $Y(1 \leq Y \leq N, X ≠ Y ≠ Z)$가 빈칸을 사이에 두고 주어진다.&lt;/p>
&lt;h2 id="출력">출력&lt;/h2>
&lt;p>출발 정점 $X$에서 출발해서 $P$개의 중간 정점 중 적어도 세 개의 정점을 반드시 거친 후 도착 정점 $Z$에 도달하는 최단 거리를 출력한다. 도착 정점 Z에 도착할 수 없는 경우 $-1$을 출력한다.&lt;/p>
&lt;hr>
&lt;h2 id="풀이">풀이&lt;/h2>
&lt;p>브루트포스 + 다익스트라 문제이다.&lt;/p>
&lt;p>$X - A - B - C - Z$ 로 가는 최단 거리를 찾아야 한다.&lt;/p>
&lt;p>우선순위 큐를 활용한 &lt;strong>다익스트라의 시간복잡도는 $bigo(E\log{V})$이다&lt;/strong>.
중간 정점은 최대 100개가 주어지며, 이 중 3개를 선택해야 하므로 경우의 수가 최대 ${}_{100}{\rm P}_3$ 이다.
모든 경우에서 다익스트라를 돌리면 당연히 &lt;strong>시간초과&lt;/strong>가 난다.&lt;/p>
&lt;p>&lt;strong>$X$와 중간 정점들을 기준으로 다익스트라를 먼저 돌리고, 그 결과들을 활용해 모든 경우 중 최소 거리를 구해 주면 된다.&lt;/strong>&lt;/p>
&lt;p>다익스트라를 &lt;strong>최대 101번&lt;/strong> 돌리고, ${}_{100}{\rm P}_3 = 970,200$이다.
종합하여 시간 복잡도를 계산해 보면 $300,000\times\log{100,000} \times 101 + 970,200 = 152,470,200$ 가 나온다.&lt;/p>
&lt;p>이 문제의 시간 제한은 6초이다. 바로 통과할 줄 알았다. 하지만 우리의 파이썬은 생각보다 느리다.&lt;/p>
&lt;p>python3 말고 pypy3로 제출해야 한다.
다익스트라 결과를 저장할 &lt;code>dist&lt;/code>를 리스트가 아닌 딕셔너리로 구현하고, &lt;code>min()&lt;/code> 함수 대신 직접 if문으로 최소값을 찾는 등 최적화를 조금 진행해 주어야 겨우 풀린다.&lt;/p>
&lt;p>마지막에 결과값이 &lt;code>INF&lt;/code>일 땐 -1로 출력하는 것을 잊지 말자.&lt;/p>
&lt;h2 id="소스-코드">소스 코드&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">heapq&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">heappop&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">heappush&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">itertools&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">permutations&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">sys&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">input&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sys&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">stdin&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">readline&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">INF&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">float&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;inf&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">dijkstra&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">graph&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">start&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">n&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">graph&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dist&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">INF&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">n&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dist&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">start&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">queue&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">start&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">while&lt;/span> &lt;span class="n">queue&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">path_len&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">v&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">heappop&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">queue&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">path_len&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">dist&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">v&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">w&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">edge_len&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">graph&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">v&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">edge_len&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">path_len&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">dist&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">w&lt;/span>&lt;span class="p">]:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dist&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">w&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">edge_len&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">path_len&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">heappush&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">queue&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">edge_len&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">path_len&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">w&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">dist&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">n&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">m&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">graph&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[[]&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">m&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">u&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">v&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">w&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">graph&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">u&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="n">v&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">w&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">graph&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">v&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="n">u&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">w&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">z&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">p&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">input&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">mid&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">()]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">dist&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">node&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">mid&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dist&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">node&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dijkstra&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">graph&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">node&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">dist&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dijkstra&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">graph&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">INF&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">a&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">c&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">permutations&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mid&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">total&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dist&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">a&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">dist&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">a&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">b&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">dist&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">b&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">dist&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">z&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">total&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">total&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">if&lt;/span> &lt;span class="n">result&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">INF&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">result&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="후기">후기&lt;/h2>
&lt;p>파이썬 기준 시간 제한이 정말 빡빡한 문제였다. 이 문제를 파이썬으로 풀어본 사람이 없길래 파이썬으로 풀어 봤다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/boj-23807/image.png"
width="2334"
height="492"
srcset="https://gyeongmin.kr/p/boj-23807/image_hu6275cfec8ca0287ac9343170595d77f4_101850_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/boj-23807/image_hu6275cfec8ca0287ac9343170595d77f4_101850_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="474"
data-flex-basis="1138px"
>&lt;/p></description></item><item><title>16935번 : 배열 돌리기 3 (Python)</title><link>https://gyeongmin.kr/p/boj-16935/</link><pubDate>Mon, 06 Feb 2023 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/boj-16935/</guid><description>&lt;img src="https://gyeongmin.kr/images/boj.png" alt="Featured image of post 16935번 : 배열 돌리기 3 (Python)" />&lt;blockquote>
&lt;p>문제 링크 : &lt;a class="link" href="https://www.acmicpc.net/problem/16935" target="_blank" rel="noopener"
>https://www.acmicpc.net/problem/16935&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="문제">문제&lt;/h2>
&lt;p>크기가 N×M인 배열이 있을 때, 배열에 연산을 R번 적용하려고 한다. 연산은 총 6가지가 있다.&lt;/p>
&lt;p>1번 연산은 배열을 상하 반전시키는 연산이다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">1 6 2 9 8 4 → 4 2 9 3 1 8
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">7 2 6 9 8 2 → 9 2 3 6 1 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1 8 3 4 2 9 → 7 4 6 2 3 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">7 4 6 2 3 1 → 1 8 3 4 2 9
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">9 2 3 6 1 5 → 7 2 6 9 8 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">4 2 9 3 1 8 → 1 6 2 9 8 4
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;배열&amp;gt; &amp;lt;연산 결과&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>2번 연산은 배열을 좌우 반전시키는 연산이다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">1 6 2 9 8 4 → 4 8 9 2 6 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">7 2 6 9 8 2 → 2 8 9 6 2 7
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1 8 3 4 2 9 → 9 2 4 3 8 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">7 4 6 2 3 1 → 1 3 2 6 4 7
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">9 2 3 6 1 5 → 5 1 6 3 2 9
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">4 2 9 3 1 8 → 8 1 3 9 2 4
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;배열&amp;gt; &amp;lt;연산 결과&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>3번 연산은 오른쪽으로 90도 회전시키는 연산이다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">1 6 2 9 8 4 → 4 9 7 1 7 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">7 2 6 9 8 2 → 2 2 4 8 2 6
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1 8 3 4 2 9 → 9 3 6 3 6 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">7 4 6 2 3 1 → 3 6 2 4 9 9
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">9 2 3 6 1 5 → 1 1 3 2 8 8
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">4 2 9 3 1 8 → 8 5 1 9 2 4
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;배열&amp;gt; &amp;lt;연산 결과&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>4번 연산은 왼쪽으로 90도 회전시키는 연산이다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">1 6 2 9 8 4 → 4 2 9 1 5 8
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">7 2 6 9 8 2 → 8 8 2 3 1 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1 8 3 4 2 9 → 9 9 4 2 6 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">7 4 6 2 3 1 → 2 6 3 6 3 9
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">9 2 3 6 1 5 → 6 2 8 4 2 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">4 2 9 3 1 8 → 1 7 1 7 9 4
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;배열&amp;gt; &amp;lt;연산 결과&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>5, 6번 연산을 수행하려면 배열을 크기가 N/2×M/2인 4개의 부분 배열로 나눠야 한다. 아래 그림은 크기가 6×8인 배열을 4개의 그룹으로 나눈 것이고, 1부터 4까지의 수로 나타냈다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">1 1 1 1 2 2 2 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1 1 1 1 2 2 2 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1 1 1 1 2 2 2 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">4 4 4 4 3 3 3 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">4 4 4 4 3 3 3 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">4 4 4 4 3 3 3 3
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>5번 연산은 1번 그룹의 부분 배열을 2번 그룹 위치로, 2번을 3번으로, 3번을 4번으로, 4번을 1번으로 이동시키는 연산이다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">3 2 6 3 1 2 9 7 → 2 1 3 8 3 2 6 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">9 7 8 2 1 4 5 3 → 1 3 2 8 9 7 8 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">5 9 2 1 9 6 1 8 → 4 5 1 9 5 9 2 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2 1 3 8 6 3 9 2 → 6 3 9 2 1 2 9 7
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1 3 2 8 7 9 2 1 → 7 9 2 1 1 4 5 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">4 5 1 9 8 2 1 3 → 8 2 1 3 9 6 1 8
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;배열&amp;gt; &amp;lt;연산 결과&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>6번 연산은 1번 그룹의 부분 배열을 4번 그룹 위치로, 4번을 3번으로, 3번을 2번으로, 2번을 1번으로 이동시키는 연산이다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">3 2 6 3 1 2 9 7 → 1 2 9 7 6 3 9 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">9 7 8 2 1 4 5 3 → 1 4 5 3 7 9 2 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">5 9 2 1 9 6 1 8 → 9 6 1 8 8 2 1 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2 1 3 8 6 3 9 2 → 3 2 6 3 2 1 3 8
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1 3 2 8 7 9 2 1 → 9 7 8 2 1 3 2 8
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">4 5 1 9 8 2 1 3 → 5 9 2 1 4 5 1 9
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;배열&amp;gt; &amp;lt;연산 결과&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="입력">입력&lt;/h2>
&lt;p>첫째 줄에 배열의 크기 $N$, $M$과 수행해야 하는 연산의 수 R이 주어진다.&lt;/p>
&lt;p>둘째 줄부터 $N$개의 줄에 배열 $A$의 원소 $A_{ij}$가 주어진다.&lt;/p>
&lt;p>마지막 줄에는 수행해야 하는 연산이 주어진다. 연산은 공백으로 구분되어져 있고, 문제에서 설명한 연산 번호이며, 순서대로 적용시켜야 한다.&lt;/p>
&lt;h2 id="출력">출력&lt;/h2>
&lt;p>입력으로 주어진 배열에 $R$개의 연산을 순서대로 수행한 결과를 출력한다.&lt;/p>
&lt;h2 id="제한">제한&lt;/h2>
&lt;ul>
&lt;li>$2 \leq N, M \leq 100$&lt;/li>
&lt;li>$1 \leq R \leq 1,000$&lt;/li>
&lt;li>$N$, $M$은 짝수&lt;/li>
&lt;li>$1 \leq A_{ij} \leq 10^8$&lt;/li>
&lt;/ul>
&lt;h2 id="소스-코드">소스 코드&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">sys&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">input&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sys&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">stdin&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">readline&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">n&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">m&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">r&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[[&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">()]&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">options&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">()]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">option&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">options&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">option&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">arr&lt;/span>&lt;span class="p">[::&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="c1"># 상하 반전&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">elif&lt;/span> &lt;span class="n">option&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">list&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">[::&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">arr&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="c1"># 좌우 반전&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">elif&lt;/span> &lt;span class="n">option&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">list&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">zip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">arr&lt;/span>&lt;span class="p">[::&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]))&lt;/span> &lt;span class="c1"># 오른쪽으로 90도 회전&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">n&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">m&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">m&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">n&lt;/span> &lt;span class="c1"># 행, 열 사이즈 스왑&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">elif&lt;/span> &lt;span class="n">option&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">list&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">list&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">zip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">arr&lt;/span>&lt;span class="p">)))[::&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="c1"># 왼쪽으로 90도 회전&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">n&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">m&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">m&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">n&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">arr1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">[:&lt;/span>&lt;span class="n">m&lt;/span>&lt;span class="o">//&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">arr&lt;/span>&lt;span class="p">[:&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="o">//&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="c1"># 1사분면&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">arr2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">m&lt;/span>&lt;span class="o">//&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">:],&lt;/span> &lt;span class="n">arr&lt;/span>&lt;span class="p">[:&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="o">//&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="c1"># 2사분면&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">arr3&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">[:&lt;/span>&lt;span class="n">m&lt;/span>&lt;span class="o">//&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">arr&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="o">//&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">:])&lt;/span> &lt;span class="c1"># 3사분면&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">arr4&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">m&lt;/span>&lt;span class="o">//&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">:],&lt;/span> &lt;span class="n">arr&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="o">//&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">:])&lt;/span> &lt;span class="c1"># 4사분면&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">option&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="c1"># 시계 방향 사분면 회전&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">list&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">zip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">arr1&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nb">list&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">zip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">arr2&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">elif&lt;/span> &lt;span class="n">option&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="c1"># 반시계 방향 사분면 회전&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">list&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">zip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">arr4&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nb">list&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">zip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">arr3&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">list&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">lambda&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">arr&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">row&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">arr&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">row&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="풀이">풀이&lt;/h2>
&lt;p>&lt;img src="https://gyeongmin.kr/p/boj-16935/image.png"
width="804"
height="603"
srcset="https://gyeongmin.kr/p/boj-16935/image_hub9aa214d7c5dfd41eb97aa2cb5b89c78_312627_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/boj-16935/image_hub9aa214d7c5dfd41eb97aa2cb5b89c78_312627_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="풀이는 소스코드를 참고해 주세요"
class="gallery-image"
data-flex-grow="133"
data-flex-basis="320px"
>&lt;/p>
&lt;h2 id="후기">후기&lt;/h2>
&lt;p>좀 귀찮은 문제였는데, 깔끔하게 구현해 보려고 노력했다. 파이썬 리스트컴프리헨션을 연습하기 좋은 문제였다.&lt;/p></description></item><item><title>BOJ 14620: 꽃길 (Python)</title><link>https://gyeongmin.kr/p/boj-14620/</link><pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/boj-14620/</guid><description>&lt;img src="https://gyeongmin.kr/images/boj.png" alt="Featured image of post BOJ 14620: 꽃길 (Python)" />&lt;blockquote>
&lt;p>문제 링크 : &lt;a class="link" href="https://www.acmicpc.net/problem/14620" target="_blank" rel="noopener"
>https://www.acmicpc.net/problem/14620&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="문제">문제&lt;/h2>
&lt;p>2017년 4월 5일 식목일을 맞이한 진아는 나무를 심는 대신 하이테크관 앞 화단에 꽃을 심어 등교할 때 마다 꽃길을 걷고 싶었다.&lt;/p>
&lt;p>진아가 가진 꽃의 씨앗은 꽃을 심고나면 정확히 1년후에 꽃이 피므로 진아는 다음해 식목일 부터 꽃길을 걸을 수 있다.&lt;/p>
&lt;p>하지만 진아에게는 꽃의 씨앗이 세개밖에 없었으므로 세 개의 꽃이 하나도 죽지 않고 1년후에 꽃잎이 만개하길 원한다.&lt;/p>
&lt;p>꽃밭은 N $\times$ N의 격자 모양이고 진아는 씨앗을 (1,1)~(N,N)의 지점 중 한곳에 심을 수 있다. 꽃의 씨앗은 그림 (a)처럼 심어지며 1년 후 꽃이 피면 그림 (b)모양이 된다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/boj-14620/image.png"
width="579"
height="349"
srcset="https://gyeongmin.kr/p/boj-14620/image_hu6818dc205906c7e6bb90237cd021fa53_28279_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/boj-14620/image_hu6818dc205906c7e6bb90237cd021fa53_28279_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="165"
data-flex-basis="398px"
>&lt;/p>
&lt;p>꽃을 심을 때는 주의할 점이있다. 어떤 씨앗이 꽃이 핀 뒤 다른 꽃잎(혹은 꽃술)과 닿게 될 경우 두 꽃 모두 죽어버린다. 또 화단 밖으로 꽃잎이 나가게 된다면 그 꽃은 죽어버리고 만다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/boj-14620/image-1.png"
width="593"
height="345"
srcset="https://gyeongmin.kr/p/boj-14620/image-1_hu503838a8d1e46810789a8270f24afdc5_44653_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/boj-14620/image-1_hu503838a8d1e46810789a8270f24afdc5_44653_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="171"
data-flex-basis="412px"
>&lt;/p>
&lt;p>그림(c)는 세 꽃이 정상적으로 핀 모양이고 그림(d)는 두 꽃이 죽어버린 모양이다.&lt;/p>
&lt;p>하이테크 앞 화단의 대여 가격은 격자의 한 점마다 다르기 때문에 진아는 서로 다른 세 씨앗을 모두 꽃이 피게하면서 가장 싼 가격에 화단을 대여하고 싶다.&lt;/p>
&lt;p>단 화단을 대여할 때는 꽃잎이 핀 모양을 기준으로 대여를 해야하므로 꽃 하나당 5평의 땅을 대여해야만 한다.&lt;/p>
&lt;p>돈이 많지 않은 진아를 위하여 진아가 꽃을 심기 위해 필요한 최소비용을 구해주자!&lt;/p>
&lt;h2 id="입력">입력&lt;/h2>
&lt;p>입력의 첫째 줄에 화단의 한 변의 길이 $N (6 \leq N \leq 10)$이 들어온다.&lt;/p>
&lt;p>이후 N개의 줄에 N개씩 화단의 지점당 가격$(0 \leq G \leq 200)$이 주어진다.&lt;/p>
&lt;h2 id="출력">출력&lt;/h2>
&lt;p>꽃을 심기 위한 최소 비용을 출력한다.&lt;/p>
&lt;hr>
&lt;h1 id="풀이">풀이&lt;/h1>
&lt;p>꽃이 &lt;strong>+&lt;/strong> 모양으로 생겼기 때문에, 중심점을 잘 생각해야 한다.&lt;/p>
&lt;p>다음 그림을 보면서 꽃이 죽는 규칙을 살펴보자.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/boj-14620/image-2.png"
width="500"
height="500"
srcset="https://gyeongmin.kr/p/boj-14620/image-2_hua4e8b0d31328622bf43e8c7fabfc6987_73593_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/boj-14620/image-2_hua4e8b0d31328622bf43e8c7fabfc6987_73593_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="100"
data-flex-basis="240px"
>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>중심점의 좌표 $(x,y)$는 $1 \leq x, \space y \leq n-2$ 이다.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>두 꽃이 서로 겹쳐 죽는 경우는 다음 3가지다.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>$x_1, x_2$의 차가 $0$인 경우, $y_1, y_2$의 차이가 $3$미만일 때&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$x_1, x_2$의 차가 $1$인 경우, $y_1, y_2$의 차이가 $2$미만일 때&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$x_1, x_2$의 차가 $2$인 경우, $y_1, y_2$의 차이가 $1$미만일 때&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="소스코드">소스코드&lt;/h1>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">sys&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">itertools&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">combinations&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">input&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sys&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">stdin&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">readline&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">inf&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mf">2e9&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">is_dead&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">p2&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="nb">abs&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p1&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">p2&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="nb">abs&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p1&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">p2&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="kc">True&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">elif&lt;/span> &lt;span class="nb">abs&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p1&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">p2&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="nb">abs&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p1&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">p2&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="kc">True&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">elif&lt;/span> &lt;span class="nb">abs&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p1&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">p2&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="nb">abs&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p1&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">p2&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="kc">True&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="kc">False&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">get_cost&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">p&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">cost&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">y&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">cost&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">y&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">cost&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">y&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">cost&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">y&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">cost&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">y&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">solution&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">p2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">p3&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">is_dead&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">p2&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="ow">or&lt;/span> &lt;span class="n">is_dead&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">p3&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="ow">or&lt;/span> &lt;span class="n">is_dead&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">p1&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">inf&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">get_cost&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">get_cost&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p2&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">get_cost&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">n&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">input&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">cost&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[[&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">()]&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">pos&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[(&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">y&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">inf&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">p1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">p2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">p3&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">combinations&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">pos&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">result&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">solution&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">p1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">p2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">p3&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">result&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>BOJ 9461: 파도반 수열 (Python)</title><link>https://gyeongmin.kr/p/boj-9461/</link><pubDate>Tue, 17 Jan 2023 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/boj-9461/</guid><description>&lt;img src="https://gyeongmin.kr/images/boj.png" alt="Featured image of post BOJ 9461: 파도반 수열 (Python)" />&lt;blockquote>
&lt;p>문제 링크 : &lt;a class="link" href="https://www.acmicpc.net/problem/9461" target="_blank" rel="noopener"
>https://www.acmicpc.net/problem/9461&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="문제">문제&lt;/h2>
&lt;p>오른쪽 그림과 같이 삼각형이 나선 모양으로 놓여져 있다. 첫 삼각형은 정삼각형으로 변의 길이는 1이다. 그 다음에는 다음과 같은 과정으로 정삼각형을 계속 추가한다. 나선에서 가장 긴 변의 길이를 k라 했을 때, 그 변에 길이가 k인 정삼각형을 추가한다.&lt;/p>
&lt;p>파도반 수열 P(N)은 나선에 있는 정삼각형의 변의 길이이다. P(1)부터 P(10)까지 첫 10개 숫자는 1, 1, 1, 2, 2, 3, 4, 5, 7, 9이다.&lt;/p>
&lt;p>N이 주어졌을 때, P(N)을 구하는 프로그램을 작성하시오.&lt;/p>
&lt;h2 id="입력">입력&lt;/h2>
&lt;p>첫째 줄에 테스트 케이스의 개수 T가 주어진다. 각 테스트 케이스는 한 줄로 이루어져 있고, N이 주어진다. $(1 \leq N \leq 100)$&lt;/p>
&lt;h2 id="출력">출력&lt;/h2>
&lt;p>각 테스트 케이스마다 P(N)을 출력한다.&lt;/p>
&lt;h2 id="풀이">풀이&lt;/h2>
&lt;p>$N$의 범위는 $(1 \leq N \leq 100)$ 이므로, 100까지 미리 계산해 두고 꺼내 쓰면 된다.&lt;/p>
&lt;p>조금만 찾아보면 규칙이 보이는데, $a_i$는 $a_{i-5}$와 $a_{i-1}$를 더한 값이다.&lt;/p>
&lt;p>다음 코드와 같이, 파이썬을 사용하면 배열의 특정 부분에 값을 편하게 넣어줄 수 있다.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="n">dp&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="소스코드">소스코드&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">sys&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">input&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sys&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">stdin&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">readline&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">dp&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">100&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">dp&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">101&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dp&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dp&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">dp&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">t&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">input&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">t&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">n&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">input&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dp&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>백준 디스코드 봇 '백준봇'</title><link>https://gyeongmin.kr/p/baekjoonbot/</link><pubDate>Tue, 03 Jan 2023 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/baekjoonbot/</guid><description>&lt;img src="https://gyeongmin.kr/p/baekjoonbot/image-1.png" alt="Featured image of post 백준 디스코드 봇 '백준봇'" />&lt;h1 id="백준-디스코드-봇-백준봇">백준 디스코드 봇 &amp;lsquo;백준봇&amp;rsquo;&lt;/h1>
&lt;blockquote>
&lt;p>백준 스터디를 진행할 때 문제를 조금 더 이쁘게 올려 보고 싶어 만들었습니다.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://gyeongmin.kr/p/baekjoonbot/image-1.png"
width="1187"
height="904"
srcset="https://gyeongmin.kr/p/baekjoonbot/image-1_hu3ba0e11ccd78cd419cf9cf4dfafe4b05_113858_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/baekjoonbot/image-1_hu3ba0e11ccd78cd419cf9cf4dfafe4b05_113858_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="131"
data-flex-basis="315px"
>&lt;/p>
&lt;hr>
&lt;p>&lt;a class="link" href="https://solvedac.github.io/unofficial-documentation/#/" target="_blank" rel="noopener"
>solved.ac 비공식 API&lt;/a> 를 사용하여 만들었습니다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/baekjoonbot/image-2.png"
width="1500"
height="500"
srcset="https://gyeongmin.kr/p/baekjoonbot/image-2_hua3f398f3dc87c7c8d5a4fd5322b217a0_123732_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/baekjoonbot/image-2_hua3f398f3dc87c7c8d5a4fd5322b217a0_123732_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="300"
data-flex-basis="720px"
>&lt;/p>
&lt;hr>
&lt;h2 id="사용-방법">사용 방법&lt;/h2>
&lt;h3 id="문제-올리기">문제 올리기&lt;/h3>
&lt;p>&lt;code>/백준 문제번호&lt;/code> 로 문제를 올릴 수 있습니다.
&lt;img src="https://gyeongmin.kr/p/baekjoonbot/image-6.png"
width="962"
height="81"
srcset="https://gyeongmin.kr/p/baekjoonbot/image-6_hu2facb2ba88d2dbba0ca32a6b9c440ab0_3694_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/baekjoonbot/image-6_hu2facb2ba88d2dbba0ca32a6b9c440ab0_3694_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="1187"
data-flex-basis="2850px"
>&lt;/p>
&lt;p>또는 &lt;code>/백준 문제링크&lt;/code> 로 문제를 올릴 수 있습니다.
&lt;img src="https://gyeongmin.kr/p/baekjoonbot/image-7.png"
width="1121"
height="97"
srcset="https://gyeongmin.kr/p/baekjoonbot/image-7_hu0f6723ab47112f2b9c890bf47ad2c7cd_7752_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/baekjoonbot/image-7_hu0f6723ab47112f2b9c890bf47ad2c7cd_7752_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="1155"
data-flex-basis="2773px"
>&lt;/p>
&lt;h3 id="문제와-소스코드를-함께-올리기">문제와 소스코드를 함께 올리기&lt;/h3>
&lt;p>&lt;code>/백준 문제번호&lt;/code> 또는 &lt;code>/백준 문제링크&lt;/code> 하단에 소스코드를 같이 입력하면, 문제와 소스코드를 함께 올릴 수 있습니다.&lt;/p>
&lt;p>줄바꿈은 &lt;code>Shift&lt;/code> + &lt;code>Enter&lt;/code> 키를 눌러주시면 됩니다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/baekjoonbot/image-4.png"
width="964"
height="517"
srcset="https://gyeongmin.kr/p/baekjoonbot/image-4_hu95272da1a80a9eb9e31f98224bb7d4be_32035_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/baekjoonbot/image-4_hu95272da1a80a9eb9e31f98224bb7d4be_32035_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="186"
data-flex-basis="447px"
>&lt;/p>
&lt;p>위 사진과 같이 디스코드의 코드 블럭을 이용하시면, 하이라이팅된 코드를 업로드 할 수 있습니다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/baekjoonbot/image-3.png"
width="970"
height="587"
srcset="https://gyeongmin.kr/p/baekjoonbot/image-3_hu42b54d877be7b417125bc335b2754ff6_54257_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/baekjoonbot/image-3_hu42b54d877be7b417125bc335b2754ff6_54257_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="165"
data-flex-basis="396px"
>&lt;/p>
&lt;h4 id="소스-코드가-길-때">소스 코드가 길 때&lt;/h4>
&lt;p>디스코드의 Embed의 내용은 4096자 제한이 있습니다.
따라서 Embed의 범위를 벗어나면 아래 사진과 같이 출력합니다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/baekjoonbot/image-8.png"
width="959"
height="590"
srcset="https://gyeongmin.kr/p/baekjoonbot/image-8_hu2df989813509d31de0633370673ec202_51433_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/baekjoonbot/image-8_hu2df989813509d31de0633370673ec202_51433_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="162"
data-flex-basis="390px"
>&lt;/p>
&lt;p>명령어 입력이 잘못된 경우,
&amp;ldquo;잘못된 입력입니다.&amp;rdquo; 라는 메세지를 출력합니다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/baekjoonbot/image-5.png"
width="959"
height="590"
srcset="https://gyeongmin.kr/p/baekjoonbot/image-5_hu2df989813509d31de0633370673ec202_51433_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/baekjoonbot/image-5_hu2df989813509d31de0633370673ec202_51433_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="162"
data-flex-basis="390px"
>&lt;/p>
&lt;p>Embed에 실패하여 메세지를 보내지 못한 경우, 또는 solved.ac 서버가 불안정하여 데이터를 가져오지 못한 경우
&amp;ldquo;메세지 전송이 실패했습니다.&amp;rdquo; 라는 메세지를 출력합니다.&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/baekjoonbot/image-9.png"
width="960"
height="69"
srcset="https://gyeongmin.kr/p/baekjoonbot/image-9_hu48de6d47a3ff341ae85709b5d734bb5b_10853_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/baekjoonbot/image-9_hu48de6d47a3ff341ae85709b5d734bb5b_10853_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="1391"
data-flex-basis="3339px"
>&lt;/p>
&lt;hr>
&lt;h2 id="백준봇-초대하기">백준봇 초대하기&lt;/h2>
&lt;blockquote>
&lt;p>&lt;a class="link" href="https://discord.com/api/oauth2/authorize?client_id=1055791861572325417&amp;amp;permissions=17179879424&amp;amp;scope=bot" target="_blank" rel="noopener"
>초대 링크&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>현재 너무 바빠 업데이트를 못 하고 있는데, 추후 다양한 기능을 업데이트할 예정입니다.&lt;/p>
&lt;hr></description></item><item><title>BOJ 1011: Fly me to the Alpha Centauri (Python)</title><link>https://gyeongmin.kr/p/boj-1011/</link><pubDate>Thu, 30 Jun 2022 00:00:00 +0000</pubDate><guid>https://gyeongmin.kr/p/boj-1011/</guid><description>&lt;img src="https://gyeongmin.kr/images/boj.png" alt="Featured image of post BOJ 1011: Fly me to the Alpha Centauri (Python)" />&lt;blockquote>
&lt;p>문제 링크 : &lt;a class="link" href="https://www.acmicpc.net/problem/1011" target="_blank" rel="noopener"
>https://www.acmicpc.net/problem/1011&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="문제">문제&lt;/h2>
&lt;p>우현이는 어린 시절, 지구 외의 다른 행성에서도 인류들이 살아갈 수 있는 미래가 오리라 믿었다. 그리고 그가 지구라는 세상에 발을 내려 놓은 지 23년이 지난 지금, 세계 최연소 ASNA 우주 비행사가 되어 새로운 세계에 발을 내려 놓는 영광의 순간을 기다리고 있다.&lt;/p>
&lt;p>그가 탑승하게 될 우주선은 Alpha Centauri라는 새로운 인류의 보금자리를 개척하기 위한 대규모 생활 유지 시스템을 탑재하고 있기 때문에, 그 크기와 질량이 엄청난 이유로 최신기술력을 총 동원하여 개발한 공간이동 장치를 탑재하였다. 하지만 이 공간이동 장치는 이동 거리를 급격하게 늘릴 경우 기계에 심각한 결함이 발생하는 단점이 있어서, 이전 작동시기에 k광년을 이동하였을 때는 $k-1$ , $k$ 혹은 $k+1$ 광년만을 다시 이동할 수 있다. 예를 들어, 이 장치를 처음 작동시킬 경우 -1 , 0 , 1 광년을 이론상 이동할 수 있으나 사실상 음수 혹은 0 거리만큼의 이동은 의미가 없으므로 1 광년을 이동할 수 있으며, 그 다음에는 0 , 1 , 2 광년을 이동할 수 있는 것이다. ( 여기서 다시 2광년을 이동한다면 다음 시기엔 1, 2, 3 광년을 이동할 수 있다. )&lt;/p>
&lt;p>&lt;img src="https://gyeongmin.kr/p/boj-1011/image.png"
width="626"
height="164"
srcset="https://gyeongmin.kr/p/boj-1011/image_hu1c570bd22b47ad41bfd2f1e1240e423c_67354_480x0_resize_box_3.png 480w, https://gyeongmin.kr/p/boj-1011/image_hu1c570bd22b47ad41bfd2f1e1240e423c_67354_1024x0_resize_box_3.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="381"
data-flex-basis="916px"
>&lt;/p>
&lt;p>김우현은 공간이동 장치 작동시의 에너지 소모가 크다는 점을 잘 알고 있기 때문에 $x$지점에서 $y$지점을 향해 최소한의 작동 횟수로 이동하려 한다. 하지만 $y$지점에 도착해서도 공간 이동장치의 안전성을 위하여 $y$지점에 도착하기 바로 직전의 이동거리는 반드시 1광년으로 하려 한다.&lt;/p>
&lt;p>김우현을 위해 $x$지점부터 정확히 $y$지점으로 이동하는데 필요한 공간 이동 장치 작동 횟수의 최솟값을 구하는 프로그램을 작성하라.&lt;/p>
&lt;h2 id="입력">입력&lt;/h2>
&lt;p>입력의 첫 줄에는 테스트케이스의 개수 $T$가 주어진다. 각각의 테스트 케이스에 대해 현재 위치 $x$ 와 목표 위치 $y$ 가 정수로 주어지며, $x$는 항상 $y$보다 작은 값을 갖는다. $(0 ≤ x &amp;lt; y &amp;lt; 231)$&lt;/p>
&lt;h2 id="출력">출력&lt;/h2>
&lt;p>각 테스트 케이스에 대해 $x$지점으로부터 $y$지점까지 정확히 도달하는데 필요한 최소한의 공간이동 장치 작동 횟수를 출력한다.&lt;/p>
&lt;h2 id="풀이">풀이&lt;/h2>
&lt;p>우선 거리 $d$를 구한다.
$d = y - x$&lt;/p>
&lt;p>그리고 $d$보다 작은 최대의 제곱수 $k^2$를 구한다.&lt;/p>
&lt;p>거리가 제곱수일 때에 주목하여 규칙을 살펴보자.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">k&lt;/th>
&lt;th style="text-align:center">거리&lt;/th>
&lt;th style="text-align:center">이동&lt;/th>
&lt;th style="text-align:center">횟수&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">11&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">3&lt;/td>
&lt;td style="text-align:center">111&lt;/td>
&lt;td style="text-align:center">3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">4&lt;/td>
&lt;td style="text-align:center">121&lt;/td>
&lt;td style="text-align:center">3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">1211&lt;/td>
&lt;td style="text-align:center">4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">6&lt;/td>
&lt;td style="text-align:center">1221&lt;/td>
&lt;td style="text-align:center">4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">7&lt;/td>
&lt;td style="text-align:center">12211&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">8&lt;/td>
&lt;td style="text-align:center">12221&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">3&lt;/td>
&lt;td style="text-align:center">9&lt;/td>
&lt;td style="text-align:center">12321&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">3&lt;/td>
&lt;td style="text-align:center">10&lt;/td>
&lt;td style="text-align:center">123211&lt;/td>
&lt;td style="text-align:center">6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">3&lt;/td>
&lt;td style="text-align:center">11&lt;/td>
&lt;td style="text-align:center">123221&lt;/td>
&lt;td style="text-align:center">6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">3&lt;/td>
&lt;td style="text-align:center">12&lt;/td>
&lt;td style="text-align:center">123321&lt;/td>
&lt;td style="text-align:center">6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">3&lt;/td>
&lt;td style="text-align:center">13&lt;/td>
&lt;td style="text-align:center">1233211&lt;/td>
&lt;td style="text-align:center">7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">3&lt;/td>
&lt;td style="text-align:center">14&lt;/td>
&lt;td style="text-align:center">1233221&lt;/td>
&lt;td style="text-align:center">7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">3&lt;/td>
&lt;td style="text-align:center">15&lt;/td>
&lt;td style="text-align:center">1233321&lt;/td>
&lt;td style="text-align:center">7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">4&lt;/td>
&lt;td style="text-align:center">16&lt;/td>
&lt;td style="text-align:center">1234321&lt;/td>
&lt;td style="text-align:center">7&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>보다시피 제곱수일 때 이동을 살펴보면&lt;/p>
&lt;p>$$1,2,3,&amp;hellip;,k,&amp;hellip;,3,2,1$$&lt;/p>
&lt;p>1부터 k까지 1씩 증가하고, 다시 1까지 감소하는 것을 확인할 수 있다.&lt;/p>
&lt;p>이때, 이동 거리가 제곱수인 경우 이동 횟수의 일반항을 구할 수 있다.&lt;/p>
&lt;p>$$a_{n} = 2n-1$$&lt;/p>
&lt;p>거리가 제곱수인 경우를 이용해서 이외의 경우도 구할 수 있다.&lt;/p>
&lt;p>$d - k^2&amp;lt;k$ 인 경우, 이동 거리는 거리가 $k^2$일 때 횟수에 1을 더한 값이다.&lt;/p>
&lt;p>$d - k^2&amp;lt;2k$ 인 경우, 이동 거리는 거리가 $k^2$일 때 횟수에 2을 더한 값이다.&lt;/p>
&lt;p>이를 수식화하면 $2 * k - 1 + [(d - k^2 + k - 1) / k]$ 가 된다.&lt;/p>
&lt;p>파이썬 코드로는 &lt;code>2 * k - 1 + (d - k ** 2 + k - 1) // k&lt;/code> 가 된다.&lt;/p>
&lt;h2 id="소스-코드">소스 코드&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">n&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">input&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">x&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">map&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">input&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">d&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">y&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">x&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># d보다 작은 최대의 제곱수 k^2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">k&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">while&lt;/span> &lt;span class="n">k&lt;/span> &lt;span class="o">**&lt;/span> &lt;span class="mi">2&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">d&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">k&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">k&lt;/span> &lt;span class="o">-=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">2&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">k&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">d&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">k&lt;/span> &lt;span class="o">**&lt;/span> &lt;span class="mi">2&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">k&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">//&lt;/span> &lt;span class="n">k&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">result&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item></channel></rss>