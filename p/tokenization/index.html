<!doctype html><html lang=ko dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="자연어 처리에서 토큰화의 의미와 형태소 분석기의 종류"><title>토큰화</title><link rel=canonical href=https://gyeongmin.kr/p/tokenization/><link rel=stylesheet href=/scss/style.min.2325ab3f1c53340b74d88bd622b7f5bcc047e55d78831b42a905dd43de9993e0.css><meta property="og:title" content="토큰화"><meta property="og:description" content="자연어 처리에서 토큰화의 의미와 형태소 분석기의 종류"><meta property="og:url" content="https://gyeongmin.kr/p/tokenization/"><meta property="og:site_name" content="Gyeongmin의 개발 블로그"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="Python"><meta property="article:tag" content="딥러닝"><meta property="article:published_time" content="2024-03-20T00:00:00+00:00"><meta property="article:modified_time" content="2024-03-20T00:00:00+00:00"><meta property="og:image" content="https://gyeongmin.kr/images/pytorch-transformer-nlp-computer-vision.png"><meta name=twitter:title content="토큰화"><meta name=twitter:description content="자연어 처리에서 토큰화의 의미와 형태소 분석기의 종류"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://gyeongmin.kr/images/pytorch-transformer-nlp-computer-vision.png"><link rel="shortcut icon" href=/logo.ico/favicon.ico><script async src="https://www.googletagmanager.com/gtag/js?id=G-RBG63ZJRZM"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-RBG63ZJRZM",{anonymize_ip:!1})}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2100464285092061" crossorigin=anonymous></script>
<link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color=#757575><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#000000"><link rel=icon href=/logo.ico/favicon.ico><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2100464285092061" crossorigin=anonymous></script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="메뉴 여닫기">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/profile_hu5d202280e416202dba72f1bb8473638c_1285338_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Gyeongmin의 개발 블로그</a></h1><h2 class=site-description>Computer Vision Engineer</h2></div></header><ol class=social-menu><li><a href=https://github.com/gyeongminn target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="22" height="22" viewBox="1 -2 19 25" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path d="M0 0h22v22H0z" stroke="none"/><path d="M8.25 17.416c-3.942 1.284-3.942-2.292-5.5-2.75m11 4.584v-3.208c0-.916.092-1.284-.458-1.834 2.566-.274 5.042-1.284 5.042-5.5a4.216 4.216.0 00-1.192-2.934A3.85 3.85.0 0017.05 2.84s-1.008-.274-3.208 1.192a11.274 11.274.0 00-5.684.0C5.958 2.566 4.95 2.841 4.95 2.841a3.85 3.85.0 00-.092 2.934A4.216 4.216.0 003.666 8.708c0 4.216 2.474 5.226 5.042 5.5-.55.55-.55 1.1-.458 1.834v3.208"/></svg></a></li><li><a href=https://www.instagram.com/gyeongminx/ target=_blank title=instagram rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-instagram" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 4m0 4a4 4 0 014-4h8a4 4 0 014 4v8a4 4 0 01-4 4H8a4 4 0 01-4-4z"/><path d="M12 12m-3 0a3 3 0 106 0 3 3 0 10-6 0"/><path d="M16.5 7.5v.01"/></svg></a></li><li><a href=https://www.linkedin.com/in/gyeongmin-lee-865448256/ target=_blank title=Linkedin rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-linkedin" width="44" height="44" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 4m0 2a2 2 0 012-2h12a2 2 0 012 2v12a2 2 0 01-2 2H6a2 2 0 01-2-2z"/><path d="M8 11v5"/><path d="M8 8v.01"/><path d="M12 16v-5"/><path d="M16 16v-3a2 2 0 00-4 0"/></svg></a></li><li><a href=mailto:gyeongmin@hansung.ac.kr target=_blank title=mail rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-mail" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path d="M0 0h24v24H0z" stroke="none"/><path d="M3 7a2 2 0 012-2h14a2 2 0 012 2v10a2 2 0 01-2 2H5a2 2 0 01-2-2V7z"/><path d="m3 7 9 6 9-6"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>About</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>Archives</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><li><a href=/links/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg><span>Links</span></a></li><div class=menu-bottom-section><li id=i18n-switch><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg><select name=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://gyeongmin.kr/ selected>한국어</option><option value=https://gyeongmin.kr/en/>English</option></select></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>다크 모드</span></li></div></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">목차</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#자연어-처리>자연어 처리</a></li><li><a href=#토큰화>토큰화</a><ol><li><a href=#단어-토큰화>단어 토큰화</a></li><li><a href=#글자-토큰화>글자 토큰화</a></li><li><a href=#형태소-토큰화>형태소 토큰화</a><ol><li><a href=#형태소-분석기>형태소 분석기</a></li><li><a href=#형태소-어휘-사전>형태소 어휘 사전</a></li></ol></li><li><a href=#하위-단어-토근화>하위 단어 토근화</a><ol><li><a href=#바이트-페어-인코딩>바이트 페어 인코딩</a></li><li><a href=#센텐스피스>센텐스피스</a></li><li><a href=#워드피스>워드피스</a></li><li><a href=#토크나이저스>토크나이저스</a></li></ol></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/tokenization/><img src=/../images/pytorch-transformer-nlp-computer-vision.png loading=lazy alt="Featured image of post 토큰화"></a></div><div class=article-details><header class=article-category><a href=/categories/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98-%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC%EC%99%80-%EC%BB%B4%ED%93%A8%ED%84%B0-%EB%B9%84%EC%A0%84-%EC%8B%AC%EC%B8%B5%ED%95%99%EC%8A%B5/>파이토치 트랜스포머를 활용한 자연어 처리와 컴퓨터 비전 심층학습</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/tokenization/>토큰화</a></h2><h3 class=article-subtitle>자연어 처리에서 토큰화의 의미와 형태소 분석기의 종류</h3></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Mar 20, 2024</time></div></footer></div></header><section class=article-content><h2 id=자연어-처리>자연어 처리</h2><p>자연어(Natural Language)는 사람들이 일상적으로 쓰는 언어를 말한다.
자연어 처리(Natural Language Processing)는 컴퓨터가 인간의 언어를 이해하고 해석 및 생성하기 위한 기술을 의미한다.</p><ul><li><p>모호성(Ambiguity): 인간 언어는 맥락에 따라 다양한 의미를 가질 수 있으며, 이를 명확히 구분</p></li><li><p>가변성(Variability): 인간 언어는 사투리, 억양, 신조어 등 다양한 스타일로 인해 가변적이며, 이를 이해하고 처리해야 언어를 올바르게 사용</p></li><li><p>구조성(Structure): 문장의 구조와 문법적 요소를 이해하고 이를 바탕으로 의미를 추론 및 분석</p></li></ul><h2 id=토큰화>토큰화</h2><p>문제를 이해하고 구분할 수 있는 모델을 만들려면 우선 말뭉치(Corpus)를 일정한 단위인 토큰(Token)으로 나눠야 한다. 토큰화(Tokenization)을 진행해 컴퓨터가 자연어를 이해할 수 있도록 말뭉치를 나누는 것이다.</p><h3 id=단어-토큰화>단어 토큰화</h3><p>우리말 띄어쓰기 원칙 제 2항, &ldquo;문장의 각 단어는 띄어 씀을 원칙으로 한다"에 의해, 공백을 기준으로 <code>split()</code>하면 단어 토큰화를 할 수 있다.</p><ul><li>입력: <code>'단어 토큰화 예시'</code></li><li>출력: <code>['단어', '토큰화', '예시']</code></li></ul><h3 id=글자-토큰화>글자 토큰화</h3><p>글자 토큰화는 글자 기준으로 문장을 나누는 방식이다. <code>split('')</code>을 적용해 글자 토큰화를 할 수 있다.</p><ul><li>입력: <code>'글자 토큰화이다.'</code></li><li>출력: <code>['글', '자', ' ', '토', '큰', '화', '이', '다', '.']</code></li></ul><p>영어는 한 칸에 한 글자가 들어가지만, 한글의 경우 초성, 중성, 종성의 조합으로 한 글자가 구성된다. 이를 모두 분해할 수 있는 자모(jamo) 라이브러리도 있다.</p><ul><li>입력: <code>'자모 토큰화'</code></li><li>출력: <code>['ㅈ', 'ㅏ', 'ㅁ', 'ㅗ', ' ', 'ㅌ', 'ㅗ', 'ㅋ', 'ㅡ', 'ㄴ', 'ㅎ', 'ㅘ']</code></li></ul><h3 id=형태소-토큰화>형태소 토큰화</h3><p>형태소 토큰화(Morpheme Tokenization)란 텍스트를 형태소 단위로 나누는 토큰화 방법이다. 형태소는 의미를 가지는 최소 단위이다.</p><p>형태소는 명사, 동사, 형용사와 같이 문장 내에서 홀로 쓰일 수 있으며 스스로 의미를 가지는 <strong>자립 형태소</strong>와, 스스로 의미를 가지지 못하고 조사, 어미, 접두사, 접미사와 같이 다른 형태소와 조합되어 사용되는 <strong>의존 형태소</strong>로 구분한다.</p><p>문장 내 단어의 위치에 따라 품사가 결정되는 영어와는 달리, 한국어는 단어와 조사의 결합으로 품사가 결정된다. &ldquo;나는 밥을 먹는다&rdquo; 에서 &ldquo;먹는다 나는 밥을&rdquo; 로 바꾸어도 어색하지만 문장의 의미는 이해할 수 있는 것과 같다.</p><p>우리말에서 동사를 보면 변화가 굉장히 많다. &lsquo;먹다&rsquo;, &lsquo;먹는다&rsquo;, &lsquo;먹이다&rsquo;, 먹었다&rsquo;, &lsquo;먹어&rsquo; 등 유사한 단어가 무수히 많다. 이는 &lsquo;먹-&lsquo;이라는 어간에 어미 &lsquo;-다&rsquo;, 사동 접미사 &lsquo;-이-&rsquo;, 과거 시제 어미 &lsquo;-었-&rsquo; 등이 붙어 여러 단어의 조합이 된 것이다.</p><p>이처럼 단어의 변화형을 고려하지 않고 유사한 단어를 모두 다른 단어로 간주한다면, 자칫 차원의 저주에 빠지게 되거나 모델 학습이 어려워질 수 있다. 따라서 의미를 가지는 최소 단위인 형태소로 글자를 분리(토큰화)하여 모델을 학습하는 것이 좋다.</p><p>토큰화를 할 때는 그 언어의 문법적인 특성을 고려하여 적절한 토크나이저를 사용해야 한다.</p><h4 id=형태소-분석기>형태소 분석기</h4><p>Konlpy, NLTK, spaCy와 같은 라이브러리 등이 있다. 아래는 Konlpy 라이브러리에서 꼬꼬마 형태소 분석기를 사용하는 예시이다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=kn>from</span> <span class=nn>konlpy.tag</span> <span class=kn>import</span> <span class=n>Kkma</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>kkma</span> <span class=o>=</span> <span class=n>Kkma</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>sentence</span> <span class=o>=</span> <span class=s2>&#34;무엇이든 상상할 수 있는 사람은 무엇이든 만들어 낼 수 있다.&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>nouns</span> <span class=o>=</span> <span class=n>kkma</span><span class=o>.</span><span class=n>nouns</span><span class=p>(</span><span class=n>sentence</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>sentences</span> <span class=o>=</span> <span class=n>kkma</span><span class=o>.</span><span class=n>sentences</span><span class=p>(</span><span class=n>sentence</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>morphs</span> <span class=o>=</span> <span class=n>kkma</span><span class=o>.</span><span class=n>morphs</span><span class=p>(</span><span class=n>sentence</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>pos</span> <span class=o>=</span> <span class=n>kkma</span><span class=o>.</span><span class=n>pos</span><span class=p>(</span><span class=n>sentence</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;명사 추출 :&#34;</span><span class=p>,</span> <span class=n>nouns</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;문장 추출 :&#34;</span><span class=p>,</span> <span class=n>sentences</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;형태소 추출 :&#34;</span><span class=p>,</span> <span class=n>morphs</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;품사 태깅 :&#34;</span><span class=p>,</span> <span class=n>pos</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>명사 추출: [&#39;무엇&#39;, &#39;상상&#39;, &#39;수&#39;, &#39;사람&#39;, &#39;무엇&#39;]
</span></span><span class=line><span class=cl>구문 추출 : [&#39;무엇이든 상상할 수 있는 사람은 무엇이든 만들어 낼 수 있다.&#39;]
</span></span><span class=line><span class=cl>형태소 추출 : [&#39;무엇&#39;, &#39;이&#39;, &#39;든&#39;, &#39;상상&#39;, &#39;하&#39;, &#39;ᄅ&#39;, &#39;수&#39;, &#39;있&#39;, &#39;는&#39;, &#39;사람&#39;, &#39;은&#39;, &#39;무엇&#39;, &#39;이&#39;, &#39;든&#39;, &#39;만들&#39;, &#39;어&#39;, &#39;내&#39;, &#39;ᄅ&#39;, &#39;수&#39;, &#39;있&#39;, &#39;다&#39;, &#39;.&#39;]
</span></span><span class=line><span class=cl>품사 태깅 : [(&#39;무엇&#39;, &#39;NNG&#39;), (&#39;이&#39;, &#39;VCP&#39;), (&#39;든&#39;, &#39;ECE&#39;), (&#39;상상&#39;, &#39;NNG&#39;), (&#39;하&#39;, &#39;XSV&#39;), (&#39;ᄅ&#39;, &#39;ETD&#39;), (&#39;수&#39;, &#39;NNB&#39;), (&#39;있&#39;, &#39;VV&#39;), (&#39;는&#39;, &#39;ETD&#39;), (&#39;사람&#39;, &#39;NNG&#39;), (&#39;은&#39;, &#39;JX&#39;), (&#39;무엇&#39;, &#39;NP&#39;), (&#39;이&#39;, &#39;VCP&#39;), (&#39;든&#39;, &#39;ECE&#39;), (&#39;만들&#39;, &#39;VV&#39;), (&#39;어&#39;, &#39;ECD&#39;), (&#39;내&#39;, &#39;VX&#39;), (&#39;ᄅ&#39;, &#39;ETD&#39;), (&#39;수&#39;, &#39;NNB&#39;), (&#39;있&#39;, &#39;VV&#39;), (&#39;다&#39;, &#39;EFN&#39;), (&#39;.&#39;, &#39;SF&#39;)]
</span></span></code></pre></td></tr></table></div></div><h4 id=형태소-어휘-사전>형태소 어휘 사전</h4><p>형태소 어휘 사전(Morpheme Vocabulary)는 자연어 처리에서 사용되는 단어 집합인 어휘 사전 중에서도 각 단어의 형태소 정보를 포함하는 사전을 말한다. &ldquo;그녀&rdquo;, &ldquo;그녀는&rdquo;, &ldquo;그녀에게"를 모두 같은 의미 단위인 단어도 쉽게 학습할 수 있다.</p><p>일반적으로 형태소 어휘 사전에는 각 형태소가 어떤 품사(Part Of Speech, POS)에 속하는지와 그 품사의 뜻에 대한 정보도 같이 제공된다. 품사를 태깅하는 작업은 품사 태깅(POS Tagging)이라고 한다. 이를 통해 문맥을 고려할 수 있어 더욱 정확한 분석이 가능하다.</p><h3 id=하위-단어-토근화>하위 단어 토근화</h3><p>언어는 시간이 지남에 따라 변화한다. 신조어나 축약어가 등장하거나 더 이상 쓰이지 않는 표현도 생긴다. 또한 디지털 시대에는 오탈자가 많아 기존 형태소 분석기로 토큰화하기 어려울 수 있다.</p><p>형태소 분석기는 전문용어나 고유어에 취약하다. 즉, 형태소 분석기는 모르는 단어를 적절한 단어로 나누는 것에 취약하며, 이는 잠재적으로 어휘 사전의 크기를 크게 만들고 OOV(Out of Vocabulary)에 대응하기 어렵다.</p><p>이를 해결하기 위한 방법 중 하나로 하위 단어 토큰화(Subword Tokenization)가 있다. 하위 단어 토큰화란 하나의 단어가 빈번하게 사용되는 하위 단어(Subword)의 조합으로 나누어 토큰화 하는 방법이다. 예를 들어 &lsquo;Reinforcement&rsquo;라는 단어는 길이가 비교적 길어 처리가 어려울 수 있다. 하위 단어 토큰화를 적용한다면 &lsquo;Rein&rsquo;, &lsquo;force&rsquo;, &lsquo;ment&rsquo; 등으로 나눠 처리할 수 있다.</p><h4 id=바이트-페어-인코딩>바이트 페어 인코딩</h4><p>바이트 페어 인코딩(Byte Pair Encoding, BPE)이란 다이그램 코딩(Digram Coding)이라고도 하며 하위 단어 토큰화의 한 종류다. 초기에는 데이터 압축을 위해 개발됐으나, 자연어 처리 분야에서 하위 단어 토큰화를 위한 방법으로 사용된다.</p><p>빈도 사전 내 모든 단어를 글자 단위로 나누고, 가장 많이 등장한 글자 쌍을 병합하고 어휘 사전에 추가하는 과정 반복하여 사전을 구축한다.</p><h4 id=센텐스피스>센텐스피스</h4><p>구글에서 개발한 오픈소스 하위 단어 토크나이저 라이브러리로, 바이트 페어 인코딩과 유사한 알고리즘을 사용하였다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sentencepiece</span> <span class=kn>import</span> <span class=n>SentencePieceProcessor</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>SentencePieceProcessor</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&#34;../models/petition_bpe.model&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>sentence</span> <span class=o>=</span> <span class=s2>&#34;안녕하세요, 토크나이저가 잘 학습되었군요!&#34;</span>
</span></span><span class=line><span class=cl><span class=n>sentences</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;이렇게 입력값을 리스트로 받아서&#34;</span><span class=p>,</span> <span class=s2>&#34;쉽게 토크나이저를 사용할 수 있답니다&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tokenized_sentence</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode_as_pieces</span><span class=p>(</span><span class=n>sentence</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>tokenized_sentences</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode_as_pieces</span><span class=p>(</span><span class=n>sentences</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;단일 문장 토큰화 :&#34;</span><span class=p>,</span> <span class=n>tokenized_sentence</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;여러 문장 토큰화 :&#34;</span><span class=p>,</span> <span class=n>tokenized_sentences</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>encoded_sentence</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode_as_ids</span><span class=p>(</span><span class=n>sentence</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>encoded_sentences</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode_as_ids</span><span class=p>(</span><span class=n>sentences</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;단일 문장 정수 인코딩 :&#34;</span><span class=p>,</span> <span class=n>encoded_sentence</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;여러 문장 정수 인코딩 :&#34;</span><span class=p>,</span> <span class=n>encoded_sentences</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>decode_ids</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>decode_ids</span><span class=p>(</span><span class=n>encoded_sentences</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>decode_pieces</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>decode_pieces</span><span class=p>(</span><span class=n>encoded_sentences</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;정수 인코딩에서 문장 변환 :&#34;</span><span class=p>,</span> <span class=n>decode_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;하위 단어 토큰에서 문장 변환 :&#34;</span><span class=p>,</span> <span class=n>decode_pieces</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>단일 문장 토큰화 : [&#39;안녕하세요&#39;, &#39;,&#39;, &#39;토&#39;, &#39;크&#39;, &#39;나&#39;, &#39;이&#39;, &#39;저&#39;, &#39;가&#39;, &#39;잘&#39;, &#39;학&#39;, &#39;습&#39;, &#39;되었&#39;, &#39;군요&#39;, &#39;!&#39;]  
</span></span><span class=line><span class=cl>여러 문장 토큰화 : [[&#39;_이렇게&#39;, &#39;_입&#39;, &#39;력&#39;, &#39;값을&#39;, &#39;_리&#39;, &#39;_스트&#39;, &#39;로&#39;, &#39;_받아서&#39;], [&#39;_쉽게&#39;, &#39;_토&#39;, &#39;_크&#39;, &#39;_나&#39;, &#39;_이&#39;, &#39;_저&#39;, &#39;_를&#39;, &#39;_사용할&#39;, &#39;_수&#39;, &#39;_있&#39;, &#39;답니다&#39;]]  
</span></span><span class=line><span class=cl>단일 문장 정수 인코딩 : [664, 6553, 991, 6880, 6544, 6513, 6590, 6523, 159, 110, 6554, 868, 782, 6648]  
</span></span><span class=line><span class=cl>여러 문장 정수 인코딩 : [[370, 180, 6677, 4427, 1768, 1610, 6527, 4157], [1677, 991, 6880, 6544, 6513, 6590, 6536, 5848, 18, 5, 2633]]  
</span></span><span class=line><span class=cl>정수 인코딩에서 문장 변환 : [&#39;이렇게 입력값을 리스트로 받아서&#39;, &#39;쉽게 토크나이저를 사용할 수 있습니다&#39;]  
</span></span><span class=line><span class=cl>하위 단어 토큰에서 문장 변환 : [&#39;이렇게 입력값을 리스트로 받아서&#39;, &#39;쉽게 토크나이저를 사용할 수 있습니다&#39;]  
</span></span></code></pre></td></tr></table></div></div><h4 id=워드피스>워드피스</h4><p>워드피스(Wordpiece) 토크나이저는 확률 기반으로 글자 쌍을 병합한다. 새로운 하위 단어를 생성할 때 이전 하위 단어와 함께 나타날 확률을 계산해 가장 높은 확률을 가진 하위 단어를 선택한다. 각 글자 쌍에 대한 점수는 아래와 같이 계산된다. 여기서 $f$는 빈도(frequency)이다.</p><p>$$
\text{score} = \frac{f(x,y)}{f(x), f(y)}
$$</p><h4 id=토크나이저스>토크나이저스</h4><p>토크나이저스 라이브러리는 정규화(Normalization)와 사전 토큰화(Pre-tokenization)를 제공한다.</p><p>정규화는 일관된 형식으로 텍스트를 표준화하고 모호한 경우를 방지하기 위해 불필요한 공백 제거, 대소문자 변환, 유니코드 정규화, 구두점 처리, 특수 문자 처리 등을 제공한다.</p><p>사전 토큰화는 입력 문장을 토큰화하기 전에 단어와 같은 작은 단위로 나누는 기능을 제공한다. 공백 혹은 구두점을 기준으로 입력 문장을 나눠 텍스트 데이터를 효율적으로 처리하고 모델의 성능을 향상시킬 수 있다.</p></section><footer class=article-footer><section class=article-tags><a href=/tags/python/>Python</a>
<a href=/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/>딥러닝</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css integrity="sha256-J+iAE0sgH8QSz9hpcDxXIftnj65JEZgNhGcgReTTK9s=" crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js integrity="sha256-InsNdER1b2xUewP+pKCUJpkhiqwHgqiPXDlIk7GzBu4=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI=" crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".article-content");if(e){let t=e.innerHTML;t=t.replace(/(\$\$)([\s\S]+?)(\$\$)/g,(e,t,n,s)=>{const o=n.replace(/<em>/g,"_").replace(/<\/em>/g,"_");return`<div markdown="katex">
${t}
${o.trim()}
${s}
</div>`}),e.innerHTML=t,renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],ignoredClasses:["gist"]})}})</script></article><aside class=related-content--wrapper><h2 class=section-title>관련 글</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/pre-trained-model/><div class=article-image><img src=/../images/pytorch-transformer-nlp-computer-vision.png loading=lazy data-key=pre-trained-model data-hash=/../images/pytorch-transformer-nlp-computer-vision.png></div><div class=article-details><h2 class=article-title>Pre-trained 모델</h2></div></a></article><article class=has-image><a href=/p/data-augmentation/><div class=article-image><img src=/../images/pytorch-transformer-nlp-computer-vision.png loading=lazy data-key=data-augmentation data-hash=/../images/pytorch-transformer-nlp-computer-vision.png></div><div class=article-details><h2 class=article-title>데이터 증강 및 변환</h2></div></a></article><article class=has-image><a href=/p/regularization/><div class=article-image><img src=/../images/pytorch-transformer-nlp-computer-vision.png loading=lazy data-key=regularization data-hash=/../images/pytorch-transformer-nlp-computer-vision.png></div><div class=article-details><h2 class=article-title>정칙화</h2></div></a></article><article class=has-image><a href=/p/activation-functions/><div class=article-image><img src=/../images/pytorch-transformer-nlp-computer-vision.png loading=lazy data-key=activation-functions data-hash=/../images/pytorch-transformer-nlp-computer-vision.png></div><div class=article-details><h2 class=article-title>활성화 함수</h2></div></a></article><article class=has-image><a href=/p/optimization-functions/><div class=article-image><img src=/../images/pytorch-transformer-nlp-computer-vision.png loading=lazy data-key=optimization-functions data-hash=/../images/pytorch-transformer-nlp-computer-vision.png></div><div class=article-details><h2 class=article-title>최적화 함수의 종류와 발전 과정</h2></div></a></article></div></div></aside><script src=https://giscus.app/client.js data-repo=gyeongminn/gyeongminn.github.io data-repo-id=R_kgDOKsf9nw data-category=Announcements data-category-id=DIC_kwDOKsf9n84Ca_6Y data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=light data-lang=ko crossorigin=anonymous async></script>
<script>function setGiscusTheme(e){let t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:{setConfig:{theme:e}}},"https://giscus.app")}(function(){addEventListener("message",t=>{if(event.origin!=="https://giscus.app")return;e()}),window.addEventListener("onColorSchemeChange",e);function e(){setGiscusTheme(document.documentElement.dataset.scheme==="light"?"light":"noborder_gray")}})()</script><footer class=site-footer><section class=copyright>&copy;
2023 -
2025 Gyeongmin Lee</section><section class=powerby><br></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://cdn.jsdelivr.net/gh/orioncactus/pretendard@v1.3.9/dist/web/static/pretendard.min.css",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>