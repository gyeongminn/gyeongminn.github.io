<!doctype html><html lang=ko dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="순환 신경망(RNN)과 장단기 메모리(LSTM)의 원리와 구조에 대하여"><title>순환 신경망(RNN)과 장단기 메모리(LSTM)</title><link rel=canonical href=https://gyeongmin.kr/p/rnn-and-lstm/><link rel=stylesheet href=/scss/style.min.2325ab3f1c53340b74d88bd622b7f5bcc047e55d78831b42a905dd43de9993e0.css><meta property="og:title" content="순환 신경망(RNN)과 장단기 메모리(LSTM)"><meta property="og:description" content="순환 신경망(RNN)과 장단기 메모리(LSTM)의 원리와 구조에 대하여"><meta property="og:url" content="https://gyeongmin.kr/p/rnn-and-lstm/"><meta property="og:site_name" content="Gyeongmin의 개발 블로그"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="NLP"><meta property="article:tag" content="Python"><meta property="article:tag" content="딥러닝"><meta property="article:published_time" content="2024-04-30T00:00:00+00:00"><meta property="article:modified_time" content="2024-04-30T00:00:00+00:00"><meta property="og:image" content="https://gyeongmin.kr/images/pytorch-transformer-nlp-computer-vision.png"><meta name=twitter:title content="순환 신경망(RNN)과 장단기 메모리(LSTM)"><meta name=twitter:description content="순환 신경망(RNN)과 장단기 메모리(LSTM)의 원리와 구조에 대하여"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://gyeongmin.kr/images/pytorch-transformer-nlp-computer-vision.png"><link rel="shortcut icon" href=/logo.ico/favicon.ico><script async src="https://www.googletagmanager.com/gtag/js?id=G-RBG63ZJRZM"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-RBG63ZJRZM",{anonymize_ip:!1})}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2100464285092061" crossorigin=anonymous></script>
<link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color=#757575><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#000000"><link rel=icon href=/logo.ico/favicon.ico><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2100464285092061" crossorigin=anonymous></script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="메뉴 여닫기">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/profile_hu5d202280e416202dba72f1bb8473638c_1285338_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Gyeongmin의 개발 블로그</a></h1><h2 class=site-description>Computer Vision Engineer</h2></div></header><ol class=social-menu><li><a href=https://github.com/gyeongminn target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="22" height="22" viewBox="1 -2 19 25" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path d="M0 0h22v22H0z" stroke="none"/><path d="M8.25 17.416c-3.942 1.284-3.942-2.292-5.5-2.75m11 4.584v-3.208c0-.916.092-1.284-.458-1.834 2.566-.274 5.042-1.284 5.042-5.5a4.216 4.216.0 00-1.192-2.934A3.85 3.85.0 0017.05 2.84s-1.008-.274-3.208 1.192a11.274 11.274.0 00-5.684.0C5.958 2.566 4.95 2.841 4.95 2.841a3.85 3.85.0 00-.092 2.934A4.216 4.216.0 003.666 8.708c0 4.216 2.474 5.226 5.042 5.5-.55.55-.55 1.1-.458 1.834v3.208"/></svg></a></li><li><a href=https://www.instagram.com/gyeongminx/ target=_blank title=instagram rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-instagram" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 4m0 4a4 4 0 014-4h8a4 4 0 014 4v8a4 4 0 01-4 4H8a4 4 0 01-4-4z"/><path d="M12 12m-3 0a3 3 0 106 0 3 3 0 10-6 0"/><path d="M16.5 7.5v.01"/></svg></a></li><li><a href=https://www.linkedin.com/in/gyeongmin-lee-865448256/ target=_blank title=Linkedin rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-linkedin" width="44" height="44" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 4m0 2a2 2 0 012-2h12a2 2 0 012 2v12a2 2 0 01-2 2H6a2 2 0 01-2-2z"/><path d="M8 11v5"/><path d="M8 8v.01"/><path d="M12 16v-5"/><path d="M16 16v-3a2 2 0 00-4 0"/></svg></a></li><li><a href=mailto:gyeongmin@hansung.ac.kr target=_blank title=mail rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-mail" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path d="M0 0h24v24H0z" stroke="none"/><path d="M3 7a2 2 0 012-2h14a2 2 0 012 2v10a2 2 0 01-2 2H5a2 2 0 01-2-2V7z"/><path d="m3 7 9 6 9-6"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>About</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>Archives</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><li><a href=/links/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg><span>Links</span></a></li><div class=menu-bottom-section><li id=i18n-switch><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg><select name=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://gyeongmin.kr/ selected>한국어</option><option value=https://gyeongmin.kr/en/>English</option></select></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>다크 모드</span></li></div></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">목차</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#순환-신경망>순환 신경망</a><ol><li><a href=#자연어-데이터와-rnn>자연어 데이터와 RNN</a></li><li><a href=#rnn의-동작-원리>RNN의 동작 원리</a><ol><li><a href=#은닉-상태의-계산>은닉 상태의 계산</a></li><li><a href=#출력값의-계산>출력값의 계산</a></li></ol></li><li><a href=#순환-신경망의-다양한-구조>순환 신경망의 다양한 구조</a><ol><li><a href=#일대다-구조>일대다 구조</a></li><li><a href=#다대일-구조>다대일 구조</a></li><li><a href=#다대다-구조>다대다 구조</a></li></ol></li><li><a href=#rnn-구현-예제>RNN 구현 예제</a></li></ol></li><li><a href=#장단기-메모리>장단기 메모리</a><ol><li><a href=#rnn의-한계>RNN의 한계</a></li><li><a href=#lstm의-구조>LSTM의 구조</a><ol><li><a href=#lstm의-주요-게이트>LSTM의 주요 게이트</a></li></ol></li><li><a href=#lstm-구현-예제>LSTM 구현 예제</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/rnn-and-lstm/><img src=/../images/pytorch-transformer-nlp-computer-vision.png loading=lazy alt="Featured image of post 순환 신경망(RNN)과 장단기 메모리(LSTM)"></a></div><div class=article-details><header class=article-category><a href=/categories/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98-%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC%EC%99%80-%EC%BB%B4%ED%93%A8%ED%84%B0-%EB%B9%84%EC%A0%84-%EC%8B%AC%EC%B8%B5%ED%95%99%EC%8A%B5/>파이토치 트랜스포머를 활용한 자연어 처리와 컴퓨터 비전 심층학습</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/rnn-and-lstm/>순환 신경망(RNN)과 장단기 메모리(LSTM)</a></h2><h3 class=article-subtitle>순환 신경망(RNN)과 장단기 메모리(LSTM)의 원리와 구조에 대하여</h3></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Apr 30, 2024</time></div></footer></div></header><section class=article-content><h2 id=순환-신경망>순환 신경망</h2><p>순환 신경망(Recurrent Neural Network, RNN)은 시퀀스(Sequence) 데이터를 처리하기 위해 개발된 인공 신경망이다. 일반적인 신경망은 입력과 출력이 독립적이지만, RNN은 각 시점의 데이터가 이전 시점의 데이터에 영향을 받는 구조를 가지고 있어 자연어 처리(NLP), 시계열 분석, 음성 인식 등에 활용된다.</p><h3 id=자연어-데이터와-rnn>자연어 데이터와 RNN</h3><p>자연어 데이터 또한 연속적인 데이터의 일종이다. 문장에서 단어들은 순서대로 등장하며, 이전 단어들이 현재 단어의 의미 형성에 영향을 준다. 자연어는 이전 단어들과의 관계 속에서 문맥을 형성하며, RNN은 이러한 특성을 잘 반영할 수 있도록 설계된 신경망이다.</p><h3 id=rnn의-동작-원리>RNN의 동작 원리</h3><p>RNN의 핵심 개념은 은닉 상태(Hidden State)이다. 현재 입력값과 이전 시점의 은닉 상태를 이용하여 새로운 은닉 상태를 계산하며, 이를 통해 연속적인 정보를 유지한다.</p><h4 id=은닉-상태의-계산>은닉 상태의 계산</h4><p>각 시점 $t$에서 RNN의 은닉 상태는 다음과 같이 계산된다.</p><p>$$
h_t = \sigma_h(W_{hh} h_{t-1} + W_{xh} x_t + b_h)
$$</p><ul><li>$\sigma_h$ : 순환 신경망의 은닉 상태를 계산하기 위한 활성화 함수</li><li>$W_{hh}$ : 이전 시점의 은닉 상태 $h_{t-1}$에 대한 가중치</li><li>$W_{xh}$ : 현재 입력값 $x_t$에 대한 가중치</li><li>$b_h$ : 은닉 상태 $h_t$의 편향</li></ul><h4 id=출력값의-계산>출력값의 계산</h4><p>출력값 $ y_t $는 현재 은닉 상태를 이용해 다음과 같이 계산된다.</p><p>$$
y_t = \sigma_y(W_{hy} h_t + b_y)
$$</p><ul><li>$\sigma_y$ : 출력값을 계산하기 위한 활성화 함수</li><li>$W_{hy}$ : 현재 시점의 은닉 상태 $h_t$에 대한 가중치</li><li>$b_y$ : 출력값 $y_t$의 편향</li></ul><p>이처럼 RNN은 과거의 정보를 계속 은닉 상태에 저장하면서 새로운 입력값을 반영하는 방식으로 작동한다.</p><h3 id=순환-신경망의-다양한-구조>순환 신경망의 다양한 구조</h3><p>RNN은 다양한 방식으로 설계될 수 있으며, 크게 일대다(One-to-Many), 다대일(Many-to-One), 다대다(Many-to-Many) 구조가 존재한다.</p><h4 id=일대다-구조>일대다 구조</h4><p>하나의 입력에 대해 여러 개의 출력을 생성하는 구조이다. 예를 들어, 이미지 캡셔닝(Image Captioning)에서는 하나의 이미지를 입력받아 여러 단어로 구성된 설명 문장을 출력한다.</p><h4 id=다대일-구조>다대일 구조</h4><p>여러 개의 입력을 받아 하나의 출력을 생성하는 구조이다. 감성 분석(Sentiment Analysis)이 대표적인 예로, 한 문장의 감정이 긍정인지 부정인지를 분류하는 작업이다.</p><h4 id=다대다-구조>다대다 구조</h4><p>입력과 출력이 모두 시퀀스로 이루어진 구조이다. 예를 들어, 번역 모델(Translation)이나 음성 인식(Speech Recognition)에서 활용된다.</p><h3 id=rnn-구현-예제>RNN 구현 예제</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># RNN 모델 정의</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>RNN</span><span class=p>(</span><span class=n>input_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span> <span class=n>hidden_size</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>num_layers</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>bidirectional</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 입력 데이터 생성</span>
</span></span><span class=line><span class=cl><span class=n>batch_size</span> <span class=o>=</span> <span class=mi>4</span>
</span></span><span class=line><span class=cl><span class=n>sequence_len</span> <span class=o>=</span> <span class=mi>6</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>sequence_len</span><span class=p>,</span> <span class=mi>128</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>h_0</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=mi>6</span><span class=p>,</span> <span class=n>batch_size</span><span class=p>,</span> <span class=mi>256</span><span class=p>)</span>  <span class=c1># (num_layers * bidirectional, batch, hidden_size)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 순방향 연산</span>
</span></span><span class=line><span class=cl><span class=n>outputs</span><span class=p>,</span> <span class=n>hidden</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=n>h_0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 출력 차원 확인</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>  <span class=c1># torch.Size([4, 6, 512])</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>hidden</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>   <span class=c1># torch.Size([6, 4, 256])</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=장단기-메모리>장단기 메모리</h2><p>장단기 메모리(Long Short-Term Memory, LSTM)는 순환 신경망(RNN) 기법의 하나로 기존 순환 신경망이 갖고 있던 기억력 부족과 기울기 소실 문제를 방지하도록 개발되었다.</p><h3 id=rnn의-한계>RNN의 한계</h3><p>RNN은 기본적으로 시퀀스를 잘 처리할 수 있는 구조지만, 학습 과정에서 다음과 같은 문제가 발생할 수 있다.</p><ul><li>장기 의존성 문제(Long-term dependencies): 과거의 정보를 장기간 유지하기 어렵다.</li><li>기울기 소실(Vanishing Gradient) 문제: 역전파 과정에서 기울기가 너무 작아지면서 학습이 어려워진다.</li></ul><p>이러한 문제를 해결하기 위해 장단기 메모리 모델이 개발되었다.</p><h3 id=lstm의-구조>LSTM의 구조</h3><p>LSTM은 RNN과 유사하지만, 셀 상태(Cell State)와 게이트(Gate) 구조를 추가하여 중요한 정보를 선택적으로 저장하거나 삭제할 수 있도록 설계되었다.</p><h4 id=lstm의-주요-게이트>LSTM의 주요 게이트</h4><ol><li>망각 게이트(Forget Gate): 과거 정보를 얼마나 유지할지 결정</li></ol><p>$$
f_t = \sigma(W_f x_t + U_f h_{t-1} + b_f)
$$</p><ol start=2><li>입력 게이트(Input Gate): 새로운 정보를 메모리에 얼마나 추가할지 결정</li></ol><p>$$
i_t = \sigma(W_i x_t + U_i h_{t-1} + b_i)
$$</p><p>$$
g_t = \tanh(W_g x_t + U_g h_{t-1} + b_g)
$$</p><ol start=3><li>셀 상태 업데이트(Cell State Update)</li></ol><p>$$
C_t = f_t \odot C_{t-1} + i_t \odot g_t
$$</p><ol start=4><li>출력 게이트(Output Gate): 어떤 정보를 최종적으로 출력할지 결정</li></ol><p>$$
o_t = \sigma(W_o x_t + U_o h_{t-1} + b_o)
$$</p><p>$$
h_t = o_t \odot \tanh(C_t)
$$</p><p>이러한 구조 덕분에 LSTM은 중요한 정보는 오래 기억하면서 불필요한 정보는 쉽게 잊을 수 있어, 장기 의존성 문제를 해결할 수 있다.</p><h3 id=lstm-구현-예제>LSTM 구현 예제</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LSTM</span><span class=p>(</span><span class=n>input_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span> <span class=n>hidden_size</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>num_layers</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>bidirectional</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>sequence_len</span><span class=p>,</span> <span class=mi>128</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>h_0</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=mi>6</span><span class=p>,</span> <span class=n>batch_size</span><span class=p>,</span> <span class=mi>256</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>c_0</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=mi>6</span><span class=p>,</span> <span class=n>batch_size</span><span class=p>,</span> <span class=mi>256</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>outputs</span><span class=p>,</span> <span class=p>(</span><span class=n>h_n</span><span class=p>,</span> <span class=n>c_n</span><span class=p>)</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=p>(</span><span class=n>h_0</span><span class=p>,</span> <span class=n>c_0</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>  <span class=c1># torch.Size([4, 6, 512])</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>h_n</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>  <span class=c1># torch.Size([6, 4, 256])</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>c_n</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>  <span class=c1># torch.Size([6, 4, 256])</span>
</span></span></code></pre></td></tr></table></div></div></section><footer class=article-footer><section class=article-tags><a href=/tags/nlp/>NLP</a>
<a href=/tags/python/>Python</a>
<a href=/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/>딥러닝</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css integrity="sha256-J+iAE0sgH8QSz9hpcDxXIftnj65JEZgNhGcgReTTK9s=" crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js integrity="sha256-InsNdER1b2xUewP+pKCUJpkhiqwHgqiPXDlIk7GzBu4=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI=" crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".article-content");if(e){let t=e.innerHTML;t=t.replace(/\\big[oO]/g,"\\mathcal{O}"),t=t.replace(/(\$\$)([\s\S]+?)(\$\$)/g,(e,t,n,s)=>{const o=n.replace(/<em>/g,"_").replace(/<\/em>/g,"_");return`<div markdown="katex">
${t}
${o.trim()}
${s}
</div>`}),e.innerHTML=t,renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],ignoredClasses:["gist"]})}})</script></article><aside class=related-content--wrapper><h2 class=section-title>관련 글</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/text-embedding/><div class=article-image><img src=/../images/pytorch-transformer-nlp-computer-vision.png loading=lazy data-key=text-embedding data-hash=/../images/pytorch-transformer-nlp-computer-vision.png></div><div class=article-details><h2 class=article-title>텍스트 임베딩</h2></div></a></article><article class=has-image><a href=/p/text-vectorization/><div class=article-image><img src=/../images/pytorch-transformer-nlp-computer-vision.png loading=lazy data-key=text-vectorization data-hash=/../images/pytorch-transformer-nlp-computer-vision.png></div><div class=article-details><h2 class=article-title>텍스트 벡터화</h2></div></a></article><article class=has-image><a href=/p/tokenization/><div class=article-image><img src=/../images/pytorch-transformer-nlp-computer-vision.png loading=lazy data-key=tokenization data-hash=/../images/pytorch-transformer-nlp-computer-vision.png></div><div class=article-details><h2 class=article-title>토큰화</h2></div></a></article><article class=has-image><a href=/p/data-augmentation/><div class=article-image><img src=/../images/pytorch-transformer-nlp-computer-vision.png loading=lazy data-key=data-augmentation data-hash=/../images/pytorch-transformer-nlp-computer-vision.png></div><div class=article-details><h2 class=article-title>데이터 증강 및 변환</h2></div></a></article><article class=has-image><a href=/p/language-model/><div class=article-image><img src=/../images/pytorch-transformer-nlp-computer-vision.png loading=lazy data-key=language-model data-hash=/../images/pytorch-transformer-nlp-computer-vision.png></div><div class=article-details><h2 class=article-title>언어 모델</h2></div></a></article></div></div></aside><script src=https://giscus.app/client.js data-repo=gyeongminn/gyeongminn.github.io data-repo-id=R_kgDOKsf9nw data-category=Announcements data-category-id=DIC_kwDOKsf9n84Ca_6Y data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=light data-lang=ko crossorigin=anonymous async></script>
<script>function setGiscusTheme(e){let t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:{setConfig:{theme:e}}},"https://giscus.app")}(function(){addEventListener("message",t=>{if(event.origin!=="https://giscus.app")return;e()}),window.addEventListener("onColorSchemeChange",e);function e(){setGiscusTheme(document.documentElement.dataset.scheme==="light"?"light":"noborder_gray")}})()</script><footer class=site-footer><section class=copyright>&copy;
2023 -
2025 Gyeongmin Lee</section><section class=powerby><br></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://cdn.jsdelivr.net/gh/orioncactus/pretendard@v1.3.9/dist/web/static/pretendard.min.css",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>