<!doctype html><html lang=ko dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="단어의 의미를 컴퓨터에게 이해시키는 방법"><title>단어의 분산 표현</title><link rel=canonical href=https://gyeongmin.kr/p/word-distributed-representation/><link rel=stylesheet href=/scss/style.min.2325ab3f1c53340b74d88bd622b7f5bcc047e55d78831b42a905dd43de9993e0.css><meta property="og:title" content="단어의 분산 표현"><meta property="og:description" content="단어의 의미를 컴퓨터에게 이해시키는 방법"><meta property="og:url" content="https://gyeongmin.kr/p/word-distributed-representation/"><meta property="og:site_name" content="Gyeongmin의 개발 블로그"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="딥러닝"><meta property="article:tag" content="Python"><meta property="article:published_time" content="2023-11-27T00:00:00+00:00"><meta property="article:modified_time" content="2023-11-27T00:00:00+00:00"><meta property="og:image" content="https://gyeongmin.kr/images/deep-learning-from-scratch.jpeg"><meta name=twitter:title content="단어의 분산 표현"><meta name=twitter:description content="단어의 의미를 컴퓨터에게 이해시키는 방법"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://gyeongmin.kr/images/deep-learning-from-scratch.jpeg"><link rel="shortcut icon" href=/logo.ico/favicon.ico><script async src="https://www.googletagmanager.com/gtag/js?id=G-RBG63ZJRZM"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-RBG63ZJRZM",{anonymize_ip:!1})}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2100464285092061" crossorigin=anonymous></script>
<link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color=#757575><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#000000"><link rel=icon href=/logo.ico/favicon.ico><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2100464285092061" crossorigin=anonymous></script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="메뉴 여닫기">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/profile_hu5d202280e416202dba72f1bb8473638c_1285338_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Gyeongmin의 개발 블로그</a></h1><h2 class=site-description>Vision Engineer</h2></div></header><ol class=social-menu><li><a href=https://github.com/gyeongminn target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="22" height="22" viewBox="1 -2 19 25" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path d="M0 0h22v22H0z" stroke="none"/><path d="M8.25 17.416c-3.942 1.284-3.942-2.292-5.5-2.75m11 4.584v-3.208c0-.916.092-1.284-.458-1.834 2.566-.274 5.042-1.284 5.042-5.5a4.216 4.216.0 00-1.192-2.934A3.85 3.85.0 0017.05 2.84s-1.008-.274-3.208 1.192a11.274 11.274.0 00-5.684.0C5.958 2.566 4.95 2.841 4.95 2.841a3.85 3.85.0 00-.092 2.934A4.216 4.216.0 003.666 8.708c0 4.216 2.474 5.226 5.042 5.5-.55.55-.55 1.1-.458 1.834v3.208"/></svg></a></li><li><a href=https://www.instagram.com/gyeongminx/ target=_blank title=instagram rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-instagram" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 4m0 4a4 4 0 014-4h8a4 4 0 014 4v8a4 4 0 01-4 4H8a4 4 0 01-4-4z"/><path d="M12 12m-3 0a3 3 0 106 0 3 3 0 10-6 0"/><path d="M16.5 7.5v.01"/></svg></a></li><li><a href=https://www.linkedin.com/in/gyeongmin-lee-865448256/ target=_blank title=Linkedin rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-linkedin" width="44" height="44" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 4m0 2a2 2 0 012-2h12a2 2 0 012 2v12a2 2 0 01-2 2H6a2 2 0 01-2-2z"/><path d="M8 11v5"/><path d="M8 8v.01"/><path d="M12 16v-5"/><path d="M16 16v-3a2 2 0 00-4 0"/></svg></a></li><li><a href=mailto:gyeongmin@hansung.ac.kr target=_blank title=mail rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-mail" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path d="M0 0h24v24H0z" stroke="none"/><path d="M3 7a2 2 0 012-2h14a2 2 0 012 2v10a2 2 0 01-2 2H5a2 2 0 01-2-2V7z"/><path d="m3 7 9 6 9-6"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>About</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>Archives</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><li><a href=/links/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg><span>Links</span></a></li><div class=menu-bottom-section><li id=i18n-switch><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg><select name=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://gyeongmin.kr/ selected>한국어</option><option value=https://gyeongmin.kr/en/>English</option></select></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>다크 모드</span></li></div></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">목차</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#자연어-처리와-단어의-의미>자연어 처리와 단어의 의미</a></li><li><a href=#시소러스>시소러스</a><ol><li><a href=#wordnet>WordNet</a></li><li><a href=#문제점>문제점</a></li></ol></li><li><a href=#통계-기반-기법>통계 기반 기법</a><ol><li><a href=#말뭉치-전처리>말뭉치 전처리</a></li><li><a href=#분포-가설과-분산-표현>분포 가설과 분산 표현</a></li><li><a href=#동시-행렬-발생>동시 행렬 발생</a></li><li><a href=#벡터간-유사도>벡터간 유사도</a></li><li><a href=#유사-단어의-랭킹>유사 단어의 랭킹</a></li></ol></li><li><a href=#통계-기반-기법의-개선>통계 기반 기법의 개선</a><ol><li><a href=#상호정보량>상호정보량</a></li><li><a href=#차원-축소>차원 축소</a></li><li><a href=#ptb-데이터셋-평가>PTB 데이터셋 평가</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/word-distributed-representation/><img src=/../images/deep-learning-from-scratch.jpeg loading=lazy alt="Featured image of post 단어의 분산 표현"></a></div><div class=article-details><header class=article-category><a href=/categories/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-2/>밑바닥부터 시작하는 딥러닝 2</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/word-distributed-representation/>단어의 분산 표현</a></h2><h3 class=article-subtitle>단어의 의미를 컴퓨터에게 이해시키는 방법</h3></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Nov 27, 2023</time></div></footer></div></header><section class=article-content><blockquote><p>본 포스팅은 &lsquo;밑바닥부터 시작하는 딥러닝 2&rsquo; 교재를 참고했습니다.</p></blockquote><h2 id=자연어-처리와-단어의-의미>자연어 처리와 단어의 의미</h2><p><strong>자연어</strong>(Natural Language)란 우리가 평소에 사용하는 언어, 예를 들어 한국어나 영어를 말한다. <strong>자연어 처리</strong>(NLP, Natural Language Processing)는 이러한 자연어를 컴퓨터가 이해하도록 만드는 기술 분야이다.</p><p>우리의 말은 문자로 이루어져 있고, 말의 의미는 <strong>단어</strong>로 구성된다. 따라서 컴퓨터가 자연어를 이해하도록 하려면 우선 단어의 의미부터 이해시켜야 한다.</p><h2 id=시소러스>시소러스</h2><blockquote><p>단어의 의미를 나타내는 가장 Naive한 방법</p></blockquote><p>사람이 직접 단어의 의미를 정의하는 방식으로, 쉽게 말해 &lsquo;유의어 사전&rsquo;이다.</p><p>car, auto, automobile은 모두 자동차를 나타낸다. 시소러스에서는 이러한 유의어/동의어를 한 그룹으로 분류한다.</p><pre class=mermaid>graph LR
car~~~auto~~~automobile
  </pre><p>또한 단어 간의 상위/하위, 전체/부분 등 세세한 관계까지 정의하기도 한다.</p><pre class=mermaid>flowchart TD
    a[object] --> b[mortor vehicle]
    b --> d[go-cart]
    b --> c[car]
    b --> e[truck]
    c --> f[suv]
    c --> g[compact]
    c --> h[hatch-back]
  </pre><h3 id=wordnet>WordNet</h3><p>1985년 구축된 WordNet은 자연어 처리 분야에서 가장 유명한 시소러스이다.</p><p>WordNet을 사용하면 유의어를 얻거나, 단어 네트워크를 사용해 단어 간의 유사도를 구할 수 있다.</p><h3 id=문제점>문제점</h3><p>사람이 수작업으로 라벨링 해야하기에 여러 단점이 존재한다.</p><ul><li><p>시대 변화에 대응하기 어렵다.</p><ul><li>단어의 의미는 시간이 지남에 따라 변하기도 하고, 새로운 단어가 생기기도 한다.</li></ul></li><li><p>비용이 많이 든다.</p><ul><li>영어 단어만 해도 1000만개가 넘으며, 이는 높은 인적 비용을 요구한다.</li></ul></li><li><p>단어 간의 미묘한 차이를 표현할 수 없다.</p><ul><li>예를 들어 빈티지와 레트로의 경우 의미는 같지만, 용법은 다르다. 시소러스는 이러한 차이를 표현할 수 없다.</li></ul></li></ul><h2 id=통계-기반-기법>통계 기반 기법</h2><p>통계 기반 기법을 사용하기 위해 우리는 말뭉치(corpus)를 이용할 것이다.</p><p>말뭉치란 자연어처리 연구나 어플리케이션을 위해 수집된 대량의 텍스트 데이터로, 대표적인 말뭉치는 위키백과, 구글뉴스, 셰익스피어의 소설 등이 있다.</p><h3 id=말뭉치-전처리>말뭉치 전처리</h3><p>작은 말뭉치를 전처리하는 과정을 살펴보자.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>text</span> <span class=o>=</span> <span class=s1>&#39;You say goodbye and I say hello.&#39;</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>  <span class=c1># 모두 소문자로 변환</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s1>&#39;.&#39;</span><span class=p>,</span> <span class=s1>&#39; .&#39;</span><span class=p>)</span>  <span class=c1># &#39;.&#39;을 &#39; .&#39;으로 변환</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>text</span> 
</span></span><span class=line><span class=cl><span class=s1>&#39;you say goodbye and i say hello .&#39;</span>
</span></span></code></pre></td></tr></table></div></div><p>모든 단어를 소문자로 변환하고, 단어의 마지막 점을 띄워줬다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>words</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>split</span><span class=p>()</span>  <span class=c1># 공백을 기준으로 나눔</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>words</span> 
</span></span><span class=line><span class=cl><span class=p>[</span><span class=s1>&#39;you&#39;</span><span class=p>,</span> <span class=s1>&#39;say&#39;</span><span class=p>,</span> <span class=s1>&#39;goodbye&#39;</span><span class=p>,</span> <span class=s1>&#39;and&#39;</span><span class=p>,</span> <span class=s1>&#39;i&#39;</span><span class=p>,</span> <span class=s1>&#39;say&#39;</span><span class=p>,</span> <span class=s1>&#39;hello&#39;</span><span class=p>,</span> <span class=s1>&#39;.&#39;</span><span class=p>]</span>
</span></span></code></pre></td></tr></table></div></div><p>공백을 기준으로 나눠, 리스트에 담았다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>word_to_id</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>id_to_word</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>words</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=o>...</span>     <span class=k>if</span> <span class=n>word</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>word_to_id</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=o>...</span>         <span class=n>new_id</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>word_to_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=o>...</span>         <span class=n>word_to_id</span><span class=p>[</span><span class=n>word</span><span class=p>]</span> <span class=o>=</span> <span class=n>new_id</span>
</span></span><span class=line><span class=cl><span class=o>...</span>         <span class=n>id_to_word</span><span class=p>[</span><span class=n>new_id</span><span class=p>]</span> <span class=o>=</span> <span class=n>word</span>
</span></span></code></pre></td></tr></table></div></div><p><code>word_to_id</code> 의 경우 key가 단어, value는 id이다. <code>id_to_word</code>는 그 반대이다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>id_to_word</span>
</span></span><span class=line><span class=cl><span class=p>{</span><span class=mi>0</span><span class=p>:</span> <span class=s1>&#39;you&#39;</span><span class=p>,</span> <span class=mi>1</span><span class=p>:</span> <span class=s1>&#39;say&#39;</span><span class=p>,</span> <span class=mi>2</span><span class=p>:</span> <span class=s1>&#39;goodbye&#39;</span><span class=p>,</span> <span class=mi>3</span><span class=p>:</span> <span class=s1>&#39;and&#39;</span><span class=p>,</span> <span class=mi>4</span><span class=p>:</span> <span class=s1>&#39;i&#39;</span><span class=p>,</span> <span class=mi>5</span><span class=p>:</span> <span class=s1>&#39;hello&#39;</span><span class=p>,</span> <span class=mi>6</span><span class=p>:</span> <span class=s1>&#39;.&#39;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>word_to_id</span>
</span></span><span class=line><span class=cl><span class=p>{</span><span class=s1>&#39;you&#39;</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span> <span class=s1>&#39;say&#39;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;goodbye&#39;</span><span class=p>:</span> <span class=mi>2</span><span class=p>,</span> <span class=s1>&#39;and&#39;</span><span class=p>:</span> <span class=mi>3</span><span class=p>,</span> <span class=s1>&#39;i&#39;</span><span class=p>:</span> <span class=mi>4</span><span class=p>,</span> <span class=s1>&#39;hello&#39;</span><span class=p>:</span> <span class=mi>5</span><span class=p>,</span> <span class=s1>&#39;.&#39;</span><span class=p>:</span> <span class=mi>6</span><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>마지막으로 단어 목록을 단어 ID 목록으로 변환하면 된다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>corpus</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>word_to_id</span><span class=p>[</span><span class=n>w</span><span class=p>]</span> <span class=k>for</span> <span class=n>w</span> <span class=ow>in</span> <span class=n>words</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;&gt;</span> <span class=n>corpus</span>
</span></span><span class=line><span class=cl><span class=n>array</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>이렇게 범주형 변수를 숫자로 바꾸는 것을 <strong>원 핫 인코딩(one-hot encodeing)</strong> 이라고 한다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=k>def</span> <span class=nf>preprocess</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s1>&#39;.&#39;</span><span class=p>,</span> <span class=s1>&#39; .&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>words</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39; &#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>word_to_id</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>    <span class=n>id_to_word</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>words</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>word</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>word_to_id</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>new_id</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>word_to_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>word_to_id</span><span class=p>[</span><span class=n>word</span><span class=p>]</span> <span class=o>=</span> <span class=n>new_id</span>
</span></span><span class=line><span class=cl>            <span class=n>id_to_word</span><span class=p>[</span><span class=n>new_id</span><span class=p>]</span> <span class=o>=</span> <span class=n>word</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>corpus</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>word_to_id</span><span class=p>[</span><span class=n>w</span><span class=p>]</span> <span class=k>for</span> <span class=n>w</span> <span class=ow>in</span> <span class=n>words</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>corpus</span><span class=p>,</span> <span class=n>word_to_id</span><span class=p>,</span> <span class=n>id_to_word</span>
</span></span></code></pre></td></tr></table></div></div><p>위 과정을 합쳐 단어를 전처리하는 preprocess 함수를 구현했다.</p><h3 id=분포-가설과-분산-표현>분포 가설과 분산 표현</h3><blockquote><p>비슷한 위치에서 등장한 단어는 비슷한 의미를 가지지 않을까?</p></blockquote><p>&ldquo;단어의 의미는 주변 단어에 의해 형성된다.&rdquo; 라는 것을 <strong>분포 가설</strong>이라고 한다.</p><p>단어 자체에는 의미가 없고, 그 단어가 사용 된 맥락이 의미를 형성한다는 것이다. 여기서 맥락이란 특정 단어를 중심에 둔 그 주변 단어를 말한다.</p><p>좌우 모든 단어를 고려하며 계산하면 컴퓨팅 비용이 너무 많이 들기에, 우리는 특정 크기만큼만 고려할 것이다. 즉, 슬라이딩 윈도우를 적용할 것이다. &lsquo;맥락의 크기&rsquo;는 슬라이딩 윈도우의 사이즈와 같다.</p><p><strong>분산 표현</strong> 이란 <strong>분포 가설에 기반해 주변 단어의 분포를 기준으로 단어의 벡터 표현을 결정하는 것</strong> 이다.</p><h3 id=동시-행렬-발생>동시 행렬 발생</h3><p>분포 가설에 기초해 단어를 벡터로 나타내 보자.</p><p>가장 간단한 방법은 한 단어에 주목하여, 주변에 어떤 단어가 몇 번 등장했는지 계산하는 것이다. 이는 통계 기반 기법(statistical based)이라고 한다.</p><blockquote><p>{&lsquo;you&rsquo;: 0, &lsquo;say&rsquo;: 1, &lsquo;goodbye&rsquo;: 2, &lsquo;and&rsquo;: 3, &lsquo;i&rsquo;: 4, &lsquo;hello&rsquo;: 5, &lsquo;.&rsquo;: 6}</p></blockquote><p>예를 들어, &lsquo;<u>you</u> <strong>say</strong> <u>goodbye</u> and <u>i</u> <strong>say</strong> <u>hello</u> .&rsquo; 에서 &lsquo;say&rsquo;를 기준으로 살펴보자.</p><p>&lsquo;say&rsquo; 좌우로 &lsquo;you&rsquo;, &lsquo;goodbye&rsquo;, &lsquo;i&rsquo;, &lsquo;hello&rsquo; 가 있다.</p><p>이는 벡터 &lsquo;[1, 0, 1, 0, 1, 1, 0]&rsquo; 으로 표현 할 수 있을 것이다.</p><p>이것을 모든 단어에 대해 적용시킨다면 아래와 같은 테이블을 얻을 수 있을 것이다.</p><div class=table-wrapper><table><thead><tr><th style=text-align:center></th><th style=text-align:center>you</th><th style=text-align:center>say</th><th style=text-align:center>goodbye</th><th style=text-align:center>and</th><th style=text-align:center>i</th><th style=text-align:center>hello</th><th style=text-align:center>.</th></tr></thead><tbody><tr><td style=text-align:center>you</td><td style=text-align:center>0</td><td style=text-align:center>1</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>0</td></tr><tr><td style=text-align:center>say</td><td style=text-align:center>1</td><td style=text-align:center>0</td><td style=text-align:center>1</td><td style=text-align:center>0</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>0</td></tr><tr><td style=text-align:center>goodbye</td><td style=text-align:center>0</td><td style=text-align:center>1</td><td style=text-align:center>0</td><td style=text-align:center>1</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>0</td></tr><tr><td style=text-align:center>and</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>1</td><td style=text-align:center>0</td><td style=text-align:center>1</td><td style=text-align:center>0</td><td style=text-align:center>0</td></tr><tr><td style=text-align:center>i</td><td style=text-align:center>0</td><td style=text-align:center>1</td><td style=text-align:center>0</td><td style=text-align:center>1</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>0</td></tr><tr><td style=text-align:center>hello</td><td style=text-align:center>0</td><td style=text-align:center>1</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>1</td></tr><tr><td style=text-align:center>.</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>0</td><td style=text-align:center>1</td><td style=text-align:center>0</td></tr></tbody></table></div><p>이것을 <strong>동시 발생 행렬</strong> 이라고 한다.</p><p>동시 발생 행렬을 만드는 코드는 아래와 같다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=k>def</span> <span class=nf>create_co_matrix</span><span class=p>(</span><span class=n>corpus</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>,</span> <span class=n>window_size</span><span class=o>=</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>corpus_size</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>corpus</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>co_matrix</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>int32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>idx</span><span class=p>,</span> <span class=n>word_id</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>corpus</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>window_size</span> <span class=o>+</span> <span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>left_idx</span> <span class=o>=</span> <span class=n>idx</span> <span class=o>-</span> <span class=n>i</span>
</span></span><span class=line><span class=cl>            <span class=n>right_idx</span> <span class=o>=</span> <span class=n>idx</span> <span class=o>+</span> <span class=n>i</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>left_idx</span> <span class=o>&gt;=</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>left_word_id</span> <span class=o>=</span> <span class=n>corpus</span><span class=p>[</span><span class=n>left_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=n>co_matrix</span><span class=p>[</span><span class=n>word_id</span><span class=p>,</span> <span class=n>left_word_id</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>right_idx</span> <span class=o>&lt;</span> <span class=n>corpus_size</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>right_word_id</span> <span class=o>=</span> <span class=n>corpus</span><span class=p>[</span><span class=n>right_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=n>co_matrix</span><span class=p>[</span><span class=n>word_id</span><span class=p>,</span> <span class=n>right_word_id</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>co_matrix</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=벡터간-유사도>벡터간 유사도</h3><p>앞서 구한 행렬을 통해 벡터 간의 유사도를 구한다면 단어 간의 유사도를 구할 수 있을 것이다.</p><p>벡터의 유사도를 측정하는 대표적인 방법으로는 벡터의 내적이나 유클리드 거리, 코사인 유사도가 있다. 이 중, 우리는 코사인 유사도를 사용할 것이다.</p><p>$$
\tag{1}
\text{similarity}(A, B)=\frac{A⋅B}{||A||\ ||B||}=\frac{\sum_{i=1}^{n}{A_{i}B_{i}}}{\sqrt{\sum_{i=1}^{n}(A_{i})^2}\sqrt{\sum_{i=1}^{n}(B_{i})^2}}
$$</p><p>[식 1]의 분자에는 벡터의 내적이, 분모에는 각 벡터의 노름(norm)이 등장한다. 노름은 벡터의 크기를 나타낸 것으로, 여기선 L2 노름을 계산한다.</p><blockquote><p>코사인 유사도는 두 벡터가 가르키는 방향이 얼마나 유사한지를 나타낸다. 방향이 같으면 1, 반대면 -1이다.</p></blockquote><p>파이썬 코드로는 아래와 같이 나타낼 수 있다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=k>def</span> <span class=nf>cos_similarity</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>eps</span><span class=o>=</span><span class=mf>1e-8</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>nx</span> <span class=o>=</span> <span class=n>x</span> <span class=o>/</span> <span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>x</span> <span class=o>**</span> <span class=mi>2</span><span class=p>))</span> <span class=o>+</span> <span class=n>eps</span><span class=p>)</span>  <span class=c1># x의 정규화</span>
</span></span><span class=line><span class=cl>    <span class=n>ny</span> <span class=o>=</span> <span class=n>y</span> <span class=o>/</span> <span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>y</span> <span class=o>**</span> <span class=mi>2</span><span class=p>))</span> <span class=o>+</span> <span class=n>eps</span><span class=p>)</span>  <span class=c1># y의 정규화</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>nx</span><span class=p>,</span> <span class=n>ny</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>0으로 나누어 오류가 나는 일이 없도록 $10^{-8}$ 이라는 작은 값을 더해주는 것을 볼 수 있다.</p><h3 id=유사-단어의-랭킹>유사 단어의 랭킹</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=k>def</span> <span class=nf>most_similar</span><span class=p>(</span><span class=n>query</span><span class=p>,</span> <span class=n>word_to_id</span><span class=p>,</span> <span class=n>id_to_word</span><span class=p>,</span> <span class=n>word_matrix</span><span class=p>,</span> <span class=n>top</span><span class=o>=</span><span class=mi>5</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>query</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>word_to_id</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;</span><span class=si>%s</span><span class=s1> is not found&#39;</span> <span class=o>%</span> <span class=n>query</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>[query] &#39;</span> <span class=o>+</span> <span class=n>query</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>query_id</span> <span class=o>=</span> <span class=n>word_to_id</span><span class=p>[</span><span class=n>query</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>query_vec</span> <span class=o>=</span> <span class=n>word_matrix</span><span class=p>[</span><span class=n>query_id</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>vocab_size</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>id_to_word</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>similarity</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>similarity</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>cos_similarity</span><span class=p>(</span><span class=n>word_matrix</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>query_vec</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>count</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=p>(</span><span class=o>-</span><span class=mi>1</span> <span class=o>*</span> <span class=n>similarity</span><span class=p>)</span><span class=o>.</span><span class=n>argsort</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>id_to_word</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>==</span> <span class=n>query</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>continue</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39; </span><span class=si>%s</span><span class=s1>: </span><span class=si>%s</span><span class=s1>&#39;</span> <span class=o>%</span> <span class=p>(</span><span class=n>id_to_word</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>similarity</span><span class=p>[</span><span class=n>i</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>count</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>count</span> <span class=o>&gt;=</span> <span class=n>top</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span>
</span></span></code></pre></td></tr></table></div></div><p>위 코드로 &lsquo;you&rsquo; 와 유사한 단어를 찾아보자.</p><div class=table-wrapper><table><thead><tr><th style=text-align:center></th><th>Value</th></tr></thead><tbody><tr><td style=text-align:center>goodbye</td><td>0.7071067691154799</td></tr><tr><td style=text-align:center>i</td><td>0.7071067691154799</td></tr><tr><td style=text-align:center>hello</td><td>0.7071067691154799</td></tr><tr><td style=text-align:center>say</td><td>0.0</td></tr><tr><td style=text-align:center>and</td><td>0.0</td></tr></tbody></table></div><p>&lsquo;goodbye&rsquo;, &lsquo;i&rsquo;, &lsquo;hello&rsquo;의 경우 &lsquo;say&rsquo;나 &lsquo;and&rsquo;에 비해 유사하다고 볼 수 있다.</p><h2 id=통계-기반-기법의-개선>통계 기반 기법의 개선</h2><h3 id=상호정보량>상호정보량</h3><blockquote><p>발생 횟수는 좋은 특징이 아니다</p></blockquote><p><strong>동시 발생 행렬</strong>은 두 단어가 동시에 발생한 빈도를 측정한다. 하지만 이것만으로는 부족하다. &rsquo;the&rsquo;, &rsquo;this&rsquo;처럼 <strong>고빈도 단어</strong> 의 경우를 생각해 보자.</p><p>&lsquo;drive&rsquo;, &rsquo;the&rsquo; 중에 &lsquo;car&rsquo;와 더 유사한 단어는 무엇인가? 모두 &lsquo;drive&rsquo;와 유사한 단어로 &lsquo;car&rsquo;를 고를 것이다.</p><p>하지만 동시 발생 빈도는 &rsquo;the&rsquo;가 압도적으로 높을 것이다. 동시 발생 행렬에서는 &rsquo;the&rsquo; 자체가 문서에서 <strong>더 많이 등장</strong>하기에, 더 높은 유사성을 갖는다고 잘못 평가할 수 있다.</p><p>이 문제를 해결하기 위해 <strong>점별 상호정보량</strong>(PMI, Pointwise Mutual Information) 이라는 척도를 사용할 것이다.</p><p><strong>PMI</strong>는 확률 변수 $x$와 $y$에 대해 다음과 같은 식으로 정의된다.</p><p>$$
\tag{2}
\text{PMI}(x,y)=\log_2\frac{P(x,y)}{P(x)P(y)}
$$</p><p>[식 2]에서 $P(x)$는 $x$가 일어날 확률, $P(y)$는 $y$가 일어날 확률, $P(x,y)$는 $x, y$가 동시에 일어날 확률이다. PMI가 높을 수록 관련성이 높다는 의미이다.</p><p>자연어 처리에서 $P(x)$는 말뭉치에서 $x$라는 단어가 등장할 확률이다. 예를 들어, 단어 100,000개의 말뭉치에서 &rsquo;the&rsquo;라는 단어가 100번 등장했다면, $P(`\text{the}&rsquo;) = 0.0001$이다.</p><p>하지만 PMI도 문제가 있다. 동시 발생 횟수가 0이라면 PMI 값은 $-\infty$가 된다.</p><p>따라서 <strong>PPMI</strong>(Positive PMI) 라는 척도를 쓴다. 이는 다음과 같다.</p><p>$$
\tag{3}
\text{PPMI}(x, y) = \max(0, \text{PMI}(x,y))
$$</p><p>[식 3]을 보면, PPMI는 PMI값이 음수면 0으로 취급한다는 것을 확인할 수 있다.</p><p>이제 PPMI를 파이썬으로 구현해 보자.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=k>def</span> <span class=nf>ppmi</span><span class=p>(</span><span class=n>C</span><span class=p>,</span> <span class=n>eps</span> <span class=o>=</span> <span class=mf>1e-8</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>M</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=n>C</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>N</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>C</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>S</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>C</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>C</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>C</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>            <span class=n>pmi</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>log2</span><span class=p>(</span><span class=n>C</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>j</span><span class=p>]</span> <span class=o>*</span> <span class=n>N</span> <span class=o>/</span> <span class=p>(</span><span class=n>S</span><span class=p>[</span><span class=n>j</span><span class=p>]</span><span class=o>*</span><span class=n>S</span><span class=p>[</span><span class=n>i</span><span class=p>])</span> <span class=o>+</span> <span class=n>eps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>M</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>j</span><span class=p>]</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>pmi</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>M</span>
</span></span></code></pre></td></tr></table></div></div><p>이제 동시 발생 행렬을 PPMI로 변환해 보자.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=s1>&#39;You say goodbye and I say hello.&#39;</span>
</span></span><span class=line><span class=cl><span class=n>corpus</span><span class=p>,</span> <span class=n>word_to_id</span><span class=p>,</span> <span class=n>id_to_word</span> <span class=o>=</span> <span class=n>preprocess</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>vocab_size</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>word_to_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>C</span> <span class=o>=</span> <span class=n>create_co_matrix</span><span class=p>(</span><span class=n>corpus</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>W</span> <span class=o>=</span> <span class=n>ppmi</span><span class=p>(</span><span class=n>C</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>np</span><span class=o>.</span><span class=n>set_printoptions</span><span class=p>(</span><span class=n>precision</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>  <span class=c1># 유효 자릿수를 세 자리로 표시</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;동시발생 행렬&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>C</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;-&#39;</span><span class=o>*</span><span class=mi>50</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;PPMI&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>W</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>위 코드를 실행시킨 결과는 아래와 같다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=cl>동시발생 행렬
</span></span><span class=line><span class=cl>[[0 1 0 0 0 0 0]
</span></span><span class=line><span class=cl> [1 0 1 0 1 1 0]
</span></span><span class=line><span class=cl> [0 1 0 1 0 0 0]
</span></span><span class=line><span class=cl> [0 0 1 0 1 0 0]
</span></span><span class=line><span class=cl> [0 1 0 1 0 0 0]
</span></span><span class=line><span class=cl> [0 1 0 0 0 0 1]
</span></span><span class=line><span class=cl> [0 0 0 0 0 1 0]]
</span></span><span class=line><span class=cl>--------------------------------------------------
</span></span><span class=line><span class=cl>PPMI
</span></span><span class=line><span class=cl>[[0.    1.807 0.    0.    0.    0.    0.   ]
</span></span><span class=line><span class=cl> [1.807 0.    0.807 0.    0.807 0.807 0.   ]
</span></span><span class=line><span class=cl> [0.    0.807 0.    1.807 0.    0.    0.   ]
</span></span><span class=line><span class=cl> [0.    0.    1.807 0.    1.807 0.    0.   ]
</span></span><span class=line><span class=cl> [0.    0.807 0.    1.807 0.    0.    0.   ]
</span></span><span class=line><span class=cl> [0.    0.807 0.    0.    0.    0.    2.807]
</span></span><span class=line><span class=cl> [0.    0.    0.    0.    0.    2.807 0.   ]]
</span></span></code></pre></td></tr></table></div></div><p>이제 더 좋은 단어 벡터를 얻었다.</p><p>하지만 아직 문제점이 있다. 벡터의 크기가 너무 크다는 것이다. 단어의 개수가 10만개라면, 벡터의 차운 수도 10만이 된다.</p><p>또한, 대부분 0으로 구성된 희소행렬(Sparse Matrix)이다.</p><p>이는 매우 비효율적이고, 노이즈에 취약하다.</p><h3 id=차원-축소>차원 축소</h3><p>차원 축소는 중요한 정보는 최대한 유지하되, 벡터의 차원을 줄이는 것이다. 그 중 특잇값 분해를 적용해보자.</p><p>특잇값 분해에 대한 자세한 설명은 <a class=link href=https://pasus.tistory.com/15 target=_blank rel=noopener>여기</a> 블로그를 참고하자.</p><p>특잇값 분해를 사용한 파이썬 코드는 아래와 같다.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=s1>&#39;You say goodbye and I say hello.&#39;</span>
</span></span><span class=line><span class=cl><span class=n>corpus</span><span class=p>,</span> <span class=n>word_to_id</span><span class=p>,</span> <span class=n>id_to_word</span> <span class=o>=</span> <span class=n>preprocess</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>vocab_size</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>id_to_word</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>C</span> <span class=o>=</span> <span class=n>create_co_matrix</span><span class=p>(</span><span class=n>corpus</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>,</span> <span class=n>window_size</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>W</span> <span class=o>=</span> <span class=n>ppmi</span><span class=p>(</span><span class=n>C</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>U</span><span class=p>,</span> <span class=n>S</span><span class=p>,</span> <span class=n>V</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>svd</span><span class=p>(</span><span class=n>W</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>np</span><span class=o>.</span><span class=n>set_printoptions</span><span class=p>(</span><span class=n>precision</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>C</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>W</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>U</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>word</span><span class=p>,</span> <span class=n>word_id</span> <span class=ow>in</span> <span class=n>word_to_id</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>annotate</span><span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=p>(</span><span class=n>U</span><span class=p>[</span><span class=n>word_id</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>U</span><span class=p>[</span><span class=n>word_id</span><span class=p>,</span> <span class=mi>1</span><span class=p>]))</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>U</span><span class=p>[:,</span><span class=mi>0</span><span class=p>],</span> <span class=n>U</span><span class=p>[:,</span><span class=mi>1</span><span class=p>],</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p><img src=/p/word-distributed-representation/myplot.png width=640 height=480 srcset="/p/word-distributed-representation/myplot_huf803c14a96123a2f3e5d87800bfe075b_11535_480x0_resize_box_3.png 480w, /p/word-distributed-representation/myplot_huf803c14a96123a2f3e5d87800bfe075b_11535_1024x0_resize_box_3.png 1024w" loading=lazy class=gallery-image data-flex-grow=133 data-flex-basis=320px></p><p>위 코드는 동시발생 행렬에 SVD를 적용한 후 각 단어를 2차원 벡터로 변환한 것을 시각화 한 것이다.</p><h3 id=ptb-데이터셋-평가>PTB 데이터셋 평가</h3><p>이번에는 많은 양의 데이터를 처리해야 하므로, sklearn의 고속 SVD를 사용하자.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=kn>from</span> <span class=nn>dataset</span> <span class=kn>import</span> <span class=n>ptb</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.utils.extmath</span> <span class=kn>import</span> <span class=n>randomized_svd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>window_size</span> <span class=o>=</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl><span class=n>wordvec_size</span> <span class=o>=</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>corpus</span><span class=p>,</span> <span class=n>word_to_id</span><span class=p>,</span> <span class=n>id_to_word</span> <span class=o>=</span> <span class=n>ptb</span><span class=o>.</span><span class=n>load_data</span><span class=p>(</span><span class=s1>&#39;train&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>vocab_size</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>word_to_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>C</span> <span class=o>=</span> <span class=n>create_co_matrix</span><span class=p>(</span><span class=n>corpus</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>,</span> <span class=n>window_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>W</span> <span class=o>=</span> <span class=n>ppmi</span><span class=p>(</span><span class=n>C</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>U</span><span class=p>,</span> <span class=n>S</span><span class=p>,</span> <span class=n>V</span> <span class=o>=</span> <span class=n>randomized_svd</span><span class=p>(</span><span class=n>W</span><span class=p>,</span> <span class=n>n_components</span><span class=o>=</span><span class=n>wordvec_size</span><span class=p>,</span> <span class=n>n_iter</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>word_vecs</span> <span class=o>=</span> <span class=n>U</span><span class=p>[:,</span> <span class=p>:</span><span class=n>wordvec_size</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>querys</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;you&#39;</span><span class=p>,</span> <span class=s1>&#39;year&#39;</span><span class=p>,</span> <span class=s1>&#39;car&#39;</span><span class=p>,</span> <span class=s1>&#39;toyota&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>query</span> <span class=ow>in</span> <span class=n>querys</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>most_similar</span><span class=p>(</span><span class=n>query</span><span class=p>,</span> <span class=n>word_to_id</span><span class=p>,</span> <span class=n>id_to_word</span><span class=p>,</span> <span class=n>word_vecs</span><span class=p>,</span> <span class=n>top</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>이제 드디어 단어의 의미를 벡터로 잘 인코딩했다.</p><p>말뭉치를 사용해 맥락에 속한 단어의 등장 횟수를 센 후 PPMI 행렬로 변환하고, 다시 SVD를 이용해 차원을 감소시킴으로써 더 좋은 단어 벡터를 얻어냈다.</p><p>이것이 단어의 분산 표현이고, 각 단어는 고정 길이의 밀집벡터로 표현되었다.</p><blockquote><p>단어의 벡터 공간에서는 의미가 가까운 단어는 그 거리도 가깝다.</p></blockquote></section><script type=module>
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
    mermaid.initialize({ startOnLoad: true });
    if (document.documentElement.dataset.scheme == 'dark') {
      mermaid.initialize({theme: 'dark'})
    } else {
      mermaid.initialize({theme: 'light', themeVariables: {xyChart: {plotColorPalette: '#3366FF', backgroundColor: '#FAFAFA'}}})
    }
  </script><footer class=article-footer><section class=article-tags><a href=/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/>딥러닝</a>
<a href=/tags/python/>Python</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css integrity="sha256-J+iAE0sgH8QSz9hpcDxXIftnj65JEZgNhGcgReTTK9s=" crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js integrity="sha256-InsNdER1b2xUewP+pKCUJpkhiqwHgqiPXDlIk7GzBu4=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI=" crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".article-content");if(e){let t=e.innerHTML;t=t.replace(/\\big[oO]/g,"\\mathcal{O}"),t=t.replace(/(\$\$)([\s\S]+?)(\$\$)/g,(e,t,n,s)=>{const o=n.replace(/<em>/g,"_").replace(/<\/em>/g,"_");return`<div markdown="katex">
${t}
${o.trim()}
${s}
</div>`}),e.innerHTML=t,renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],ignoredClasses:["gist"]})}})</script></article><aside class=related-content--wrapper><h2 class=section-title>관련 글</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/word2vec-2/><div class=article-image><img src=/../images/deep-learning-from-scratch.jpeg loading=lazy data-key=word2vec-2 data-hash=/../images/deep-learning-from-scratch.jpeg></div><div class=article-details><h2 class=article-title>Word2Vec의 최적화</h2></div></a></article><article class=has-image><a href=/p/word2vec/><div class=article-image><img src=/../images/deep-learning-from-scratch.jpeg loading=lazy data-key=word2vec data-hash=/../images/deep-learning-from-scratch.jpeg></div><div class=article-details><h2 class=article-title>word2vec을 이용한 단어 임베딩</h2></div></a></article><article class=has-image><a href=/p/neural-network-trainning/><div class=article-image><img src=/../images/deep-learning-from-scratch.jpeg loading=lazy data-key=neural-network-trainning data-hash=/../images/deep-learning-from-scratch.jpeg></div><div class=article-details><h2 class=article-title>신경망의 학습</h2></div></a></article><article class=has-image><a href=/p/neural-network-inference/><div class=article-image><img src=/../images/deep-learning-from-scratch.jpeg loading=lazy data-key=neural-network-inference data-hash=/../images/deep-learning-from-scratch.jpeg></div><div class=article-details><h2 class=article-title>신경망의 추론</h2></div></a></article><article class=has-image><a href=/p/rnn-and-lstm/><div class=article-image><img src=/../images/pytorch-transformer-nlp-computer-vision.png loading=lazy data-key=rnn-and-lstm data-hash=/../images/pytorch-transformer-nlp-computer-vision.png></div><div class=article-details><h2 class=article-title>순환 신경망(RNN)과 장단기 메모리(LSTM)</h2></div></a></article></div></div></aside><script src=https://giscus.app/client.js data-repo=gyeongminn/gyeongminn.github.io data-repo-id=R_kgDOKsf9nw data-category=Announcements data-category-id=DIC_kwDOKsf9n84Ca_6Y data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=light data-lang=ko crossorigin=anonymous async></script>
<script>function setGiscusTheme(e){let t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:{setConfig:{theme:e}}},"https://giscus.app")}(function(){addEventListener("message",t=>{if(event.origin!=="https://giscus.app")return;e()}),window.addEventListener("onColorSchemeChange",e);function e(){setGiscusTheme(document.documentElement.dataset.scheme==="light"?"light":"noborder_gray")}})()</script><footer class=site-footer><section class=copyright>&copy;
2021 -
2025 Gyeongmin Lee</section><section class=powerby><br></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://cdn.jsdelivr.net/gh/orioncactus/pretendard@v1.3.9/dist/web/static/pretendard.min.css",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>